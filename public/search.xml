<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[理解php单例模式]]></title>
      <url>%2F2017%2F06%2F28%2F%E7%90%86%E8%A7%A3php%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[单例作为一个最经典的设计模式之一，到底什么是单例？为什么要用单例？怎么设计单例？php中单例如何具体实现？ 一、什么是单例wiki百科：单例模式，也叫单子模式，是一种常用的软件设计模式。 在应用这个模式时，单例对象的类必须保证只有一个实例存在。 许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。 通俗的说，也就是对于某一个功能只能实例化一个对象。 二、为什么用单例实际项目中像数据库查询，日志输出，全局回调，统一校验等模块。这些模块功能单一，但需要多次访问，如果能够全局唯一，多次复用会大大提升性能。这也就是单例存在的必要性。 单例模式的好处： 1：减少频繁创建，节省了cpu。 2：静态对象公用，节省了内存。 3：功能解耦，代码已维护。 三、如何设计单例通过上面的描述，单例的核心是，实例一次生成，全局唯一，多次调用。因此在单例模式必须包含三要素： 1：私有化构造函数，私有化clone。也就是不能new，不能clone。【唯一】 2：拥有一个静态变量，用于保存当前的类。【唯一如何保存】 3：提供一个公共的访问入口。【可以访问】 四、php实现php 实现的单例模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?phpclass XiaozhuaiSingleton&#123; // 私有化构造方法 private function __construct() &#123; &#125; // 私有化clone方法 private function __clone() &#123; &#125; // 保存实例的静态对象 public static $singleInstance; /** * 声明静态调用方法 * 目的：保证该方法的调用全局唯一 * * @return XiaozhuaiSingleton */ public static function getInstance() &#123; if (!self::$singleInstance) &#123; self::$singleInstance = new self(); &#125; return self::$singleInstance; &#125; // 调用单例的方法 public function singletonFunc() &#123; echo "call single ton method"; &#125;&#125;$singleInstance = XiaozhuaiSingleton::getInstance();$singleInstance-&gt;singletonFunc();$singleInstance2 = XiaozhuaiSingleton::getInstance();$singleInstance2-&gt;singletonFunc();// 校验是否是一个实例var_dump($singleInstance === $singleInstance2); // true ，一个对象]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php进程通信]]></title>
      <url>%2F2017%2F06%2F21%2Fphp%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%2F</url>
      <content type="text"><![CDATA[PHP间进程如何通信，PHP相关的服务的IPC是实现方式，IPC的思想如何用到项目中。 一、linux进程间通信理解php间进程通信机制，先了解下linux进程间有哪些通讯机制 1.1 历史发展linux ipc 按照历史来源主要有两大块 AT&amp;T的system v IPc:管道，FIFO，信号 BSD的socket Ipc :消息队列，共享内存，信号灯。 1.2 主要方式总结起来主要有以下六种方式 1：管道【pipe】：主要是有关系的进程之间的通讯，例如ls xx |grep xx。 2：信号【signal】：通过中间进程来管理进程之间的通讯，属于比较复杂的进程间通讯方式。 3：消息队列【message】：消息的链接表，进程生产和消费消费消息队列。 优势：克服了信号量承载的消息少，管道只能用规定的字节流，同时受到缓冲区大小的约束的问题 （而且读写是有队列的，有一个写，就只有一个能读到，比较简单，不需要同步和互斥） 缺点：太过简单，处理复杂情况可能会造成饥饿现象 4：共享内存。多个进程访问同一个内存区。最快的IPC方式，但是需要处理进程间的同步和互斥。 同时也是当下使用最广泛的IPC，例如nginx，框架通讯，配置中心都是该原理。 5：信号量【semaphore】：主要作为进程间，以及进程内部线程之间的通讯手段。nginx早起的channel机制就类似于信号量 6：套接字【socket】：不同机器之间的通讯手段。处于tcp-》socket-》http之间的一个协议。 二、php进程通讯有哪些方式最好的语言php有哪些IPC的方式 pcntl扩展：主要的进程扩展，完成进程的创建，子进程的创建，也是当前使用比较广的多进程。 posix扩展：完成posix兼容机通用api,如获取进程id,杀死进程等。主要依赖 IEEE 1003.1 (POSIX.1) ，兼容posix sysvmsg扩展：实现system v方式的进程间通信之消息队列。 sysvsem扩展：实现system v方式的信号量。 sysvshm扩展：实现system v方式的共享内存。 sockets扩展：实现socket通信，跨机器，跨平台。 php也有一些封装好的异步进程处理框架：例如swoole,workman等 三、与php相关的IPC3.1 nginx的IPCnginx的ipc主要有两种： 早期：channel 机制：类似于信号，标示不同进程以及进程与子进程之间的套接字，同时具有继承关系。缺点：过于复杂，也产生了过多的套接字，造成存储浪费。 当前主流：共享内存方式：快，写入数据少，方便。 具体可以参见这篇文章：写的非常好 https://rocfang.gitbooks.io/dev-notes/content/nginxzhong_de_jin_cheng_jian_tong_xin.html 3.2 apache的IPCapache：https://arrow.apache.org/docs/ipc.html 四、实际应用中的IPC在平时的项目中，类似于php和linux的IPC的思想大量存在，深入理解。 socket方式：不同项目间通讯，跨机微服务等等，也是使用最广泛的IPC。 共享内存方式：配置中心，公共数据库，甚至git都可以看做共享内存的衍生；`共享内存就必须要注意同步和互斥。 cache ：是共享内存和管道结合的思想 项目流式架构：管道的方式，可以大量的节省空间和时间的通讯方式。 【转载请注明：php进程通信 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CodeIgniter 性能优化]]></title>
      <url>%2F2017%2F06%2F05%2FCodeIgniter%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[背景：部署一套PHP微服务接口，需要兼顾性能，开发效率，扩展性。权衡后选择了CodeIgniter；同时优化框架的默认启动项，在qps1000+的压力下整个启动时间优化到5ms左右。 一、选型 背景：使用php作为微服务的接口，具有一定的性能要求和并发要求。 方案： 1：选一个轻量的php框架。具有简单高效的路由，模块化即可。 2：在框架的基础上，自定义的优化 从以下几个角度做了简单的比较 1.1 不同框架的性能https://www.ruilog.com/blog/view/b6f0e42cf705.html 列举了很多数据，除了直接写php之外，ci和lumen的并发和性能不错，在考虑范围内。 1.2 从流行度上看。github排名前四的是laravel,symfony,ci,yii2。最火的是laravel毋庸置疑。但前四均在考虑范围内 1.3 从文档来看。laraval,ci,yii的中文社区都还不错。 综合考虑之后，在满足功能的情况下，选择性能最好，也易入手的codeIgniter作为基础框架。（整个包才2.5M，删除了web文件夹后更小） 二、30ms+到10ms[粗读代码]框架的基本部署，直接参考官网：https://codeigniter.org.cn/ 2.1 问题描述配置了数据库之后，添加了一个默认的controller，一个model，默认加载时间竟然30ms+—_-。瞬间懵逼了，nginx+fpm也就1-2ms，框架竟然30ms，肯定那里配置错了，决定沿着路由追一下。 2.2 问题追查沿着ci的路由顺序追查，从index入，一步一步卡时间。[括号内为运行到的总计数] -》index.php [1ms]-》core/CodeIgniter.php-》加载常量[1ms]-》加载common(包括log，show，error,is_https等)[1ms]load hooks [2ms]-》加载autoload 方法-》加载benchmark-》实例化hooks-》实例化pre_controller-》实例化post_controller_constructor-》实例化post_controller-》实例化post_system-》加载config [3ms]-》加载扩展mbstring,iconv,hash,stardard-》load 组件utf8，uri-》load router [4ms]-》load output，input，lang[5ms]-》autoload package,cinfig,helper,language,driver,lib,model,db,cache-》404 &amp;empty$…handle [31ms]-》controller remap（测试性能写了个remap）[35ms]-》controller 业务逻辑 [35ms] 这个ci的加载过程之后，基本一幕了然，在autoload里面耗时25ms。然后对autoload里面8个组件一个一个分析。 2.3 问题原因分析完之后，处理特别简单，下面这行代码1$autoload['libraries'] = array('database'); ci 出于单例和复用角度考虑，选择默认加载database，也就是mysql在框架初始化的过程中默认初始化了。mysql链接在并发情况下，init基本上要耗费10-30ms。直接干掉。干掉之后，压测基本上在10ms左右。 三、从10ms到5ms [细看代码]3.1 优化目标优化了配置等之后，ci在高并发下依然有10ms左右的加载时间，需要结合自身逻辑优化下，删减掉部分不需要的功能和组件。 3.2 代码分析之前在追查问题的过程中，粗读了一遍代码的流程。而需要进一步优化，就需要细看每个模块函数的功能，干掉不需要的，逐步优化。 -》index.php 作用：加载了部分全局变量，文件路径等入口 优化：干掉了整个web文件，调整了部分路径 -》core/CodeIgniter.php 作用：ci的核心文件，基本上加载了整个模块 优化：进入内部优化 -》加载common.php 作用：框架特别基本的一些函数log，show，error，is_xxx等，800行左右代码 优化：暂时未处理 -》composer autoload func-》加载benchmark 作用：benchmark性能追查工具，设置了全局的开始和结束时间 优化：直接干掉，全局处理。但是性能需要卡，就在index中初始化了一个入库的timer12345// 定义全局开始追查list($msec, $sec) = explode(' ', microtime());define('START_TIME', (float)sprintf('%.0f', (floatval($msec) + floatval($sec)) * 1000));// 定义全局uuiddefine('UUID', uniqid('xxx', true)); -》实例化hooks和预变量 作用：设计特别棒，对于一些hook或者针对不同模块的预加载函数。 优化：直接干掉，7,8个hook后期用到再针对性添加 -》加载config 作用：对应的是ci的get_config等函数，加载了base_url,uri,cache path等 。 优化：直接干掉，全局变量占用需要自己加就行，这种不可控的干掉 -》加载扩展mbstring,iconv,hash,stardard 作用：一些额外的扩展。 优化：直接干掉，试了下干掉对功能不影响，ci写的太全面了，后期可以通过加载自己的lib弥补。 -》load 组件utf8，uri 作用：uri路由方式处理，utf8的处理。 优化：直接干掉。 -》load router [4ms] 作用：路由。 优化：干不掉。 额外：laravel 据说是使用COC最好的框架，看了下ci的router也不错，基本上都是遵循COC -》load output，input 作用：output和浏览器交互输出的处理组件，input包括获取数据array_merge等等。 优化：干掉,需要自己写 -》autoload package,cinfig,helper,language,driver,lib,model,db,cache 作用：各种各样的组建了。 优化：全不加载 -》404 &amp;empty$…handle 作用：异常处理。 优化：加载 -》controller remap（测试性能写了个remap） 作用：指向其他controller。 优化：无 -》controller 业务逻辑 到此将整个框架过程优化完成，初始一下4-5ms感觉还不错。 四、压测数据4.1 高并发压测2000qps+ ，均值约6ms 4.2 长时间高负载压测1500qps 10min，均值约6ms 问题：分析了部分数据的超时分布，约千分之二超过30ms，如下图【这块需要之后优化】 4.3 无限发压nginx + php 均值：17ms框架部分的均值：9ms 也基本上满足需求 五、汇总ci 是一个比较优秀的轻量级MVC框架，可以用来，业能否支撑1000-2000pqs的业务接口。 最后来一张ci的路由图 ```]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【nginx学习一】基本原理学习]]></title>
      <url>%2F2017%2F03%2F14%2Fnginx_study_1%2F</url>
      <content type="text"><![CDATA[由于性能问题，需要将 apache + php5.2 升级到 nginx + php7，对于nginx的性能和热加载早有耳闻，why nginx so diao。小拽进行了初探，有任何疑问或不准确的地方，欢迎直接开炮！！！ 一、nginx现状nginx 是当前的使用最广泛的webserver ,支持http正向/反向代理，支持TCP/UDP层代理，来看下netcraft的数据 nginx在全部网站中占比达到18%，在top millon busest 达到28%，而且一直在增加。当下最时尚的webserver非nginx莫属 更全数据可以参考：【netcraft】 二、nginx的特点深入了解nginx之前，先泛泛的了解下nginx的几个特点 性能好 非阻塞IO/高并发,支持文件IO 多worker，thread pool 基于rbtree的定时器 系统特性的持续支持 功能强大 webserver/cache/keepalive/pipeline等等 各种upstream的支持【fastcgi/http/…】 输出灵活【chunk/zip/…】 在不断的发展 http2,tcp,udp,proxy… 运维的友好【这个对于开发和部署很重要】 配置非常规范【个人认为：约定及规范是最好的实践】 热加载和热更新【后文会详细介绍，能在二进制的层面热更新】 日志强大【真的很强的，很多变量支撑】 扩展强大 下图是nginx、apache和lighttpd的一个对比。系统压力，内存占用，upstream支持等多个方面都非常不错 三、nginx的核心机制3.1 运行方式一句话简述nginx的运行方式：master-worker多进程模式运行，单线程/非阻塞执行 如下官方图：nginx 启动后生成master，master会启动conf数量的worker进程，当用户的请求过来之后，由不同的worker调起执行线程，非阻塞的执行请求。这种运行方式相对于apache的进程执行相对轻量很多，支撑的并发性也会高很多。 3.2 进程管理nginx是master-worker进程工作模式，那么nginx是如何管理master启程，怎么做到热加载的？ 3.2.1 配置热加载官方图很赞，在更换配置之后，master生成新的worker，直到原有的worker全部任务结束kill掉之后。从现象上作证，也就是在relaod配置之后，短时间可能出现超过conf数量的进程，更新完成后，进程会完全改变。 不更新、直接替换，这种设计思路在代码部署中也很常见，包括mysql迁移，代码更新，服务尝试，很值的学习。 3.2.2 版本更新热加载了解了worker的热加载之后，理解master就非常简单了，通过信号控制，同时存在两个master，逐步替代。 关于replace过程中如何细节控制一致性，稳定性，信号控制，log控制等等，敬请期待小拽的进一步探索！ 3.3 处理流程和模块启动进程后，请求在nginx内部是如何流转的，nginx内部包括哪些模块？ 3.3.1 worker处理过程 【post header】请求到达后首先读取header，log中request time初始时间便从此开始。 【rewrite】请求相关的配置和参数 【pre-access】预处理阶段，频率控制，高频绝句 【acess】权限控制，白名单，403，access deny ，静态文件开放等均有这个模块产生 【content】这个模块会调用upstream产生内容，这个阶段最重要此处调起了工作线程，调用fastcgi，http，以及各种操作产生内容均在此处。性能优化可能需要确认程序执行时间，对应access log中的upstream time 由此产生，记录了nginx中程序运行的全量时间，而request - upstream 就是网络传输和预处理时间。 【filter】内容过滤，包括gzip压缩，返回等在此处 【log】日志的产生 【重定向】没有这个模块，所有的进行智能单向走，有了这个，在任何阶段都可以产生返回，例如client主动阶段产生499的log，过程可能就是1-》2-》8-》7 over 摘自某ppt的一个图，如侵权，请尽快联系小拽 各个阶段的主要状态机可以参考:【跳转】 3.4 请求管理了解了worker的工作模式和worker的内部主要模块，那么worker是如何管理请求的？ 3.4.1 任务调度 官方阐述：It’s well known that NGINX uses an asynchronous, event‑driven approach to handling connections. This means that instead of creating another dedicated process or thread for each request (like servers with a traditional architecture), it handles multiple connections and requests in one worker process. To achieve this, NGINX works with sockets in a non‑blocking mode and uses efficient methods such as epoll and kqueue.核心词：异步，事件驱动，链接控制 解释的很清楚，nginx并不是通过每个请求都创建线程，而是通过内部管理的调度分配。如下图：此处不翻译了，大家直接看原版epoll详解：【跳转】 3.4.2 线程池官方说明 Let’s return to our poor sales assistant who delivers goods from a faraway warehouse. But he has become smarter (or maybe he became smarter after being beaten by the crowd of angry clients?) and hired a delivery service. Now when somebody asks for something from the faraway warehouse, instead of going to the warehouse himself, he just drops an order to a delivery service and they will handle the order while our sales assistant will continue serving other customers. Thus only those clients whose goods aren’t in the store are waiting for delivery, while others can be served immediately. 小拽认为简而言之：结合实际情况，除了空闲被动给，更多的通过事件驱动主动要，通过这种方式在执行资源紧缺的情况下，达到一个执行资源的优化部署，如下图。线程池官网详解：【跳转】 3.4.3 事件调度请求的具体调度基于事件，例如网络IO,磁盘IO,定时器等均可以对事件进行阻塞，当阻塞的事件空闲时，发出调度请求，完成处理。需要额外提一下，nginx的定时器基于rbtree，红黑树的快速插入和查询保证了nginx事件调度的高效性事件框架的处理模型 四、简单总结 性能：nginx 工作模式是master-worker进程方式，执行请求是有更轻量线程完成。 热加载：nginx 替换非更新的方式是nginx热加载的本质 功能强大：nginx upstream是在线程层面调度，兼容多种，所以可以扩展很多功能强大 处理流程：主要的流程过程和模块分离清晰。 请求处理：通过自身的管理，线程池，异步事件驱动等当来完成任务调度 再次强调：初探nginx，有疑问或不准确的地方，请直接开炮！！！ 五、参考文章 netcraft：https://news.netcraft.com/archives/2017/01/12/january-2017-web-server-survey.html nginx的线程调度设计：https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/ epoll详述：http://man7.org/linux/man-pages/man7/epoll.7.html http://yaocoder.blog.51cto.com/2668309/888374 线程池：https://www.nginx.com/blog/thread-pools-boost-performance-9x/ 【转载请注明：【【nginx学习一】基本原理学习 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【redis学习三】简单高可用redis架构实践]]></title>
      <url>%2F2017%2F02%2F05%2Fredis3%2F</url>
      <content type="text"><![CDATA[背景：支撑线上千万级别的天级查询请求，要求高可用。 一、方案调研1.1 redis版本选择redis当前主流版本是redis 2.x 和 redis 3.x，3.0对集群支持比较不错，官方解释如下： Redis是一个开源、基于C语言、基于内存亦可持久化的高性能NoSQL数据库，同时，它还提供了多种语言的API。近日，Redis 3.0在经过6个RC版本后，其正式版终于发布了。Redis 3.0的最重要特征是对Redis集群的支持，此外，该版本相对于2.8版本在性能、稳定性等方面都有了重大提高。 综合考虑之后扩展性和稳定性之后，选择版本 redis 3.2.3-1版本进行部署 1.2 是否选择搭建集群是否搭建集群关键要看单机是否能够满足业务需求，做了个简单的数据评估。 数据量评估 测试：单机写入2000w业务数据，占用内存1.5g，本机126g内存 评估：单机的稳定数据承载量：2000w （126/1.56） 0.6 = 96923w 结论：9T 的数据承载量，远超当前千万级别的数据量 性能评估 测试：简单压测了下 写操作 1000w，80% 在20ms一下 ，98%在30ms，最大218ms，qps 5w/s，总耗时197s 读操作 1000w，97% 在10ms一下 ，99.99%在24ms，qps 6w/s，总耗时160s 评估：当前的调用量在千万每天，qps的话在百/s。 结论：当前单机的redis完全满足需求 因此：在单机远能够满足当下业务需求的情况下，决定不采用的集群的方式来部署redis，减少技术债务风险。 1.3 初定方案和架构图选定了版本和基本部署方案之后，主要考虑服务的容灾和稳定性，经过思考之后采用采用极简的主从从结构，001实时同步数据002和003；001读写，002，003只读，机构图如下 二、实现过程2.1 redis安装此处略去，参考官方文档 https://redis.io/ 2.2 配置读写master 修改端口：port 【目的：简单的修改默认端口是最好的防攻击】 添加密码：pwd 关闭压缩：rdbcompression no 【硬盘最够，降低cpu的能耗更利于提升性能】 开启守护进程：daemonize yes 【master开启守护，增加稳定性】 关闭protect-mode :允许他机器访问 添加白名单：bind xxx 修改log地址，pid地址和数据存储地址：logfile pidfile 【便于维护和安全】 添加慢查询：slowlog-log-slower-than 500 【根据业务需求，便于优化】 最大内存限制：maxmemory 【考虑稳定性和性能，一般不超过最大内存的60%】 2.3 配置只读slave 同master 设置主库:slaveof ip:port 主库密码：masterauth masterpwd 只读：slave-read-only yes 2.4 启动测试启动主库写入数据 进入从库查看最初没有数据，主库写入之后，从库去到数据 查看log确认过程 三、架构能力评估3.1 容灾能力 主动容灾 备份：master 全量备份，slave全量备份。 备份安全：本机保存，hadoop同步保存一份。 监控和探活：监控机分钟级探活和预警 被动容灾： slave 宕机：重启之后直接从master恢复 master 宕机且硬盘数据为损坏：重启后数据自动恢复且和从库一致。 master 宕机且数据损坏：删除损坏数据，使用slave1的数据恢复，保证数据一致。 master 和slave 1 同时宕机：slave2 保证读正常，业务不影响，利用slave2 数据备份恢复master，启动slave 即可 三台全宕机：服务挂掉，从hadoop获取数据恢复服务。 3.2 性能评估压测数据，参见方案选择，完全hold住。 四、问题思考4.1 内存清理策略暂时采用：noeviction -&gt; 谁也不删，直接在写操作时返回错误。之后采用：volatile-lru -&gt; 根据LRU算法删除带有过期时间的key。 最少使用算法删除。如果达到内存限制，手工清理，通过监控脚本监控内存情况 4.2 伸缩性和单节点问题扩展slave可以直接扩展，扩展master需要master之间数据同步，暂时是个瓶颈。对于主读业务的需求，暂时问题不大；写需求的话，暂时的想法是代码转写的方式。 4.3 采用redis sentinal 监听默认不错的监听，尝试了下效果不错，还在调研中，配置conf即可，完成后可以查看监听的情况12345678127.0.0.1:port&gt; INFO Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redis115,status=ok,address=ip:port,slaves=2,sentinels=1 五：常用代码12345678910# 强制杀死redis，模仿宕机ps aux |grep redis |awk '&#123;print $2&#125;'|xargs kill -9# 优化模拟宕机 【根据Dual-X-raY提示-_-】redis&gt; DEBUG SEGFAULT# 重启，指定conf/home/work/xxx/bin/redis-server /home/work/xxx/etc/redis.conf# 压测，具体参数可以参考benchmark[cuihuan@cuihuan bin]$ ./redis-benchmark -h 127.0.0.1 -p 端口 -a 密码 -c 1000 -n 10000000 -d 1024 -r 100000 -t set,get,incr,del 【转载请注明：【redis学习三】简单高可用redis架构实践 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【高并发简单解决方案】redis队列缓存 + 批量入库 + php离线整合]]></title>
      <url>%2F2017%2F01%2F20%2F%E3%80%90%E9%AB%98%E5%B9%B6%E5%8F%91%E7%AE%80%E5%8D%95%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%91redis%E9%98%9F%E5%88%97%E7%BC%93%E5%AD%98%20%2B%20mysql%20%E6%89%B9%E9%87%8F%E5%85%A5%E5%BA%93%20%2B%20php%E7%A6%BB%E7%BA%BF%E6%95%B4%E5%90%88%2F</url>
      <content type="text"><![CDATA[需求背景：有个调用统计日志存储和统计需求，要求存储到mysql中；存储数据高峰能达到日均千万，瓶颈在于直接入库并发太高，可能会把mysql干垮。 问题分析思考：应用网站架构的衍化过程中，应用最新的框架和工具技术固然是最优选择；但是，如果能在现有的框架的基础上提出简单可依赖的解决方案，未尝不是一种提升自我的尝试。 解决： 问题一：要求日志最好入库；但是，直接入库mysql确实扛不住，批量入库没有问题，done。【批量入库和直接入库性能差异参考文章】 问题二：批量入库就需要有高并发的消息队列，决定采用redis list 仿真实现，而且方便回滚。 问题三：日志量毕竟大，保存最近30条足矣，决定用php写个离线统计和清理脚本。 done，下面是小拽的简单实现过程 一：设计数据库表和存储 考虑到log系统对数据库的性能更多一些，稳定性和安全性没有那么高，存储引擎自然是只支持select insert 没有索引的archive。如果确实有update需求，也可以采用myISAM。 考虑到log是实时记录的所有数据，数量可能巨大，主键采用bigint，自增即可。 考虑到log系统以写为主，统计采用离线计算，字段均不要出现索引，因为一方面可能会影响插入数据效率，另外读时候会造成死锁，影响写数据。 二：redis存储数据形成消息队列由于高并发，尽可能简单，直接，上代码。123456789101112131415161718192021222324252627282930313233&lt;?php/***************************************************************************** 获取到的调用日志，存入redis的队列中.* $Id$***************************************************************************//*** @file saveLog.php* @date 2015/11/06 20:47:13* @author:cuihuan* @version $Revision$* @brief***/// 获取info$interface_info = $_GET['info'];// 存入redis队列$redis = new Redis();$redis-&gt;connect('xx', 6379);$redis-&gt;auth("password");// 加上时间戳存入队列$now_time = date("Y-m-d H:i:s");$redis-&gt;rPush("call_log", $interface_info . "%" . $now_time);$redis-&gt;close();/* vim: set ts=4 sw=4 sts=4 tw=100 */?&gt; 三：数据定时批量入库。定时读取redis消息队列里面的数据，批量入库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;?php/** * 获取redis消息队列中的脚本，拼接sql，批量入库。 * @update 2015-11-07 添加失败消息队列回滚机制 * * @Author:cuihuan * 2015-11-06 * */// init redis$redis_xx = new Redis();$redis_xx-&gt;connect('ip', port);$redis_xx-&gt;auth("password");// 获取现有消息队列的长度$count = 0;$max = $redis_xx-&gt;lLen("call_log");// 获取消息队列的内容，拼接sql$insert_sql = "insert into fb_call_log (`interface_name`, `createtime`) values ";// 回滚数组$roll_back_arr = array();while ($count &lt; $max) &#123; $log_info = $redis_cq01-&gt;lPop("call_log"); $roll_back_arr = $log_info; if ($log_info == 'nil' || !isset($log_info)) &#123; $insert_sql .= ";"; break; &#125; // 切割出时间和info $log_info_arr = explode("%",$log_info); $insert_sql .= " ('".$log_info_arr[0]."','".$log_info_arr[1]."'),"; $count++;&#125;// 判定存在数据，批量入库if ($count != 0) &#123; $link_2004 = mysql_connect('ip:port', 'user', 'password'); if (!$link_2004) &#123; die("Could not connect:" . mysql_error()); &#125; $crowd_db = mysql_select_db('fb_log', $link_2004); $insert_sql = rtrim($insert_sql,",").";"; $res = mysql_query($insert_sql); // 输出入库log和入库结果; echo date("Y-m-d H:i:s")."insert ".$count." log info result:"; echo json_encode($res); echo "&lt;/br&gt;\n"; // 数据库插入失败回滚 if(!$res)&#123; foreach($roll_back_arr as $k)&#123; $redis_xx-&gt;rPush("call_log", $k); &#125; &#125; // 释放连接 mysql_free_result($res); mysql_close($link_2004);&#125;// 释放redis$redis_cq01-&gt;close();?&gt; 四：离线天级统计和清理数据脚本123456789101112131415161718192021222324252627282930313233343536?php/*** static log ：每天离线统计代码日志和删除五天前的日志** @Author:cuihuan* 2015-11-06* */// 离线统计$link_2004 = mysql_connect('ip:port', 'user', 'pwd');if (!$link_2004) &#123; die("Could not connect:" . mysql_error());&#125;$crowd_db = mysql_select_db('fb_log', $link_2004);// 统计昨天的数据$day_time = date("Y-m-d", time() - 60 * 60 * 24 * 1);$static_sql = "get sql";$res = mysql_query($static_sql, $link_2004);// 获取结果入库略// 清理15天之前的数据$before_15_day = date("Y-m-d", time() - 60 * 60 * 24 * 15);$delete_sql = "delete from xxx where createtime &lt; '" . $before_15_day . "'";try &#123; $res = mysql_query($delete_sql);&#125;catch(Exception $e)&#123; echo json_encode($e)."\n"; echo "delete result:".json_encode($res)."\n";&#125;mysql_close($link_2004);?&gt; 五：代码部署主要是部署，批量入库脚本的调用和天级统计脚本，crontab例行运行。12345# 批量入库脚本*/2 * * * * /home/cuihuan/xxx/lamp/php5/bin/php /home/cuihuan/xxx/batchLog.php &gt;&gt;/home/cuihuan/xxx/batchlog.log# 天级统计脚本0 5 * * * /home/cuihuan/xxx/php5/bin/php /home/cuihuan/xxx/staticLog.php &gt;&gt;/home/cuihuan/xxx/staticLog.log 总结：相对于其他复杂的方式处理高并发，这个解决方案简单有效：通过redis缓存抗压，mysql批量入库解决数据库瓶颈，离线计算解决统计数据，通过定期清理保证库的大小。 【转载请注明：高并发简单解决方案 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php爬虫：知乎用户数据爬取和分析]]></title>
      <url>%2F2017%2F01%2F20%2Fcharactor%2F</url>
      <content type="text"><![CDATA[背景说明：小拽利用php的curl写的爬虫，实验性的爬取了知乎5w用户的基本信息；同时，针对爬取的数据，进行了简单的分析呈现。demo 地址 php的spider代码和用户dashboard的展现代码，整理后上传github，在个人博客和公众号更新代码库，程序仅供娱乐和学习交流；如果有侵犯知乎相关权益，请尽快联系本人删除。 无图无真相移动端分析数据截图 pc端分析数据截图 整个爬取，分析，展现过程大概分如下几步，小拽将分别介绍 curl爬取知乎网页数据 正则分析知乎网页数据 数据数据入库和程序部署 数据分析和呈现 curl爬取网页数据PHP的curl扩展是PHP支持的，允许你与各种服务器使用各种类型的协议进行连接和通信的库。是一个非常便捷的抓取网页的工具，同时，支持多线程扩展。 本程序抓取的是知乎对外提供用户访问的个人信息页面https://www.zhihu.com/people/xxx,抓取过程需要携带用户cookie才能获取页面。直接上码 获取页面cookie 123// 登录知乎，打开个人中心，打开控制台，获取cookiedocument.cookie"_za=67254197-3wwb8d-43f6-94f0-fb0e2d521c31; _ga=GA1.2.2142818188.1433767929; q_c1=78ee1604225d47d08cddd8142a08288b23|1452172601000|1452172601000; _xsrf=15f0639cbe6fb607560c075269064393; cap_id="N2QwMTExNGQ0YTY2NGVddlMGIyNmQ4NjdjOTU0YTM5MmQ=|1453444256|49fdc6b43dc51f702b7d6575451e228f56cdaf5d"; __utmt=1; unlock_ticket="QUJDTWpmM0lsZdd2dYQUFBQVlRSlZUVTNVb1ZaNDVoQXJlblVmWGJ0WGwyaHlDdVdscXdZU1VRPT0=|1453444421|c47a2afde1ff334d416bafb1cc267b41014c9d5f"; __utma=51854390.21428dd18188.1433767929.1453187421.1453444257.3; __utmb=51854390.14.8.1453444425011; __utmc=51854390; __utmz=51854390.1452846679.1.dd1.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); __utmv=51854390.100-1|2=registration_date=20150823=1^dd3=entry_date=20150823=1" 抓取个人中心页面通过curl，携带cookie，先抓取本人中心页面 123456789101112131415161718192021/** * 通过用户名抓取个人中心页面并存储 * * @param $username str :用户名 flag * @return boolean :成功与否标志 */public function spiderUser($username)&#123; $cookie = "xxxx" ; $url_info = 'http://www.zhihu.com/people/' . $username; //此处cui-xiao-zhuai代表用户ID,可以直接看url获取本人id $ch = curl_init($url_info); //初始化会话 curl_setopt($ch, CURLOPT_HEADER, 0); curl_setopt($ch, CURLOPT_COOKIE, $cookie); //设置请求COOKIE curl_setopt($ch, CURLOPT_USERAGENT, $_SERVER['HTTP_USER_AGENT']); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); //将curl_exec()获取的信息以文件流的形式返回，而不是直接输出。 curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 1); $result = curl_exec($ch); file_put_contents('/home/work/zxdata_ch/php/zhihu_spider/file/'.$username.'.html',$result); return true; &#125; 正则分析网页数据分析新链接，进一步爬取对于抓取过来的网页进行存储，要想进行进一步的爬取，页面必须包含有可用于进一步爬取用户的链接。通过对知乎页面分析发现：在个人中心页面中有关注人和部分点赞人和被关注人。如下所示12// 抓取的html页面中发现了新的用户，可用于爬虫&lt;a class="zm-item-link-avatar avatar-link" href="/people/new-user" data-tip="p$t$new-user"&gt; ok，这样子就可以通过自己-》关注人-》关注人的关注人-》。。。进行不断爬取。接下来就是通过正则匹配提取该信息 12345// 匹配到抓取页面的所有用户preg_match_all('/\/people\/([\w-]+)\"/i', $str, $match_arr);// 去重合并入新的用户数组,用户进一步抓取self::$newUserArr = array_unique(array_merge($match_arr[1], self::$newUserArr)); 到此，整个爬虫过程就可以顺利进行了。如果需要大量的抓取数据，可以研究下curl_multi和pcntl进行多线程的快速抓取，此处不做赘述。 分析用户数据，提供分析通过正则可以进一步匹配出更多的该用户数据，直接上码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 获取用户头像preg_match('/&lt;img.+src=\"?([^\s]+\.(jpg|gif|bmp|bnp|png))\"?.+&gt;/i', $str, $match_img);$img_url = $match_img[1];// 匹配用户名：// &lt;span class="name"&gt;崔小拽&lt;/span&gt;preg_match('/&lt;span.+class=\"?name\"?&gt;([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+span&gt;/u', $str, $match_name);$user_name = $match_name[1];// 匹配用户简介// class bio span 中文preg_match('/&lt;span.+class=\"?bio\"?.+\&gt;([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+span&gt;/u', $str, $match_title);$user_title = $match_title[1];// 匹配性别//&lt;input type="radio" name="gender" value="1" checked="checked" class="male"/&gt; 男&amp;nbsp;&amp;nbsp;// gender value1 ;结束 中文preg_match('/&lt;input.+name=\"?gender\"?.+value=\"?1\"?.+([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+\;/u', $str, $match_sex);$user_sex = $match_sex[1];// 匹配地区//&lt;span class="location item" title="北京"&gt;preg_match('/&lt;span.+class=\"?location.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)\"&gt;/u', $str, $match_city);$user_city = $match_city[1];// 匹配工作//&lt;span class="employment item" title="人见人骂的公司"&gt;人见人骂的公司&lt;/span&gt;preg_match('/&lt;span.+class=\"?employment.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)\"&gt;/u', $str, $match_employment);$user_employ = $match_employment[1];// 匹配职位// &lt;span class="position item" title="程序猿"&gt;&lt;a href="/topic/19590046" title="程序猿" class="topic-link" data-token="19590046" data-topicid="13253"&gt;程序猿&lt;/a&gt;&lt;/span&gt;preg_match('/&lt;span.+class=\"?position.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+\"&gt;/u', $str, $match_position);$user_position = $match_position[1];// 匹配学历// &lt;span class="education item" title="研究僧"&gt;研究僧&lt;/span&gt;preg_match('/&lt;span.+class=\"?education.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)\"&gt;/u', $str, $match_education);$user_education = $match_education[1];// 工作情况// &lt;span class="education-extra item" title='挨踢'&gt;挨踢&lt;/span&gt;preg_match('/&lt;span.+class=\"?education-extra.+\"?.+&gt;([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)&lt;/u', $str, $match_education_extra);$user_education_extra = $match_education_extra[1];// 匹配关注话题数量// class="zg-link-litblue"&gt;&lt;strong&gt;41 个话题&lt;/strong&gt;&lt;/a&gt;preg_match('/class=\"?zg-link-litblue\"?&gt;&lt;strong&gt;(\d+)\s.+strong&gt;/i', $str, $match_topic);$user_topic = $match_topic[1];// 关注人数// &lt;span class="zg-gray-normal"&gt;关注了preg_match_all('/&lt;strong&gt;(\d+)&lt;.+&lt;label&gt;/i', $str, $match_care);$user_care = $match_care[1][0];$user_be_careed = $match_care[1][1];// 历史浏览量// &lt;span class="zg-gray-normal"&gt;个人主页被 &lt;strong&gt;17&lt;/strong&gt; 人浏览&lt;/span&gt;preg_match('/class=\"?zg-gray-normal\"?.+&gt;(\d+)&lt;.+span&gt;/i', $str, $match_browse);$user_browse = $match_browse[1]; 数据入库和程序优化在抓取的过程中，有条件的话，一定要通过redis入库，确实能提升抓取和入库效率。没有条件的话只能通过sql优化。这里来几发心德。 数据库表设计索引一定要慎重。在spider爬取的过程中，建议出了用户名，左右字段都不要索引，包括主键都不要，尽可能的提高入库效率，试想5000w的数据，每次添加一个，建立索引需要多少消耗。等抓取完毕，需要分析数据时，批量建立索引。 数据入库和更新操作，一定要批量。 mysql 官方给出的增删改的建议和速度：http://dev.mysql.com/doc/refman/5.7/en/insert-speed.html 12# 官方的最优批量插入INSERT INTO yourtable VALUES (1,2), (5,5), ...; 部署操作。程序在抓取过程中，有可能会出现异常挂掉，为了保证高效稳定，尽可能的写一个定时脚本。每隔一段时间干掉，重新跑，这样即使异常挂掉也不会浪费太多宝贵时间，毕竟，time is money。 12345678#!/bin/bash# 干掉ps aux |grep spider |awk '&#123;print $2&#125;'|xargs kill -9sleep 5s# 重新跑nohup /home/cuixiaohuan/lamp/php5/bin/php /home/cuixiaohuan/php/zhihu_spider/spider_new.php &amp; 数据分析呈现数据的呈现主要使用echarts 3.0，感觉对于移动端兼容还不错。兼容移动端的页面响应式布局主要通过几个简单的css控制，代码如下 12345678910111213141516171819202122232425262728293031323334/*兼容性和响应式div设计*/@media screen and (max-width: 480px) &#123; body&#123; padding: 0 ; &#125; .adapt-div &#123; width: 100% ; float: none ; margin: 20px 0; &#125; .half-div &#123; height: 350px ; margin-bottom: 10px; &#125; .whole-div &#123; height: 350px; &#125;&#125;&lt;!-- 整块完整布局，半块在web端采用float的方式，移动端去掉--&gt;.half-div &#123; width: 48%; height: 430px; margin: 1%; float: left&#125;.whole-div &#123; width: 98%; height: 430px; margin: 1%; float: left&#125; 不足和待学习整个过程中涉及php,shell,js,css,html,正则等语言和部署等基础知识，但还有诸多需要改进完善，小拽特此记录，后续补充例： php 采用multicul进行多线程。 正则匹配进一步优化 部署和抓取过程采用redis提升存储 移动端布局的兼容性提升 js的模块化和sass书写css。 【转载请注明：php爬虫：知乎用户数据爬取和分析 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【page-monitor 前端自动化 下篇】 实践应用]]></title>
      <url>%2F2016%2F08%2F20%2F%E3%80%90page-monitor%20%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96%20%E4%B8%8B%E7%AF%87%E3%80%91%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[通过page-diff的初步调研和源码分析，确定page-diff在前端自动化测试和监控方面做一些事情。本篇主要介绍下，page-diff在具体的实践中的一些应用 核心dom校验前端的快速发展，造成前端dom无论结构还是命名经常变化，每次都尽可能关注每个dom的变化，不可能也没有必要。但是核心dom是相对变化较小，但是比较重要，因此可以利用page-monitor 修改关注结构中的核心代码，核心架构的变化。 上图是未修改的代码，下图是忽略footer内部变化实践中可以针对自身的核心dom进行进一步优化 局部dom校验项目中，往往在某一时期特别关心某些板块，或者某些板块相对容易出错；因此，可以利用page-monitor 进行局部dom的细节diff。中篇中对只针对header进行对比diff做了详细介绍，此处不赘述，上图。 算法优化由于获取了完整了dom的json，因此可以通过相关阈值的设定或者算法的优化；来对比结果，进行更加优化的分级预警和分析；作者一般对非核心预警超过15%变化会做出预警，超过更高阈值会进一步的预警等等。贴一个dom 细节图 其他分析小拽通过上面的举例，旨在抛砖引玉，希望page-monitor或者dom结构在前端的自动化测试有一定应用，提升产品质量。 最终再上一张流程图，便于分析 相关文章：【page-monitor 前端自动化 上篇】 初步调研【page-monitor 前端自动化 中篇】 源码分析]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[fsck修复linux文件损坏]]></title>
      <url>%2F2016%2F08%2F20%2Ffsck%E4%BF%AE%E5%A4%8Dlinux%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%2F</url>
      <content type="text"><![CDATA[数据一定要备份，最好多机备份，代码一定要ci。 背景和损失背景：机房事故，突然关机，硬盘年老失修，造成很多文件不可用。如图 面临损失：作为一名靠谱程序员，数据库单机多机备份，程序版本控制这些都是有的【如果没有，一定要加上】；但这次有一个重要影响，就是git中commit之后，没有push的文件全损坏了，损坏了，坏了，了。。。。 分析原因op给出的说法是网络波动，造成机房故障，机器重启。但从结果看，文件系统乱掉了，而且乱掉的文件主要分两类： 1：当时正在写入和操作的文件。例如运行的脚本，正在写的文件，samba建立网络映射的文件，git实时文件。 2：内存里的数据，例如memcache里的数据等等 处理：fsck修复。###1：查看硬盘挂载：df查看下磁盘的挂载位置。 2：操作挂起：不挂起可能会出现数据恢复中断。报错：直接挂起会出现 dev is busy，如下图用：umout -l /dev/sda31234#umount -l &lt;挂载点|设备&gt;此命令将会断开设备并关闭打开该设备的全部句柄。通常，您可以使用 eject &lt;挂载点|设备&gt;命令弹出碟片 3：fsck 扫盘1fsck -f /dev/sda3 注意ext2 还会进行e2fsck 再扫一遍，此为正常操作 4：扫盘结束后，挂载驱动盘5：寻找和恢复文件把.git 内的文件全部整理，导出，一个一个寻找自己需要的文件，找到了久违的文件。 后续一句话：代码一定要ci，数据一定要容灾 【转载请注明：fsck修复linux文件损坏 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[phpredis单例模式封装]]></title>
      <url>%2F2016%2F08%2F08%2Fphpredis%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%B0%81%E8%A3%85%2F</url>
      <content type="text"><![CDATA[通过单例模式实现对phpredis连接的封装。 直接上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?php/** * Class RedisConnManager * * 单例模式对redis实例的操作的进一步封装 * 主要目的：防止过多的连接，一个页面只能存在一个声明连接 * * @author ：cuihuan */class RedisManager&#123; private static $redisInstance; /** * 私有化构造函数 * 原因：防止外界调用构造新的对象 */ private function __construct()&#123;&#125; /** * 获取redis连接的唯一出口 */ static public function getRedisConn()&#123; if(!self::$redisInstance instanceof self)&#123; self::$redisInstance = new self; &#125; // 获取当前单例 $temp = self::$redisInstance; // 调用私有化方法 return $temp-&gt;connRedis(); &#125; /** * 连接ocean 上的redis的私有化方法 * @return Redis */ static private function connRedis() &#123; try &#123; $redis_ocean = new Redis(); $redis_ocean-&gt;connect(G::$conf['redis-host'], G::$conf['redis-port']); $redis_ocean-&gt;auth(G::$conf['redis-pass']); &#125;catch (Exception $e)&#123; echo $e-&gt;getMessage().'&lt;br/&gt;'; &#125; return $redis_ocean; &#125;&#125; 【转载请注明：phpredis单例模式封装 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【page-monitor 前端自动化 上篇】初步调研]]></title>
      <url>%2F2016%2F08%2F07%2F%E3%80%90page-monitor%20%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96%20%E4%B8%8A%E7%AF%87%E3%80%91%E5%88%9D%E6%AD%A5%E8%B0%83%E7%A0%94%20%2F</url>
      <content type="text"><![CDATA[前端自动化测试主要在于：变化快，不稳定，兼容性复杂；故而，想通过较低的成本维护较为通用的自动化case比较困难。本文旨在通过page-monitor获取和分析dom结构，调研能否通过监控和分析核心dom，来进行前端自动化测试。 一：page-monitor 介绍page-monitor：通过xpath获取dom节点结构，之后可视化的渲染出页面的差异。github地址：https://github.com/fouber/page-monitor基本原理：利用xpath获取页面的dom结构，存储为结构化的json，对比两次的json之间的差异，利用phantom渲染页面和差异页面。 先上个初次试用的图 二：初次试用2.1 安装123# page-monitor 依赖于 phantomjsnpm install phantomjsnpm install page-monitor 注意：phantomJs较大，如果比较慢 可以用brew安装，并且page-monitor最多兼容phantom1.9812345# 调整phantom为1.98 版本MacBook-Pro:~ cuixiaohuan$ brew link phantomjs198Linking /usr/local/Cellar/phantomjs198/1.9.8... 2 symlinks createdMacBook-Pro:~ cuixiaohuan$ phantomjs -v1.9.8 2.2 初次运行：写一个test.js 代码如下:12345678var Monitor = require('page-monitor');var url = 'http://www.baidu.com';var monitor = new Monitor(url);monitor.capture(function(code)&#123; console.log(monitor.log); // from phantom console.log('done, exit [' + code + ']');&#125;); 运行效果12345678910111213141516171819MacBook-Pro:test cuixiaohuan$ node test.js&#123; debug: [ 'mode: 11', 'need diff', 'loading: http://www.baidu.com', 'page.viewportSize = &#123;"width":320,"height":568&#125;', 'page.settings.resourceTimeout = 20000', 'page.settings.userAgent = "Mozilla/5.0 (iPhone; CPU iPhone OS 7_0 like Mac OS X; en-us) AppleWebKit/537.51.1 (KHTML, like Gecko) Version/7.0 Mobile/11A465 Safari/9537.53"', 'loaded: http://www.baidu.com', 'delay before render: 0ms', 'walk tree', 'save capture [/Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/www.baidu.com/Lw==/1461155680901]', 'screenshot [/Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/www.baidu.com/Lw==/1461155680901/screenshot.jpg]', 'Unsafe JavaScript attempt to access frame with URL about:blank from frame with URL file:///Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/node_modules/page-monitor/phantomjs/index.js. Domains, protocols and ports must match.' ], warning: [], info: [], error: [], notice: [] &#125;done, exit [0] 2.2 生成对比页面 test.js code 1234monitor.diff(1408947323420, 1408947556898, function(code)&#123; console.log(monitor.log.info); // diff result console.log('[DONE] exit [' + code + ']');&#125;); 运行123MacBook-Pro:test cuixiaohuan$ node test.js[ '&#123;"diff":&#123;"left":"1461155680901","right":"1461163758667","screenshot":"/Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/www.baidu.com/Lw==/diff/1461155680901-1461163758667.jpg","count":&#123;"add":2,"remove":2,"style":0,"text":9&#125;&#125;&#125;' ][DONE] exit [0] 2.3 对比页面效果如下图 2.4 目录初步分析通过目录和运行结果1：每个时间利用phantom生成一张截图【保存现场】和一个dome的tree.json【对比dom】 【生成过程看下源码】2：diff 调用tree.json 比较区中的区别【位置，内容生成和对比过程之后看下源码？】3：利用当时保存的截图渲染生成的结果 三：dom diff工具page monitor 调研初步结论： 1：dom的diff 是可行的。 2：page monitor 现有主要功能：抽取不同时间段的页面做页面domdiff使用过程中缺陷：1：依赖太多，依赖node，依赖phantom，2：接口太少，现在直接提供的就两个一个保存现场，一个diff。不方便dom定制和阈值定制。 四：应用价值思考和下一步如果能对dom树的处理更完善一些，应用价值还是挺高的，例如核心dom的diff，局部dom的diff，时效性dom(例如：时间tag必须变化，不变化则为bug)的变更检验，兼容性dom的check等等 下一步调研：看下源码中，分析dom生成tree过程，对比tree过程，展现tree过程。 相关文章：【page-monitor 前端自动化 中篇】 源码分析【page-monitor 前端自动化 下篇】 实践应用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【page-monitor 前端自动化 中篇】 源码分析]]></title>
      <url>%2F2016%2F08%2F07%2Fpage_monitor_second%2F</url>
      <content type="text"><![CDATA[上篇中初探了page-monitor的一些功能和在前端自动化测试方面的可行性，本篇主要分析下page-monitor的实现方式和源码。 mode-module简介page-monitor的存在形式是node-module，依赖于node安装和运行，简单必须了解下node_modules node-module是nodejs的模块，符合commonJs规范【具体规范可以参考：http://javascript.ruanyifeng.com/nodejs/module.html】 简单描述commonJs规范1：文件即模块，作用域在文件内，不允许重复，不会污染。2：加载依赖出现顺序，加载即运行，重复则利用缓存。 多说一句：这是amd 和cmd(commonJs)的本质区别，由于node多运行于服务端，加载比较快，因此比较适合cmd 规范，浏览器端的模块则更适用于cmd的规范，个人理解没有广义的好坏之分 方便看源码，贴出node_modole简单构成和主要函数modulenode内部提供一了一个modle的构造函数，所有的模块都继承和依赖于此模块。node module的引入 require命令。其他加载规则，路径设定不在此赘述。 page-monitor文件分析完整文件目录： 运行生成目录分析： 出了node_module及其组件代码，可用和值的分析的文件index.js 和phantomjs 下面的五个文件。 分析index.js代码中无非变量声明和引用，关键一句引用phantom的命令乳腺12// 多线程启动位置var proc = spawn(binPath, arr); 通过上面多线程的启动node可以达到高效和并发处理测试任务的需求，分析下arr的内容如下图：看到了 窗口大小，延时，ua，存放地址，diff变量等等 分析获取DOM源码获取dom的源码主要利用了web api evalution，evalution传入一个xpath的参数，返回一个xpath的对象，之后通过遍历和xpath规则生成规则化的json。贴一个evalution api 为了看懂page-monitor的代码举个栗子123456789101112# evalution example:var headings = document.evaluate("/html/body//h2", document, null, XPathResult.ANY_TYPE, null);/* 检索body中所有H2的所欲. * 结果存在于一个node的迭代器中 */var thisHeading = headings.iterateNext();var alertText = "Level 2 headings in this document are:\n";while (thisHeading) &#123; alertText += thisHeading.textContent + "\n"; thisHeading = headings.iterateNext();&#125;alert(alertText); // Alerts the text of all h2 elements 通过上面函数和page-monitor中walk.js函数最后一行，可以看出page-monitor 保存了四个元素：属性[name,id等等]，节点类型，位置[后期渲染]，样式的md5加密[样式仅需要对比是否变化即可]具体内容和dom结构如下： 对应的具体dom结构 diff.js 代码diff代码主要两个作用 1：获取差异 2：渲染差异其中对比的策略： 历史完全每个对比现在：获取更新和删除的内容现在完全每个对比历史：获取更新和新增的内容具体可以参考代码 其他api和源码简单修改必须了解的web api 还有一个是querySeletor 也就是检索的api，参考地址document.querySelector()了解了这个api就可以做一件事情：不对全局dom diff，只对特别关心的dom进行diff实现方式：修改querySelector的根节点为Header获取的dom结构如下：根节点为header 获取的页面截图如下： 代码流程图 总结本次在调研page-monitor的基础上，对page-monitor的源码实现进行分析；同时利用相关api修改，来只对核心页面进行获取优化。下一篇将会进一步思考page-monitor的应用。 相关文章：【page-monitor 前端自动化 上篇】 初步调研【page-monitor 前端自动化 下篇】 实践应用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【chrome 插件一】开发一个简单chrome浏览器插件]]></title>
      <url>%2F2016%2F04%2F26%2Fchrome_1%2F</url>
      <content type="text"><![CDATA[chrome 之所以越来越好用，很大一部分原因归功于功能丰富的插件；对于chrome忠实用户来说，了解和开发一款适合自己的chrome插件，确实是一件很cool的事情。 了解chrome 插件chrome 插件个人理解：就是一个html + js +css + image的一个web应用；不同于普通的web应用，chrome插件除了兼容普通的js，json，h5等api，还可以调用一些浏览器级别的api，例如收藏夹，历史记录等。 推荐两个网站了解和入门谷歌官方API：https://developer.chrome.com/extensions/getstarted360的文档：http://open.chrome.360.cn/extension_dev/overview.html 开始写第一个插件文件结构一个简单的demo，文件目录如下和普通的web文件没有什么区别，简单介绍下 html:存放html页面 js :存放js locales ：存放了一个多语言的兼容【可无】 image ：放了两张图片【初期图标】 manifest ：核心入口文件 写一个manifestapi参考文档 :http://open.chrome.360.cn/extension_dev/manifest.html 直接上代码：12345678910111213141516171819202122232425262728293031323334353637383940&#123; "name": "hijack analyse plug", "version": "0.0.1", "manifest_version": 2, // 简单描述 "description": "chrome plug analyse and guard the http hijack", "icons": &#123; "16": "image/icon16.png", "48": "image/icon48.png" &#125;, // 选择默认语言 "default_locale": "en", // 浏览器小图表部分 "browser_action": &#123; "default_title": "反劫持", "default_icon": "image/icon16.png", "default_popup": "html/test.html" &#125;, // 引入一个脚本 "content_scripts": [ &#123; "js": ["script/test.js"], // 在什么情况下使用该脚本 "matches": [ "http://*/*", "https://*/*" ], // 什么情况下运行【文档加载开始】 "run_at": "document_start" &#125; ], // 应用协议页面 "permissions": [ "http://*/*", "https://*/*" ]&#125; test.js 文件1234567891011/** * @author: cuixiaohuan * Date: 16/4/13 * Time: 下午8:41 */(function()&#123; /** * just test for run by self */ console.log('begin');&#125;)(); test.html 文件12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;just for test&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;test&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 运行插件chrome 中输入：chrome://extensions选择加载已解压的插件-》选择文件根目录即可。效果如下： 一个基本的插件变完成了，勾选已启用，随便打开一个网页，会看到log中输出如下 点击页面上面的小图标如下图： 优化建议一个小的插件已经完成，但是还有更多的api和有趣的事情可以去做。下面是360文档中给出一些优化建议，共勉。 确认 Browser actions 只使用在大多数网站都有功能需求的场景下。确认 Browser actions 没有使用在少数网页才有功能的场景， 此场景请使用page actions。 确认你的图标尺寸尽量占满19x19的像素空间。 Browser action 的图标应该看起来比page action的图标更大更重。 尽量使用alpha通道并且柔滑你的图标边缘，因为很多用户使用themes，你的图标应该在在各种背景下都表现不错。不要不停的闪动你的图标，这很惹人反感。 【转载请注明：【chrome 插件一】开发一个简单chrome浏览器插件 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[中型存储架构实践探索]]></title>
      <url>%2F2016%2F04%2F20%2F%E4%B8%AD%E5%9E%8B%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E5%AE%9E%E8%B7%B5%E6%8E%A2%E7%B4%A2%2F</url>
      <content type="text"><![CDATA[最近一直在做平台优化：对于中小型的站点，如何在资源有限的情况下，实现一个稳定，高效，靠谱的存储方案。下图是小拽个人在时间过程使用的一个存储架构。拿出来分享交流一下，也希望得到指点改进！ 先上图 首先说思想思想就一个：权衡资源和业务需求 简单解释一下：对于架构的理解，个人非常认同百度架构师tandai的一句话：架构设计本质上是折衷的艺术，如果你有足够量的高速存储和高性能的机器，那么完全可以用足量的cache，足量的离线计算存储，来提升时效性；同样，如果你的机器不足，资源不足，那么就可以通过可接受的时间消耗来节省存储空间。 架构基本组件： 至少两台机器。【保证物理容灾】 三个mysql实例。【一主两从，一主不解释；一从主要用于实时备份，暂叫容灾从；一从用于离线计算，cache更新，非时效性的数据抓取，暂叫api从；】 ameoba 负责负载均衡和读写分离【暂时用着还可以】。 redis 负责缓存，预取，存储cache。【可以换成其他】 一个抗高并发的中间件。【暂时只加了antispam组件，高并发并未处理，可能系统负载比较平均，qpd几千万 ，但是并未出现qps峰值】 that’s all，这些组件对于一个操作尚可的程序员来说，部署一整套肯定不会特别麻烦，相对于其他大型的架构来说，略显简单；但是，麻雀虽小，五脏俱全，下面从架构必备的几个角度分析一下。 安全性（Failover）任何一个架构首要考虑的是数据安全和容灾。小拽的架构中做了哪些 数据库全量备份这个就是一个简单脚本，对api从库在闲暇时间【晚上3-4点】进行全量导出备份，同时scp到另一台机器一份。（之所以对api库，是因为api库主要负责非失效性的查询和计算） 123456# crontab 每天3点进行数据库备份 (cuihuan)# 0 3 * * * sh /home/disk6/mysql/bin/backup.sh# 每天备份，保存最近30天的DATE=$(date +%Y%m%d)/home/xxx/bin/mysqldump -uroot -pxxx db &gt; /home/xxx/bak_sql/db_$DATE.sql;find /home/xxx/bak_sql/ -mtime +30 -name '*.sql' -exec rm -rf &#123;&#125; \; 数据库增量备份增量备份主要从两个角度 binlog中定期备份sql； 是采用主从库之后，从库会定时的备份主库信息，同时，对api库采用数据完全一致，对容灾库则设置只同步update 和insert；这样完备的保证了数据的安全。 可用性（Availabilty）数据的安全排第一，毋庸置疑；次之排平台的可用性，也毫无争议。可用性最简单的一个指标则为：不卡。 cachecache是提升查询时效性最有效的一个手段，小拽在框架中主要应用了两种cache，满足不同的业务需求。（所有关于cache的使用，一定要注意时效性和一致性，时效性和一致性，时效性和一致性） 普通的cache。即用户搜索或者查询之后的结果存在redis里面，下次查询使用。 预取的cache。即预测用户要查询的内容，放到cache里面。举几个栗子，用户首页内容一定要存cache里面；用户在看page1的时候，可以后台预测用户会看page2，提前取过来等等，这些策略和自己的实际业务紧密结合。 关于时效性和一致性再多说一句：一定要注意及时更新，例如用户写操作，点击操作，都需要在后台触发cache的主动更新，否则可能造成数据一致性错误。 分库分表中小型的架构中，存储的瓶颈往往在于读。 随着数据的增加，读库的成本越来越大，一个sql很可能会造成锁死整个库，一条sql 10+s也是常有的事情；因此，解决读库的瓶颈，可以大大提升系统的可用性；小拽的实践中主要应用了分库，分表。 分库之所以要分库，是因为二八原则的存在，80%的用户操作集中于20%的数据。 举个栗子：实践过程中小拽有个月库，只存本月的数据，基本上80%+的用户操作数据，都会命中这个库。 分库的原则有很多，例如时间原则，业务原则，数据逻辑原则等等；总之在您的框架中，当db扛不住的时候就分库，分层级。 分表分表的思想和分库类似，只是粒度更小，不在赘述。 扩展性（Scabability）小拽的架构中，扩展性主要从三个方面考虑 1：数据库的扩展性。如果资源允许N主N从都是可以的，基本上不会影响业务操作。 2：缓存的扩展。缓存基本上也是单独部署的，redis，memcache等均可以，变更成本不大。 3：高并发和负载均衡。这块属于大型网站需要考虑的，暂时只采用了ameaba进行负载均衡的扩展，高并发预留接口。 权衡（Balance）所有的架构和技术，最终都要落实到和业务需求权衡。 上面的架构最大的优势其实就是：简单，搭建起来非常容易，这就够了。 作为一名码农，只有在实践的过程中，不断发现系统的瓶颈，权衡现有资源和需求，解决和处理问题，才能成为一名靠谱的码农。 以上只是小拽在实践过程中的一点小小心的，欢迎大家到小站交流（http://cuihuan.net）。 【转载请注明：中型存储架构实践探索 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【chrome 插件二】添加菜单和添加消息提醒]]></title>
      <url>%2F2016%2F04%2F20%2Fchrome_2%2F</url>
      <content type="text"><![CDATA[上一篇中简单的接触了chrome插件，并且草草的制作一个chrome 插件（-_-只中看，不能用）；这次主要学习，browse action api制作菜单制作和调用系统提醒。 browse actionbrowse action 包括四部分：一个图标，一个tooltip，一个badge和一个pophtml先上代码和效果12345"browser_action": &#123; "default_title": "反劫持工具", "default_icon": "image/icon_19.png", "default_popup": "html/popup.html" &#125;, 图标图标优化：最好是19px，这样基本占满，可以直接使用图标也可以用h5 canvas element，同时，图片一定要是背景透明的。 ps处理后页面效果如下： tooltip直接设置default_title 效果是鼠标经过显示标题效果 badge:这个相当于设置图片文字和背景色：提供了两个方法：设置badge文字和颜色可以分别使用setBadgeText()andsetBadgeBackgroundColor()。 pophtml：创建菜单上码：能用代码说话的，不用文字js12345678910111213141516171819202122232425262728293031/** * @author: cuixiaohuan * Date: 16/4/19 * Time: 下午9:41 *//** * 点击菜单的事件 * * @param e */function click(e) &#123; chrome.tabs.executeScript(null, &#123; // 更改背景色 code: "document.body.style.backgroundColor='" + e.target.id + "'" &#125; ); window.close();&#125;/** * 页面加载完成后，监听事件 */document.addEventListener('DOMContentLoaded', function () &#123; var divs = document.querySelectorAll('div'); for (var i = 0; i &lt; divs.length; i++) &#123; divs[i].addEventListener('click', click); &#125;&#125;); html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Set Page Color Popup&lt;/title&gt; &lt;style&gt; body &#123; overflow: hidden; margin: 0px; padding: 0px; background: white; &#125; div:first-child &#123; margin-top: 0px; &#125; div &#123; cursor: pointer; text-align: center; padding: 1px 3px; font-family: sans-serif; font-size: 0.8em; width: 100px; margin-top: 1px; background: #cccccc; &#125; div:hover &#123; background: #aaaaaa; &#125; #red &#123; border: 1px solid red; color: red; &#125; #blue &#123; border: 1px solid blue; color: blue; &#125; #green &#123; border: 1px solid green; color: green; &#125; #yellow &#123; border: 1px solid yellow; color: yellow; &#125; &lt;/style&gt; &lt;script src="../script/changeBackgroud.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="red"&gt;红色小拽&lt;/div&gt; &lt;div id="blue"&gt;绿色小拽&lt;/div&gt; &lt;div id="green"&gt;蓝色小拽&lt;/div&gt; &lt;div id="yellow"&gt;换色小拽&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 效果图 调用系统提醒notification api 官方文档:https://developer.chrome.com/extensions/notifications注意 chrome32 之前的预警接口不太一样，文档中已经说明。 使用预警一定要加上权限统一123"permissions": [ "notifications"], 调用系统提醒代码1234567891011121314151617181920212223242526272829303132// 用户授权if (Notification.permission == "granted") &#123; Notification.requestPermission();&#125;/** * 调用系统提醒 * * 第一次进入页面需要授权，之后弹出提醒 */function notifyMe() &#123; if (!Notification) &#123; alert('Desktop notifications not available in your browser. Try Chromium.'); return; &#125; if (Notification.permission !== "granted")&#123; Notification.requestPermission(); &#125; else &#123; var notification = new Notification('小拽提醒', &#123; icon: 'http://cuihuan.net/wp-content/themes/quench-master/images/cuihuan_title.jpg', body: "别点击，点击跳转'靠谱崔小拽'" &#125;); notification.onclick = function () &#123; window.open("http://cuihuan.net"); &#125;; &#125;&#125; 初次进去提醒，授权 提醒效果如右上角所示 通过菜单和提醒，我们基本就可以完成一个简单的闹钟提醒，每隔30分钟提醒，码农扭扭脑袋，伸伸懒腰，小心肩周炎-_-! 【转载请注明：【chrome 插件二】弹出菜单和系统提醒学习 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql数据导库常用操作]]></title>
      <url>%2F2016%2F03%2F08%2Fmysql%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%BA%93%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[工作中经常遇到：一个数据库导入新的数据库实例中，或者一个数据库中的某些表导入新的数据库中，常用操作，总结一下。 部分数据表导入新库 单表导入新库的sql为 12# CREATE TABLE 新表 SELECT * FROM 旧表create table `dashboard`.`xx` (select * from dashboard_stb.xxx); 多表导入新库（将所有的stability_* 导入新库）多表的时候，只需选出需要的表即可。 1234567891011# 拼接处所有的导出sqlmysql&gt; select concat ('create table `dashboard`.',table_name,'(select * from `dashboard_stb`.',table_name,');') from information_schema.tables where table_name like "stability_%";+--------------------------------------------------------------------------------------------------------+| concat ('create table `dashboard`.',table_name,'(select * from `dashboard_stb`.',table_name,');') |+--------------------------------------------------------------------------------------------------------+| create table `dashboard`.stability_capacity(select * from `dashboard_stb`.stability_capacity); || create table `dashboard`.stability_dailymaxflow(select * from `dashboard_stb`.stability_dailymaxflow); || create table `dashboard`.stability_indextype(select * from `dashboard_stb`.stability_indextype); || create table `dashboard`.stability_ktraceagent(select * from `dashboard_stb`.stability_ktraceagent); # 此处省略N行+--------------------------------------------------------------------------------------------------------+ 粘贴进去直接运行即可123456789101112mysql&gt; create table `dashboard`.stability_maccpu(select * from `dashboard_stb`.stability_maccpu);Query OK, 138138 rows affected (2.16 sec)Records: 138138 Duplicates: 0 Warnings: 0mysql&gt; create table `dashboard`.stability_macmem(select * from `dashboard_stb`.stability_macmem);Query OK, 138137 rows affected (2.07 sec)Records: 138137 Duplicates: 0 Warnings: 0mysql&gt; create table `dashboard`.stability_macssd(select * from `dashboard_stb`.stability_macssd);Query OK, 138139 rows affected (2.17 sec)Records: 138139 Duplicates: 0 Warnings: 0# 此处省略N行 全库备份导入新库数据库全量导出为sql1mysqldump -uxxx -pxxx dashboard &gt; dashboard.sql 通过sql建立新库1234# 建新库mysql&gt; create databases dashboard_new# 导入数据./mysql -uxxx -p --default-character-set=utf8 dashboard_new &lt; dashboard.sql 【转载请注明：mysql 简单全量备份和快速恢复 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[postMessage处理iframe 跨域问题]]></title>
      <url>%2F2016%2F02%2F29%2FpostMessage%E5%A4%84%E7%90%86iframe%20%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[背景：由于同源策略存在，javascript的跨域一直都是一个棘手的问题。父页面无法直接获取iframe内部的跨域资源；同时，iframe内部的跨域资源也无法将信息直接传递给父页面。 一：传统的解决方式。传统的iframe资源解决方式：主要通过通过中间页面代理，此处不再赘述，参考中间页获取跨域iframe 二：html5 postMessage的产生随着HTML5的发展，html5工作组提供了两个重要的接口：postMessage(send) 和 onmessage。这两个接口有点类似于websocket，可以实现两个跨域站点页面之间的数据传递。 postMessage API 下面是实践过程中两个小栗子：分别父页面传递信息给iframe，iframe传递信息给父页面。 三：iframe获取父页面信息话不多说，直接上码：参考demo：父页面传给子页面demo 父页面代码123456789101112131415161718192021222324&lt;html&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔涣 iframe postmessage 父页面&lt;/title&gt; &lt;script type="text/JavaScript"&gt; function sendIt() &#123; // 通过 postMessage 向子窗口发送数据 document.getElementById("otherPage").contentWindow .postMessage( document.getElementById("message").value, "http://cuihuan.net:8003" ); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- 通过 iframe 嵌入子页面 --&gt;&lt;iframe src="http://cuihuan.net:8003/test.html" id="otherPage"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;br/&gt;&lt;input type="text" id="message"/&gt;&lt;input type="button" value="Send to child.com" onclick="sendIt()"/&gt;&lt;/body&gt;&lt;/html&gt; 子页面代码123456789101112131415161718&lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔涣测试子页面信息&lt;/title&gt; &lt;script type="text/JavaScript"&gt; //event 参数中有 data 属性，就是父窗口发送过来的数据 window.addEventListener("message", function( event ) &#123; // 把父窗口发送过来的数据显示在子窗口中 document.getElementById("content").innerHTML+=event.data+"&lt;br/&gt;"; &#125;, false ); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; this is the 8003 port for cuixiaozhuai &lt;div id="content"&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; demo 效果如下图：两个跨域页面之间，父页面给子页面传递数据。 四：iframe传递信息给父页面参考demo：跨域子页面传给父页面demo 父页面代码1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔涣测试父页面&lt;/title&gt; &lt;script type="text/JavaScript"&gt; //event 参数中有 data 属性，就是父窗口发送过来的数据 window.addEventListener("message", function( event ) &#123; // 把父窗口发送过来的数据显示在子窗口中 document.getElementById("content").innerHTML+=event.data+"&lt;br/&gt;"; &#125;, false ); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;iframe src="http://cuihuan.net:8003/iframeSon.html" id="otherPage"&gt;&lt;/iframe&gt; &lt;br/&gt; this is the 1015 port for cuixiaozhuai。 &lt;div id="content"&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 子页面代码123456789101112131415161718192021&lt;html&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔小涣iframe postmessage 测试页面&lt;/title&gt; &lt;script type="text/JavaScript"&gt; function sendIt() &#123; // 子页面给父页面传输信息 parent.postMessage( document.getElementById("message").value, "http://cuihuan.net:1015" ); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;br/&gt;this is the port for cuixiaozhuai&lt;input type="text" id="message"/&gt;&lt;input type="button" value="Send to child.com" onclick="sendIt()"/&gt;&lt;/body&gt;&lt;/html&gt; demo 效果如下图：两个跨域页面之间，子页面传递数据给父页面传递数据。 五：postmessage简单分析和安全问题postmessage 传送过来的信息如下图， 几乎包含了所有应该有的信息。甚至data中可以包含object，出于安全考虑可以域的校验，数据规则的校验安全校验，如下代码1234567891011121314151617181920212223242526window.addEventListener('message', function (event) &#123; //校验函数是否合法 var checkMessage = function () &#123; // 只获取需要的域，并非所有都可以跨域 if (event.origin != "need domain") &#123; return false; &#125; var message = event.data; // 传输数据类型校验 if (typeof(message) !== 'object') &#123; return false; &#125; // message 的rule中包含xxx则为xxx需要字段。 return message.rule === "xxx"; &#125;; if (checkMessage()) &#123; // 通过校验进行相关操作 addDetailFunc(event); &#125; &#125;); 【转载请注明：postMessage处理iframe 跨域问题 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[YII2数据库查询实践]]></title>
      <url>%2F2016%2F01%2F10%2FYII2%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E5%AE%9E%E8%B7%B5%2F</url>
      <content type="text"><![CDATA[初探yii2框架，对增删改查，关联查询等数据库基本操作的简单实践。 数据库配置。/config/db.php 进行数据库配置配置可以参考 yii文档 实践过程中有个test库-》test表-》两条记录如下12345678mysql&gt; select * from test;+----+--------+| id | name |+----+--------+| 1 | zhuai || 2 | heng | +----+--------+18 rows in set (0.00 sec) sql 查询方式yii2 提供了原始的数据库查询方式findBySql；同时，通过占位符的方式，自动进行了基本的sql注入防御。上码123456789101112131415// 最基本的查询方式$sql = "select * from test where 1";$res = Test::findBySql($sql)-&gt;all();var_dump(count($res)); // res-&gt;2 // findbysql 防止sql注入方式$id = '1 or 1=1';$sql = "select * from test where id = " . $id;$res = Test::findBySql($sql)-&gt;all();var_dump(count($res)); // res-&gt; 2$sql = "select * from test where id = :id";// 定位符会自动防止sql 注入$res = Test::findBySql($sql,array(":id"=&gt;$id))-&gt;all();var_dump(count($res)); // res-&gt;1 activeRecord查询方式每个框架除了原有的sql方式，都会提供相应的封装的查询方式，yii2亦然。 创建modelyii的model基本方式如下，代码如下不赘述。123456789101112131415161718192021222324&lt;?phpnamespace app\models;use Yii;use yii\db\ActiveRecord;class Test extends ActiveRecord&#123; // 可无，对应表：默认类名和表名匹配，则无需此函数 public static function tableName() &#123; return 'test'; &#125; // 可无，验证器：主要用于校验各个字段 public function rules()&#123; return [ ['id', 'integer'], ['name', 'string', 'length' =&gt; [0, 100]], ]; &#125;&#125; 使用的时候需要引入model1use app\models\Test; 增加操作1234567891011// add 操作$test = new Test();$test-&gt;name = 'test';// 合法性校验$test-&gt;validate();if($test-&gt;hasErrors())&#123; echo "数据不合法"; die;&#125;$test-&gt;save(); 查询操作查询操作先上官方文档 activeRecord doc where doc需要强调的是：yii查询提供了特别多丰富的库，例如代码中的批量查询处理等等，细节可以看文档。 1234567891011121314151617181920212223242526// select// id = 1$res = Test::find()-&gt;where(['id' =&gt; 1])-&gt;all();var_dump(count($res)); //1// id &gt; 0$res = Test::find()-&gt;where(['&gt;','id',0])-&gt;all();var_dump(count($res)); //2// id &gt; =1 id &lt;=2$res = Test::find()-&gt;where(['between','id',1,2])-&gt;all();var_dump(count($res)); //2// name字段like$res = Test::find()-&gt;where(['like', 'name', 'cuihuan'])-&gt;all();var_dump(count($res)); //2// 查询的使用 obj-&gt;array$res = Test::find()-&gt;where(['between','id',1,2])-&gt;asArray()-&gt;all();var_dump($res[0]['id']); //2// 批量查询,对于大内存操作的批量查询foreach (Test::find()-&gt;batch(1) as $test) &#123; var_dump(count($test));&#125; 删除操作1234567// delete // 选出来删除$res = Test::find()-&gt;where(['id'=&gt;1])-&gt;all();$res[0]-&gt;delete();// 直接删除var_dump(Test::deleteAll('id&gt;:id', array(':id' =&gt; 2))); 修改操作除了代码中方式，yii2直接提供update操作。1234// 活动记录修改$res = Test::find()-&gt;where(['id'=&gt;4])-&gt;one();$res-&gt;name = "update";$res-&gt;save(); 关联查询操作关联查询示例中两个表:一个学生表(student):id ，name;一个分数表(score)：id,stu_id,score123456789// 相应学生的所有score$stu = Student::find()-&gt;where(['name'=&gt;'xiaozhuai'])-&gt;one();var_dump($stu-&gt;id);// 基本获取$scores_1 = $stu-&gt;hasMany('app\model\Score',['stu_id'=&gt;$stu-&gt;id])-&gt;asArray()-&gt;all();$scores_2 = $stu-&gt;hasMany(Score::className(),['stu_id'=&gt;'id'])-&gt;asArray()-&gt;all();var_dump($scores_1);var_dump($scores_2); 两种关联查询方式；但是，在controller进行相关操作，代码显的过于混乱，在model中封装调用 首先在student model中封装相关关联调用函数123456789101112131415161718192021222324&lt;?phpnamespace app\models;use Yii;use yii\db\ActiveRecord;class Student extends ActiveRecord&#123; public static function tableName() &#123; return 'student'; &#125; // 获取分数信息 public function getScores() &#123; $scores = $this-&gt;hasMany(Score::className(), ['stu_id' =&gt; 'id'])-&gt;asArray()-&gt;all(); return $scores; &#125;&#125; 之后直接调用，两种调用方式1234567// 函数封装之后调用$scores = $stu-&gt;getScores();var_dump($scores);// 利用__get 的自动调用的方式$scores = $stu-&gt;scores;var_dump($scores); 最后上面在yii2的部署和使用过程中的一些基本的增删改查，关联查询等操作。但是如果想要将yii2的db操作使用好，还要看文档大法： activeRecord doc 【转载请注明：YII2数据库查询实践 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器多次恶意提交攻击简单防范]]></title>
      <url>%2F2016%2F01%2F07%2F%E6%9C%BA%E5%99%A8%E5%A4%9A%E6%AC%A1%E6%81%B6%E6%84%8F%E6%8F%90%E4%BA%A4%E6%94%BB%E5%87%BB%2F</url>
      <content type="text"><![CDATA[先说背景：机器不断的发送请求或者恶意提交，会给服务器造成很大压力；针对这种攻击最优的策略是判断提交次数，产生动态验证码，即判断ip规定时间内重复发送达到N次弹出验证码。下面是小拽在实践过程中一个简单的识别ip，利用session记录和防御的过程。 识别和校验ip过程如下； 识别ip ip属于白名单直接通过[白名单策略：内网ip+指定ip表] 利用session存储ip的请求时间戳 校验规定时间内ip的请求次数 采取相应的措施 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 获取和校验ip；同时防止短时间内多次提交 * * @notice ：弹出验证码，需要替换掉echo $echo_str 即可。 * @return string ：返回校验成功的ip */protected function getAndCheckIP()&#123; // 获取环境ip if (getenv("HTTP_CLIENT_IP") &amp;&amp; strcasecmp(getenv("HTTP_CLIENT_IP"), "unknown")) $ip = getenv("HTTP_CLIENT_IP"); else if (getenv("HTTP_X_FORWARDED_FOR") &amp;&amp; strcasecmp(getenv("HTTP_X_FORWARDED_FOR"), "unknown")) $ip = getenv("HTTP_X_FORWARDED_FOR"); else if (getenv("REMOTE_ADDR") &amp;&amp; strcasecmp(getenv("REMOTE_ADDR"), "unknown")) $ip = getenv("REMOTE_ADDR"); else if (isset($_SERVER['REMOTE_ADDR']) &amp;&amp; $_SERVER['REMOTE_ADDR'] &amp;&amp; strcasecmp($_SERVER['REMOTE_ADDR'], "unknown")) $ip = $_SERVER['REMOTE_ADDR']; else $ip = "unknown"; // check 环境ip if (!$this-&gt;isWhiteList($ip)) &#123; $echo_str = "提交过于频繁,请稍后再试！"; // 构建ip的时间栈数据 if (!is_array($_SESSION[$ip])) &#123; $_SESSION[$ip] = array(); &#125; if (isset($_SESSION[$ip][0])) &#123; $_SESSION[$ip][] = time(); // session 保存时间为6小时。清理session $post_interval_first = time() - $_SESSION[$ip][0]; if ($post_interval_first &gt; 21600) &#123; $_SESSION[$ip] = array(); &#125; // 两次提交小于1s，禁止提交 $post_interval_pre = time() - $_SESSION[$ip][count($_SESSION[$ip]) - 3]; if ($post_interval_pre &lt; 1) &#123; echo $echo_str; exit; &#125;; // 您在10s内已经提交了3请求，禁止提交 $post_interval_third = time() - $_SESSION[$ip][count($_SESSION[$ip]) - 3]; if (isset($_SESSION[$ip][3]) &amp;&amp; ($post_interval_third &lt; 10)) &#123; echo $echo_str; exit; &#125; // 您在1分钟期间已经提交了5请求，禁止提交 $post_interval_fifth = time() - $_SESSION[$ip][count($_SESSION[$ip]) - 3]; if (isset($_SESSION[$ip][5]) &amp;&amp; ($post_interval_fifth &lt; 60)) &#123; echo $echo_str; exit; &#125; // 6小时内提交10次，禁止提交 if (isset($_SESSION[$ip][10])) &#123; echo $echo_str; exit; &#125; &#125; else &#123; $_SESSION[$ip][] = time(); &#125; &#125; return ($ip);&#125; 白名单策略白名单策略采用：内网ip放行和特定ip放行1234567891011121314151617/** * 检验是否存在于白名单中 * * @param $ip ：校验的ip * @return bool ：校验结果 */function isWhiteList($ip)&#123; /** * 内网ip默认全部存在于白名单中 */ if(!filter_var($ip, FILTER_VALIDATE_IP, FILTER_FLAG_NO_PRIV_RANGE | FILTER_FLAG_NO_RES_RANGE))&#123; return true; &#125; // 是否在写死的whitelist 里面 return in_array($ip,$this-&gt;_WHTTE_LIST);&#125; 防攻击策略小拽采用的比较简单的策略，如上面代码，实际过程中可以结合业务需求。 1s内禁止重复提交 5s内提交上限3次 60s内提交上限5次 6小时内提交上限10次 【转载请注明：机器多次恶意提交攻击简单防范 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[检验mysql主从备份，读写分离]]></title>
      <url>%2F2016%2F01%2F03%2F%E6%A3%80%E9%AA%8Cmysql%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD%EF%BC%8C%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
      <content type="text"><![CDATA[先说背景：mysql的主从部署，读写分离，负载均衡之后；需要简单测试和校验一下，在实践中写了个简单的php脚本和校验过程，mark一下，方便再次部署校验。 数据库部署和实践数据库在实践中，往往需要进行多机主从备份保证安全，这个毋庸置疑；进行读写分离和负载均衡可以极大的提升mysql的读写性能。作者在实践中采用阿里的ameoba进行了读写分离和负载均衡操作。细节步骤参考小拽文章: mysql主从备份，读写分离和负载均衡实践 那么问题来了，部署完了，校验也需慎重，下面是简单的校验过程。 php简单读写库脚本上码：能用代码说的，最好不用文字说话！1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?php/** * 进行读写分离的校验 * @notice ：需要关闭主从备份的情况下进行 * 原理：打开主从，写主库，从库获取数据，校验主从备份；关闭主从写ameoba,校验读写分离和负载 * * @author: cuixiaohuan * Date: 15/12/29 * Time: 下午9:10 */class ReadAndWriteTest &#123; // ameoba 设定端口,校验读写时，放主库配置 const IP ="ip:port"; const PWD ="pwd"; const USER ="user"; const DB ="db"; public function __construct()&#123; error_reporting(E_ALL ^ E_DEPRECATED); $this-&gt;initDb(); $this-&gt;_writeTest(); $this-&gt;_selectTest(); &#125; /** * 进行10次读操作 */ public function _selectTest()&#123; for ($i = 0; $i &lt; 10; $i++) &#123; $read_sql = 'select * from test limit 10'; $g_result = mysql_query($read_sql); var_dump($g_result); mysql_free_result($g_result); &#125; &#125; /** * 进行10次写操作 */ public function _writeTest()&#123; for ($i = 0; $i &lt; 10; $i++) &#123; $id = uniqid(); $content = "pingce" . uniqid(); $write_sql = 'INSERT INTO `test`(`test`, `test1`) VALUES ("' . $id . '","' . $content . '")'; $g_result = mysql_query($write_sql); var_dump($g_result); &#125; &#125; /** * 初始化数据库连接信息 info */ private function initDb() &#123; $crowd_conn = mysql_pconnect(self::IP, self::USER, self::PWD); if (!$crowd_conn) &#123; die("Could not connect:" . mysql_error()); &#125; $crowd_db = mysql_select_db(self::DB, $crowd_conn); &#125;&#125;$rw = new ReadAndWriteTest(); 主从备份校验 开启slave 调整数据库信息为mysql，主库信息，运行脚本。 查看从库的log，有如下写入操作，说明实时主从备份成功。1234567891011121314151617181920212223242526272829303132151231 15:36:21 4 Query start slave14 Connect Out pingce@10.95.112.120:366615 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e5c85","pingce5684d957e5cf2")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e7937","pingce5684d957e7982")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e8e96","pingce5684d957e8ee4")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ea2c2","pingce5684d957ea2eb")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eb565","pingce5684d957eb5b3")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ec7ee","pingce5684d957ec83e")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eda2f","pingce5684d957eda78")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eeca4","pingce5684d957eecf0")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eff16","pingce5684d957eff61")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957f121e","pingce5684d957f126d")15 Query COMMIT /* implicit, from Xid_log_event */ 检验读写分离 读写分离，首先需要关闭从机器上的slave。原因：存在主从的话，无法通过log查看出读写分离操作。 12mysql&gt; stop slave;Query OK, 0 rows affected (0.08 sec) 运行脚本：如下信息标示，运行成功。 123456789101112131415161718192021[cuixiaohuan TestScript]$ /home/work/lamp/php5/bin/php ReadAndWriteTest.phpINSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e5c85","pingce5684d957e5cf2")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e7937","pingce5684d957e7982")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e8e96","pingce5684d957e8ee4")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ea2c2","pingce5684d957ea2eb")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eb565","pingce5684d957eb5b3")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ec7ee","pingce5684d957ec83e")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eda2f","pingce5684d957eda78")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eeca4","pingce5684d957eecf0")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eff16","pingce5684d957eff61")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957f121e","pingce5684d957f126d")bool(true)resource(5) of type (mysql result)resource(6) of type (mysql result)resource(7) of type (mysql result)resource(8) of type (mysql result)resource(9) of type (mysql result)resource(10) of type (mysql result)resource(11) of type (mysql result)resource(12) of type (mysql result)resource(13) of type (mysql result)resource(14) of type (mysql result) 查询读写库的log 解释：之所以主库放一个读写库，是因为有些要求超高一致性的数据，备份可能会有延迟；所以，主库承担读写操作，和高负载。 1234567891011121314151617#读写机器log： 进行了10次写和 四次读151231 15:29:27 19 Query set names gbk^@19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e5c85","pingce5684d957e5cf2")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e7937","pingce5684d957e7982")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e8e96","pingce5684d957e8ee4")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ea2c2","pingce5684d957ea2eb")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eb565","pingce5684d957eb5b3")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ec7ee","pingce5684d957ec83e")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eda2f","pingce5684d957eda78")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eeca4","pingce5684d957eecf0")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eff16","pingce5684d957eff61")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957f121e","pingce5684d957f126d")19 Query select * from test limit 10151231 15:29:28 19 Query select * from test limit 1019 Query select * from test limit 1019 Query select * from test limit 1019 Query select * from test limit 10 查看读库的log 123456789# 只进行了读操作，校正了数据库的读写分离操作。151231 15:29:20 4 Query stop slave151231 15:29:27 3 Query set names gbk^@3 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 10 最后一句话：打开slave，校验主从备份；关闭slave，校验读写分离。 【转载请注明： 检验mysql主从备份，读写分离 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php反射调用private方法实践]]></title>
      <url>%2F2015%2F12%2F20%2Fphp%E5%8F%8D%E5%B0%84%E8%B0%83%E7%94%A8private%E6%96%B9%E6%B3%95%E5%AE%9E%E8%B7%B5%2F</url>
      <content type="text"><![CDATA[问题背景：单测中有个普遍性的问题，被侧类中的private方法无法直接调用。小拽在处理过程中通过反射改变方法权限，进行单测，分享一下，直接上代码。 简单被测试类生成一个简单的被测试类，只有个private方法。 1234567891011121314151617181920212223242526&lt;?php/** * 崔小涣单测的基本模板。 * * @author cuihuan * @date 2015/11/12 22:15:31 * @version $Revision:1.0$ **/class MyClass &#123; /** * 私有方法 * * @param $params * @return bool */ private function privateFunc($params)&#123; if(!isset($params))&#123; return false; &#125; echo "test success"; return $params; &#125;&#125; 单测代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?php/*************************************************************************** * * $Id: MyClassTest T,v 1.0 PsCaseTest cuihuan Exp$ * **************************************************************************//** * 崔小涣单测的基本模板。 * * @author cuihuan * @date 2015/11/12 22:09:31 * @version $Revision:1.0$ **/require_once ('./MyClass.php');class MyClassTest extends PHPUnit_Framework_TestCase &#123; const CLASS_NAME = 'MyClass'; const FAIL = 'fail'; protected $objMyClass; /** * @brief setup: Sets up the fixture, for example, opens a network connection. * * 可以看做phpunit的构造函数 */ public function setup() &#123; date_default_timezone_set('PRC'); $this-&gt;objMyClass = new MyClass(); &#125; /** * 利用反射，对类中的private 和 protect 方法进行单元测试 * * @param $strMethodName string ：反射函数名 * @return ReflectionMethod obj ：回调对象 */ protected static function getPrivateMethod($strMethodName) &#123; $objReflectClass = new ReflectionClass(self::CLASS_NAME); $method = $objReflectClass-&gt;getMethod($strMethodName); $method-&gt;setAccessible(true); return $method; &#125; /** * @brief :测试private函数的调用 */ public function testPrivateFunc() &#123; $testCase = 'just a test string'; // 反射该类 $testFunc = self::getPrivateMethod('privateFunc'); $res = $testFunc-&gt;invokeArgs($this-&gt;objMyClass, array($testCase)); $this-&gt;assertEquals($testCase, $res); $this-&gt;expectOutputRegex('/success/i'); // 捕获没有参数异常测试 try &#123; $testFunc-&gt;invokeArgs($this-&gt;transfer2Pscase, array()); &#125; catch (Exception $expected) &#123; $this-&gt;assertNotNull($expected); return true; &#125; $this-&gt;fail(self::FAIL); &#125; &#125; ##运行结果1234567cuihuan:test cuixiaohuan$ phpunit MyClassTest.php PHPUnit 4.8.6 by Sebastian Bergmann and contributors.Time: 103 ms, Memory: 11.75MbOK (1 test, 3 assertions) 关键代码分析封装了一个，被测类方法的反射调用；同时，返回方法之前处理方法的接入权限为true，便可以访问private的函数方法。123456789101112/** * 利用反射，对类中的private 和 protect 方法进行单元测试 * * @param $strMethodName string ：反射函数名 * @return ReflectionMethod obj ：回调对象 */protected static function getPrivateMethod($strMethodName) &#123; $objReflectClass = new ReflectionClass(self::CLASS_NAME); $method = $objReflectClass-&gt;getMethod($strMethodName); $method-&gt;setAccessible(true); return $method;&#125; 【转载请注明：phpunit单测中调用private方法处理 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql 简单全量备份和快速恢复]]></title>
      <url>%2F2015%2F12%2F11%2Fmysql%20%E7%AE%80%E5%8D%95%E5%85%A8%E9%87%8F%E5%A4%87%E4%BB%BD%E5%92%8C%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%2F</url>
      <content type="text"><![CDATA[一个简单的mysql全量备份脚本，备份最近15天的数据。 备份1234#每天备份mysql数据库(保存最近15天的数据脚本)DATE=$(date +%Y%m%d)/home/cuixiaohuan/lamp/mysql5/bin/mysqldump -uuser -ppassword need_db &gt; /home/cuixiaohuan/bak_sql/mysql_dbxx_$DATE.sql;find /home/cuixiaohuan/bak_sql/ -mtime +15 -name '*.sql' -exec rm -rf &#123;&#125; \; 恢复mysql 数据导入12drop databases need_db;create databases need_db; 导入数据：必须设定编码进行恢复1./mysql -uroot -p --default-character-set=utf8 need_db &lt; xx.sql 【转载请注明：mysql 简单全量备份和快速恢复 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux 查找清理大文件]]></title>
      <url>%2F2015%2F12%2F08%2Flinux%20%E6%9F%A5%E6%89%BE%E6%B8%85%E7%90%86%E5%A4%A7%E6%96%87%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[linux 经常硬盘空间不足，往往是由于一些大文件造成；之前寻找大文件总是很头疼，速度特别慢。经学弟介绍使用：du -sh * |grep G 查找和清理速度不错，分享一下清理过程。 查看系统存储状态1234[cuihuan:~ cuixiaohuan]$ df -hFilesystem Size Used Avail Use% Mounted on/dev/sda2 8.2G 6.7G 1.6G 82% //dev/sda3 1.4T 1.3T 50G 97% /home 1.5T的硬盘占用了97%，确实不够用了，必须着手清理一下 查找大文件主要使用查找命令：du -sh * |grep G从根文件开始查找1234567[cuihuan:~]$ du -sh * | grep G。。。73G mongodb103G mxm2.1G online613G thirdparty [binggo!!!]。。。 bingo 613g，看来这个主要矛盾了，进一步分析该文件 1234567891011121314151617181920[cuihuan:~ mysql5]$ du -sh *116M bin904K include13M lib17M libexec458G log [-__]8.0K my.cnf76M mysql-test13M share2.9M sql-bench4.0K test4.0K tmp101G var [-_-][cuihuan:~ mysql5]$ cd log[cuihuan:~ log]$ ls -lhtotal 458G-rw-rw---- 1 work work 870K Dec 2 17:42 mysql.err-rw-rw---- 1 work work 3.9K Mar 24 2015 mysql.err-old-rw-rw---- 1 work work 446G Dec 3 15:19 mysql.log 【-__】-rw-rw---- 1 work work 11G Dec 3 15:10 slow.log 经过分析看到mysql.log的日志占了446G,着手清理下。【mysql log 好的保存方式是：天级导出，清理n天之前的log，此处不再赘述】 清理之后效果清理 mysql.log 和var 之后清理了大约500g的空间1234[cuihuan:~ var]$ df -h Filesystem Size Used Avail Use% Mounted on/dev/sda2 8.2G 6.7G 1.6G 82% //dev/sda3 1.4T 757G 584G 57% /home 【转载请注明：linux 查找清理大文件 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[echarts动态获取数据实例]]></title>
      <url>%2F2015%2F12%2F06%2Fecharts%E5%8A%A8%E6%80%81%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%BE%8B%2F</url>
      <content type="text"><![CDATA[echarts动态获取数据库的实时数据的简单实例。实例演示： 跳转demo 引入echarts 文件。引入echarts的文件方式有多种，比较推荐模块化的引入方式。小拽的简单demo是直接引入文件，提供一个下载地址 ： 点击下载 html 部分代码一块div 用于echart的展现。1&lt;div id="echart_show" style="height:500px"&gt;这里是一个布局展现&lt;/div&gt; js 部分代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167$(document).ready(function () &#123; // 绘制反馈量图形 var init_echarts = function () &#123; var refreshChart = function (show_data) &#123; my_demo_chart = echarts.init(document.getElementById('echart_show')); my_demo_chart.showLoading(&#123; text: '加载中...', effect: 'whirling' &#125;); var echarts_all_option = &#123; title: &#123; text: '动态数据', subtext: '纯属虚构' &#125;, tooltip: &#123; trigger: 'axis' &#125;, legend: &#123; data: ['最新成交价', '预购队列'] &#125;, toolbox: &#123; show: true, feature: &#123; mark: &#123;show: true&#125;, dataView: &#123;show: true, readOnly: false&#125;, magicType: &#123;show: true, type: ['line', 'bar']&#125;, restore: &#123;show: true&#125;, saveAsImage: &#123;show: true&#125; &#125; &#125;, dataZoom: &#123; show: false, start: 0, end: 100 &#125;, xAxis: [ &#123; type: 'category', boundaryGap: true, data: (function () &#123; var now = new Date(); var res = []; var len = 10; while (len--) &#123; res.unshift(now.toLocaleTimeString().replace(/^\D*/, '')); now = new Date(now - 2000); &#125; return res; &#125;)() &#125;, &#123; type: 'category', boundaryGap: true, data: (function () &#123; var res = []; var len = 10; while (len--) &#123; res.push(len + 1); &#125; return res; &#125;)() &#125; ], yAxis: [ &#123; type: 'value', scale: true, name: '价格', boundaryGap: [0.2, 0.2] &#125;, &#123; type: 'value', scale: true, name: '预购量', boundaryGap: [0.2, 0.2] &#125; ], series: [ &#123; name: '预购队列', type: 'bar', xAxisIndex: 1, yAxisIndex: 1, // 获取到数据库的数据 data: show_data[0] &#125;, &#123; name: '最新成交价', type: 'line', // 实时获取的数据 data:show_data[1] &#125; ] &#125;; my_demo_chart.hideLoading(); my_demo_chart.setOption(echarts_all_option); &#125;; // 获取原始数据 $.ajax(&#123; url: "http://cuihuan.net:1015/demo_file/echarts_realtime_demo/get_data.php", data: &#123;type: "2"&#125;, success: function (data) &#123; // 根据数据库取到结果拼接现在结果 refreshChart(eval(data)); &#125; &#125;); &#125;; // 开启实时获取数据更新 $("#getData").on("click",function() &#123; var timeTicket; var lastData = 11; var axisData; clearInterval(timeTicket); timeTicket = setInterval(function () &#123; // 获取实时更新数据 $.ajax(&#123; url: "http://cuihuan.net:1015/demo_file/echarts_realtime_demo/get_data.php", data: &#123;type: "new"&#125;, success: function (data) &#123; // 根据条件转换成相应的api 转化为echart 需要的数据 // todo 更新数据采用随机更新的方式 lastData += Math.random() * ((Math.round(Math.random() * 10) % 2) == 0 ? 1 : -1); lastData = lastData.toFixed(1) - 0; axisData = (new Date()).toLocaleTimeString().replace(/^\D*/, ''); // 动态数据接口 addData my_demo_chart.addData([ [ 0, // 系列索引 Math.round(Math.random() * 1000), // 新增数据 true, // 新增数据是否从队列头部插入 false // 是否增加队列长度，false则自定删除原有数据，队头插入删队尾，队尾插入删队头 ], [ 1, // 系列索引 lastData, // 新增数据 false, // 新增数据是否从队列头部插入 false, // 是否增加队列长度，false则自定删除原有数据，队头插入删队尾，队尾插入删队头 axisData // 坐标轴标签 ] ]); &#125; &#125;); &#125;, 2100); // 关闭更新操作 $("#stopData").on("click", function () &#123; clearInterval(timeTicket); &#125;); &#125;); // 默认加载 var default_load = (function () &#123; init_echarts(); &#125;)();&#125;); php 部分代码123456789101112131415161718192021222324252627282930313233343536/** * 连接数据库获取数据 * * User: cuixiaohuan * Date: 15/12/4 * Time: 下午6:47 */// 获取请求的类型$type = $_GET['type'];// 连接服务器$link = mysql_connect('ip:port', 'user', 'password');if (!$link) &#123; die("Could not connect:" . mysql_error());&#125;// 获取test库数据$crowd_db = mysql_select_db('test', $link);$day_time = date("Y-m-d");// 根据传输过来的数据获取数据$static_sql = "select v from test where id = " . $type . " limit 10";// 获取数据之后返回$res = mysql_query($static_sql, $link_2004);if ($res) &#123; // 将结果进行入库操作 $row = mysql_fetch_row($res); if($row[0])&#123; echo $row[0]; &#125; mysql_free_result($res);&#125; 简单说明小拽的demo中，根据echarts的api，绘制出了原有的图形展示；之后，对js设置了个定时任务，实时的去获取数据库中可能新入库的数据，接口通过php简单调用数据库实现。 小拽个人小站]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【wordpress优化】压缩和使用静态缓存]]></title>
      <url>%2F2015%2F12%2F06%2F%E3%80%90wordpress%E4%BC%98%E5%8C%96%E3%80%91%E5%8E%8B%E7%BC%A9%E5%92%8C%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81%E7%BC%93%E5%AD%98%2F</url>
      <content type="text"><![CDATA[先说背景：wordpress个人网站，整体性能挺不错；但是，由于采用php动态获取数据，构成页面的方式，势必会影响页面加载速度。对于一些最常用的页面[例如首页]等等，完全可以采用生成伪静态页面缓存的方式加载。 针对现有的缓存方式调研了一下：本文使用wp super cache进行了优化，提升加载速度200%以上。 无图无真想，先看效果针对相同页面在chrome下做了个加载时间，大小的对比，如下图 优化前数据：23ms感知页面；3.62s加载完成；页面大小：419k；请求个数：25个； 优化后数据：106ms感知页面；1.81s加载完成；页面大小13.9k；请求个数24个； 效果不错，后文做个详细分析。 了解 wp super cache wp super cache 是wordpress的一种缓存优化插件，本质是利用缓存机制提升页面加载速度。实现原理: php最终在前端展现时需要转换为html，然后获取响应的数据；wp super cache 则提前将php文件转换为的html伪静态文件进行存储，一旦发生请求，直接返回生成的页面；减少了数据库取数据，转换等过程，来增加加载速度。优 点: 增加了加载速度。缺 点: 增加了存储成本，而且要不断的更新，如果用户量大，个人感觉存储和离线成本增加会挺多。 安装 wp super cache官网下载地址： http://z9.io/wp-super-cache/ 【无法翻墙可参考小拽博文： 不翻墙，下载wordpress官方主题和插件小技巧 】 注意：安装wp super cache 需要设定固定连接 如下图推荐采用【自定义结果】：http://cuihuan.net/article/%postname%.html原因在于其他包含字母或者日期不太容易表意，也不利于阅读和seo等等。 如果最初采用的是http://xxx/?p=xxx的方式，需要对服务器进行相关设置，否则会一直出现404。解决和设置办法，在另一篇文章中，此处不赘述（[wp super cache 安装和问题解决](http://cuihuan.net/article/wp%20super%20cache%20%E5%AE%89%E8%A3%85%E5%92%8C%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3.html)）。 安装成功后，后台设置中会出现wp super cache 配置 wp super cache安装成功后的简单个人推荐设置。 通用-》启用cache：开启高级-》启用缓存：开启高级-》模式选择：推荐mode_rewrite 这个需要apache或者nginx进行相关设置，这个速度最快；如果不想设置，可以选择php缓存模式。高级-》压缩页面：必选。高级-》页面更新清除，评论更新清楚：推荐。作用是更新文章，评论之后触发缓存更新。高级-》移动支持：推荐。其他一些设置根据个人需求增加。 配置，更新之后，进入网站cache目录下会出现缓存的html文件和gzip的压缩文件（前提是设置了giz压缩）。 123456[root@cuixiaohuan cuihuan.net]# pwdxxx/wp-content/cache/supercache/cuihuan.net[root@cuixiaohuan cuihuan.net]# ls -lhtotal 52K-rw-r--r-- 1 apache apache 40K Dec 5 11:33 index.html-rw-r--r-- 1 apache apache 9.5K Dec 5 11:33 index.html.gz 效果分析优化前数据：23ms感知页面；3.62s加载完成；页面大小：419k；请求个数：25个；优化后数据：106ms感知页面；1.81s加载完成；页面大小13.9k；请求个数24个； 感知页面变慢：原因在于，原始php页面相对较小，传输也相对较快，传输基本框架之后，才进行页面dom绘制，js渲染，数据获取和再次渲染，所以感知时间原始的快。但是对于750ms以下的对于用户几乎都是无感知。 加载完成变快：最主要达到的效果，节省最多的时间在于数据库获取数据的时间。 页面大小变小：这块小的有点出乎意外，小是应该的，但是小这么多就有点🐂了；之后分析了下页面，可能和文章异步获取，存储的html只获取了部分页面的文章，同时，对jquery等等组件肯定是利用缓存，不计入数据大小了。 请求数目变化不大。 整体效果：加载快了，页面小了。 【转载请注明：【wordpress优化】压缩和使用静态缓存 | 靠谱崔小拽 】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[crontab 误删除恢复]]></title>
      <url>%2F2015%2F12%2F03%2Fcrontab%20%E8%AF%AF%E5%88%A0%E9%99%A4%E6%81%A2%E5%A4%8D%2F</url>
      <content type="text"><![CDATA[操作过程中：crontab被全部干掉了，利用log恢复过程记录。 事故原因分析：回忆自己操作过程中，未进行crontab的清空，网上查了下原因，并且复现了下。可能原因如下： 如果在SSH远程终端中敲下“crontab”命令之后，远程连接被一些原因（比如 糟糕的网络，程序异常）意外终止了，那么Crontab计划任务就会被操作系统所清空。听起来很不可思议，但是经过在虚拟机上的多次测试，它确确实实的发生了。测试方式为 用SecureCRT开一个SSH窗口，然后敲下命令“crontab”，接着在“任务管理器”中直接杀掉SecureCRT进程，再通过另外一个SSH窗口执行“crontab -l”，就会发现，所有的计划任务都不存在了。在今天事故发生的时间点上，就有人在服务器上遇到了这样的情况。 恢复操作 获取完整日志和cmd日志。从日志中恢复出一份最近几天的完整crontab 运行日志和cmd日志，并存储，用于之后完善和核准例行时间。 12cat /var/log/cron | grep -i "`which cron`" &gt; ./all_tempcat ./all_temp | grep -v "&lt;command&gt;” &gt; ./cmd_temp 获取所有crontab指令。从日志中恢复一份去重的crontab log。【相当于所有的crontab命令】 1awk -F'(' '/crond/&#123;a[$3]=$0&#125;END&#123;for(i in a)print a[i]&#125;' /var/log/cron* &gt;crontab.txt 手工恢复：从crontab.txt 中找出每一条指令，然后在cmd_temp 中匹配运行次数，重新编辑crontab 添加 反思工作防止类似事件再次发生，写个简单shell脚本，每天对crontab进行备份，备份最近15天的数据。过期清楚123456#!/bin/bash# 每天对crontab 进行备份 ，同时删除最近15天的数据DATE=$(date +%Y%m%d)crontab -l &gt; /home/work/bak/crontab_$DATE.bakfind /home/work/bak/ -mtime +15 -name '*.bak' -exec rm -rf &#123;&#125; \; 本人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[jsonp + php 跨域实例]]></title>
      <url>%2F2015%2F12%2F02%2Fjsonp%20%2B%20php%20%E8%B7%A8%E5%9F%9F%E5%AE%9E%E4%BE%8B%2F</url>
      <content type="text"><![CDATA[由于跨域的存在，使资源交互在不同域名间变的复杂和安全。对于跨域数据传输，当数据长度较小(get的长度内)，jsonp是一种较好的解决方案。 分享一个自己在jsonp使用过程中的demo。关于跨域可以参考：跨域总结与解决办法 jsonp的js端调用主要功能：通过jsonp向服务器，调用相应接口，获应数据；根据获取数据结果做出相应回调。 123456789101112131415161718192021222324252627282930313233343536/** * jsonp demo * 通过回调函数，进行获取之后的事件加载 * * @author:cuihuan * @private */_jsonpDemo:function(callback)&#123; $.ajax(&#123; url: "http://your_site_url", type: 'GET', dataType: 'JSONP', success: function (data) &#123; if (data &amp;&amp; data.status) &#123; if (data.status == "0") &#123; // failure solve ... &#125; else if (data.status == 500) &#123; // server error log _sendInternalLog(data.info); &#125; else if (data.status == 1) &#123; //success solve ... &#125; // callback func (callback &amp;&amp; typeof(callback) === "function" ) &amp;&amp; callback(); &#125; &#125;, error: function () &#123; _sendFailLog(); &#125; &#125;)&#125; jsonp 服务器端 (php)1234567891011121314151617181920212223242526/** * 接口返回相应数据 * * status: 0 标示失败，1标示成功,500发生错误 * return: jsonp */public function actionGetJsonPInfo()&#123; try &#123; $data = getNeedData() if ($data['status'] == "success") &#123; $res = array("status" =&gt; "1", 'info' =&gt; $data['info']); &#125;else&#123; $res = array("status" =&gt; "0", 'info' =&gt; '0'); &#125; &#125;catch (Exception $e)&#123; $res = array("status" =&gt; "500", 'info'=&gt; $e); &#125; // jsonp 通过get请求的返回数据形式 if (isset ($_GET['callback'])) &#123; header("Content-Type: application/json"); echo $_GET['callback']."(".json_encode($res).")"; &#125;&#125; 总结 目前来说，数据量小的跨域传输，jsonp是一种很好的解决方案。 jsonp在data中可以自动识别，res.status，res.info等状态位，比较方便。 php端的接受代码最好不要采用 Access-Control-Allow-Origin:* 风险太大。 本人小站原文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php 操作不同数据库]]></title>
      <url>%2F2015%2F11%2F30%2Fphp%20%E6%93%8D%E4%BD%9C%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
      <content type="text"><![CDATA[php脚本经常，处理处理不同机器上，不同数据库之间数据；而且脚本特别容易写错，抽取了个工作中最常用到的多库同步，特此记忆！ 上代码举个php操作不同数据库，进行数据同步的栗子。123456789101112131415161718192021222324252627282930313233343536373839/** * 同步库1的数据到库2 * * @author ：cuihuan * @date ：2015-10-11 */public function synchDbDiff()&#123; // 连接库1 $crowd_conn_1 = mysql_connect('ip_1:port_1', 'name_1', 'pw_1'); if (!$crowd_conn_1) &#123; die("Could not connect:" . mysql_error()); &#125; mysql_select_db('test_data', $crowd_conn_1); // 连接库2 $crowd_conn_2 = mysql_connect('ip_2:port_2', 'name_2', 'pw_2'); if (!$crowd_conn_1) &#123; die("Could not connect:" . mysql_error()); &#125; mysql_select_db('test_data', $crowd_conn_2); //获取未同步的数据 $get_data_sql = "SELECT `id`, `text` FROM `fb_conversation` WHERE `flag` = 1"; $c_result = mysql_query($get_data_sql, $crowd_conn_1); $this-&gt;check_res($c_result); if ($c_result) &#123; while ($row = mysql_fetch_array($c_result, MYSQL_NUM)) &#123; // 更新同步 $new_data_sql = "update from fb_conversation set text =" . $row[1] . " where id = " . $row[0]; $res = mysql_query($new_data_sql, $crowd_conn_2); $this-&gt;check_res($c_result); &#125; &#125;&#125; 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[phpUnit 安装，实例和简单部署]]></title>
      <url>%2F2015%2F11%2F28%2FphpUnit%20%E5%AE%89%E8%A3%85%EF%BC%8C%E5%AE%9E%E4%BE%8B%E5%92%8C%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2%2F</url>
      <content type="text"><![CDATA[背景：一个小脚本，保证稳定为主；所以试用了下phpunit，快捷方便 phpunit 的安装phpunit是一个轻量级的php单元测试框架，通过pear安装安装过程1234wget https://phar.phpunit.de/phpunit.pharchmod +x phpunit.pharsudo mv phpunit.phar /usr/local/bin/phpunitphpunit --version 成功之后显示如下:12cuihuan:~ cuixiaohuan$ phpunit --versionPHPUnit 4.8.6 by Sebastian Bergmann and contributors. 简单试用测试类集成框架 class PsCaseTest extends PHPUnit_Framework_TestCase{} 其中phpunit默认首先执行 setup默认最后执行 teardown 举个栗子：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?php/*************************************************************************** * * $Id: PsCaseTest,v 1.0 PsCaseTest cuihuan Exp$ * **************************************************************************//** * @file PsCaseTest.php * @author cuihuan * @date 2015/09/11 10:09:31 * @version $Revision:1.0$ * @brief pscase接口单元测试 * **/require_once dirname(__FILE__) . ('/PsCase.php');class PsCaseTest extends PHPUnit_Framework_TestCase&#123; /** * @var object pscase类 */ protected $pscase; /** * @brief setup: Sets up the fixture, for example, opens a network connection. * * This method is called before a test is executed. */ public function setup()&#123; $this-&gt;pscase = new PsCase(); &#125; /** * @brief teardown: Tears down the fixture, for example, closes a network connection. * * This method is called after a test is executed. */ public function teardown()&#123; &#125; /** * @brief : 测试config文件的获取 * */ public function testGetConfig() &#123; $this-&gt;assertEquals(true,$this-&gt;pscase-&gt;debugText("11")); &#125;&#125; 运行运行方式：phpunit —bootstrap [源文件] 测试文件具体如下：12345678cuihuande:newcode cuixiaohuan$ phpunit --bootstrap ./PsCase.php ./PsCaseTest.php32015-09-11 02:09:36:11&lt;br&gt;5Time: 116 ms, Memory: 11.75MbOK (1 test, 1 assertion) 【表示运行成功】 部署部署就不不赘述了，写个shell脚本，crontab天极运行，加个报警邮件，简单的单元测试ok，从此再也不用担心错误和回归测试了。 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[php 处理unicode解码]]></title>
      <url>%2F2015%2F11%2F28%2Fphp%20%E5%A4%84%E7%90%86unicode%E8%A7%A3%E7%A0%81%2F</url>
      <content type="text"><![CDATA[备忘：这个算是解码比较靠谱的，亲测。参考自stackoverflow，mark 分享 12345678910// change unicode to unt-8function replace_unicode_escape_sequence($match) &#123; return mb_convert_encoding(pack('H*', $match[1]), 'UTF-8', 'UCS-2BE');&#125;function unicode_decode($str) &#123; return preg_replace_callback('/u([0-9a-f]&#123;4&#125;)/i', 'replace_unicode_escape_sequence', $str); &#125;$str = unicode_decode('&#123;"u5173u952eu8bcd":[&#123;"","key":"u767eu5ea6"&#125;]&#125;'); 问题：使用过程中，遇到一个问题：就是当多次调用改函数的时候，出现错误。原因在于函数名方式调用问题。 如果编码是 \u5173\u952e\u8bcd 正则改为/\u([0-9a-f]{4})/i 即可 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【redis学习一】基本概念和基本操作]]></title>
      <url>%2F2015%2F11%2F28%2F%E3%80%90redis%E5%AD%A6%E4%B9%A0%E4%B8%80%E3%80%91%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[redis 基础官网地址： http://redis.io/ 基本介绍：redis 是一个ansi c编写，支持网络的，基于内存的可持久化的日执行，kv数据库；10年期redis有vmare主持开发。 支持数据类型：redis支持strings,hashes list set sorted等结构。 持久化：存储于内存或虚拟内存中，有两种持久化的方式： ：截图，内存数据不断写入硬盘【性能较高】 ：log：记录每次更新的日志。【稳定性好】 支持主从同步，性能非常优秀。提供多种语言的api 基本上知道的都有。 使用场景：(个人觉的可以有的使用场景)1：权限【权限每次都要入库校验，放在前端不靠谱，放在cache最合适】2：缓存【例如批量操作数据，可以先缓存】3：预取【例如topN数据,另外可能用到的数据，提前取出来，加快页面加载】4：构建消息队列【可以根据redis的数据结构list，构造；数据批量入库，加快页面相应等方面不错】。5：计数器【类似于批量入库的原理，可以计数，redis原子性的，可以精确支持】6：其他场景还在不断探索中。 安装和基本操作安装参考： http://www.runoob.com/redis/redis-install.html 基本操作： 官方文档地址 启动：./redis-server关闭：redis-cli shutdown12345678910111213141516171819202122232425[cuihuan bin]$ ./redis-cli shutdown[cuihuan bin]$ ./redis-server [325] 24 Sep 18:49:06.632 # Warning: no config file specified, using the default config. In order to specify a config file use ./redis-server /path/to/redis.conf _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 2.6.10 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in stand alone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 325 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' [325] 24 Sep 18:49:06.633 # Server started, Redis version 2.6.10[325] 24 Sep 18:49:06.633 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.[325] 24 Sep 18:49:06.673 * DB loaded from disk: 0.039 seconds[325] 24 Sep 18:49:06.673 * The server is now ready to accept connections on port 6379 安装成功的标志 redis-cli 可以成功进入 12[cuihuan bin]$ ./redis-cliredis 127.0.0.1:6379&gt; 注意：使用过程中如果是保密性高的数据，可以设置登录密码，增加安全想；但如果是简单数据，则可以不设置，优点就是速度稍快。 redis 基本配置：daemonize: yes 标示在后台运行bind：绑定请求的地址port：端口号，默认6379timeout:默认客户端连接超时 多长时间不操作关闭(默认永久，此处改为3600) loglevel: log等级databases：默认连接数据库的个数 【此处为8】slaveof 主从库 masterauth :密码验证requirepass:是否需要密码 maxclients :最大客户机个数 设置为10000maxmemory:最大内存个数 6625156 [机器内存32G,分配大约6g] 最基本的操作set name xxxget name xxxdel name xxxexists name xxx 举个栗子12345678910111213141516171819# get valredis 127.0.0.1:6379&gt; get name"cuixiaohuan"# set val redis 127.0.0.1:6379&gt; set name cuixiaohuan_2 OKredis 127.0.0.1:6379&gt; get name"cuixiaohuan_2"# check exists; if exists return 1redis 127.0.0.1:6379&gt; exists name(integer) 1# del valredis 127.0.0.1:6379&gt; del name(integer) 1redis 127.0.0.1:6379&gt; get name(nil) 其他常用操作：123456789101112131415# ping :check connectredis 127.0.0.1:6379&gt; pingPONG# dbsize :check sizeredis 127.0.0.1:6379&gt; dbsize(integer) 1#flush :clear dbredis 127.0.0.1:6379&gt; dbsize(integer) 1redis 127.0.0.1:6379&gt; flushdbOKredis 127.0.0.1:6379&gt; dbsize(integer) 0 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【redis学习二】多php版本下phpredis扩展安装]]></title>
      <url>%2F2015%2F11%2F28%2F%E3%80%90redis%E5%AD%A6%E4%B9%A0%E4%BA%8C%E3%80%91%E5%A4%9Aphp%E7%89%88%E6%9C%AC%E4%B8%8Bphpredis%E6%89%A9%E5%B1%95%E5%AE%89%E8%A3%85%2F</url>
      <content type="text"><![CDATA[背景：安装完redis之后，需要安装phpredis扩展，才能让php操作redis；本机有多个php版本，安装过程中遇到的坑分享一下。 ##一 下载git上下载redis的扩展包 git clone https://github.com/nicolasff/phpredis ##二 挂载和configure 在shell中输入 phpize 【注意：多个php版本的时候需要指定】 ./configure【phpize是用来扩展php扩展模块的，通过phpize可以建立php的外挂模块】 注意：（phpize 如果包含多个php，必须指定位置） cuihuan:phpredis cuixiaohuan$ ../php/bin/phpize Configuring for: PHP Api Version: 20121113 Zend Module Api No: 20121212 Zend Extension Api No: 220121212 Cannot find autoconf. Please check your autoconf installation and the $PHP_AUTOCONF environment variable. Then, rerun this script. 报错的话需要安装：brew install autoconf [phpize 报错] 否则没有phpize [work@cuixiaozhuai phpredis]$ ../php/bin/phpize Configuring for: PHP Api Version: 20041225 Zend Module Api No: 20060613 Zend Extension Api No: 220060519 [work@cuixiaozhuai phpredis]$ ./configure –with-php-config=/home/work/thirdparty/php5/bin/php-config 当存在多个版本的php的时候，需要指定配置文件 ./configure –with-php-config=/home/work/thirdparty/php5/bin/php-config ##三 编译和安装 make 之后最好make test make install cuihuan:phpredis cuixiaohuan$ make 。。。 Build complete. Don’t forget to run ‘make test’. cuihuan:phpredis cuixiaohuan$ make test cuihuan:phpredis cuixiaohuan$ make install ##四 问题修复【已修复，但是原因可能不太准确】make编译报错 .libs/redis_cluster.o(.data.rel.local+0x0): In function ht_free_seed&#39;: /home/work/thirdparty/php5/php5/phpredis/redis_cluster.c:226: multiple definition ofarginfo_scan’ .libs/redis.o(.data.rel.local+0xe0):/home/work/thirdparty/php5/php5/p hpredis/redis.c:452: first defined here /usr/bin/ld: Warning: size of symbol arginfo_scan&#39; changed from 160 in .libs/redis.o to 200 in .libs/redis_cluster.o .libs/redis_cluster.o(.data.rel.local+0xe0): In functioncreate_cluster_context’: /home/work/thirdparty/php5/php5/phpredis/redis_cluster.c:276: multiple definition of `arginfo_kscan’ .libs/redis.o(.data.rel.local+0x0):/home/work/thirdparty/php5/php5/phpredis/redis.c:364: first defined here collect2: ld returned 1 exit status make: * [redis.la] Error 1 最初以为是php多个版本生成install问题，采用./configure 指定php版本，指定php位置。但是效果还是有问题。最终通过修改redis_cluester.c 中，注释掉了这两个重复的 40 41 /* Argument info for HSCAN, SSCAN, HSCAN */ 42 /*ZEND_BEGIN_ARG_INFO_EX(arginfo_kscan, 0, 0, 2) 43 ZEND_ARG_INFO(0, str_key) 44 ZEND_ARG_INFO(1, i_iterator) 45 ZEND_ARG_INFO(0, str_pattern) 46 ZEND_ARG_INFO(0, i_count) 47 ZEND_END_ARG_INFO(); 48 */ 49 50 /* Argument infor for SCAN */ 51 /* 52 ZEND_BEGIN_ARG_INFO_EX(arginfo_scan, 0, 0, 2) 53 ZEND_ARG_INFO(1, i_iterator) 54 ZEND_ARG_INFO(0, str_node) 55 ZEND_ARG_INFO(0, str_pattern) 56 ZEND_ARG_INFO(0, i_count) 57 ZEND_END_ARG_INFO(); 58 */ ##五 简单测试 &lt;?php $redis = new Redis(); $conn = $redis-&gt;connect(&apos;127.0.0.1&apos;,6379); echo &quot;redis pass and status show&lt;/br&gt;&quot;; var_dump($redis-&gt;ping()); $redis-&gt;set(&apos;test_key&apos;,&apos;test_value&apos;); echo &quot;test set val=&quot;.$redis-&gt;get(&apos;test_key&apos;).&quot;&lt;/br&gt;&quot;; $redis-&gt;setnx(&apos;unique_key&apos;,&quot;unique_val&quot;); $redis-&gt;setnx(&apos;unique_key&apos;,&quot;unique_val_2&quot;); echo $redis-&gt;get(&quot;unique_key&quot;); sleep(60); echo &apos;is exist&apos;.$redis-&gt;exists(&apos;test_60s&apos;); echo &apos;not has value&apos;.$redis-&gt;get(&apos;test_60s&apos;); $redis-&gt;delete(&apos;test_key&apos;,&apos;test_60s&apos;); 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[canvas 生成和合并图片]]></title>
      <url>%2F2015%2F11%2F23%2Fcanvas_combine_pic%2F</url>
      <content type="text"><![CDATA[先说背景：工作中遇到一个问题，file组件上传图片，file是可以上传n张图片；但是，后台逻辑历史原因，只能展现一张。因此：考虑到成本，决定在前端将多张图片合并成一张给后端。 先上代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576_mergeImage2Canvas:function() &#123; // 获取file上传和展现的图片。一般file上传之后，有个小图标展现。 var imgs = $(".img_files"); if (!imgs) &#123; return false; &#125; // 创建原始图像 // 原因：file上传之后，展现往往是个缩略图，无法取到真正大小 for (var i = 0; i &lt; imgs.length; i++) &#123; var fbwImg = document.createElement("img"); var fbwImgID = "temp_img_id" + i; $("#" + fbwImgID).remove(); fbwImg.src = imgs[i].src; fbwImg.className = "temp-img-class"; // 不显示，仅供调用 fbwImg.style.display = "none"; // 临时区域扩展 $("#temp_section").append(fbwImg); &#125; // 合并原始图片，生成一个新的base64 图片 var getOriginImgBase64 = function (oriImgs) &#123; if (!oriImgs) &#123; return false; &#125; // 获取canvas的宽高 // 原因：canvas需要首先指定宽高，所以需要提前获取最终的宽高 var maxWidth = 0; var height = 0; for (var i = 0; i &lt; oriImgs.length; i++) &#123; var img = oriImgs[i]; if (img.width &gt; maxWidth) &#123; maxWidth = img.width; &#125; height += img.height; &#125; // 设定canvas var canvas = document.createElement("canvas"); canvas.width = maxWidth + 10; canvas.height = height + 10; var ctx = canvas.getContext("2d"); // 留5margin var dheight = 5; for (var j = 0; j &lt; oriImgs.length; j++) &#123; var img = oriImgs[j]; var cheight = img.height; var cwidth = img.width; // 留5 margin ctx.drawImage(img, 5, dheight, cwidth, cheight); dheight = dheight + cheight + 5; &#125; // 生成的base64 放在需要的一个全局变量中。 fbw_img_data = canvas.toDataURL('image/png'); // 清理 $(".temp_img_class").remove(); &#125;; // 之所以使用timer，考虑到dom树如果没有加载完成，会取到高度有误差 var imgTimer = null; imgTimer = setTimeout(function () &#123; getOriginImgBase64($(".temp_img_class")); if (imgTimer) &#123; clearTimeout(imgTimer); &#125; &#125;, 300);&#125; 合成效果图片一：小站logo 图片二：小图标： 合成效果： 原理简介主要是通过canvas 获取多个图片的base64编码，之后通过drawImage 函数合并和toDataUrl的方式合成。 问题思考 问题一：必须支持canvas，否则还需要后台统一跑脚本处理。 问题二：性能消耗过大。append img 和base64代码对dom的消耗都挺大，尤其是在移动端，很容易造成崩溃。解决办法：设定最大宽度，将图片等比缩放，这样子就少了向dom扩展元素这部分的损耗。 问题三：base64 在传输上性能消耗也挺大，没有file原生的好。 因此：出了必须前端搞定，最好的方式，还是在后台跑脚本运行合并。 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx实践一：centos apache更换为nginx]]></title>
      <url>%2F2015%2F11%2F18%2FNginx%E5%AE%9E%E8%B7%B5%E4%B8%80%EF%BC%9Acentos%20apache%E6%9B%B4%E6%8D%A2%E4%B8%BAnginx%2F</url>
      <content type="text"><![CDATA[背景介绍： 阿里云，512M内存（最屌丝配置），搭建lamp 环境，除去 mysql分配了100M左右（这个不能再少了），http竟然占用了200多M，太庞大，决定换为较轻量级，高并发的nginx。 背景数据如下图所示：系统也就500M ,出了mysql占用的100M, httpd 占了1/2 还多（经常达到十几个进程），剩余50M，有时更少不能忍，经常造成数据库崩掉，写了个自动重启脚本，但觉的不是治本之策 # 统计apache 进程个数 ps aux|grep httpd | wc –l 解决策略 1：针对Apache进行优化。包括优化worker运行方式等等。可以参考 apache优化 2 :更换轻量级服务器。采用nginx 或者lighthttpd等更轻量的服务器。传说中Nginx大法负载均衡和高并发略胜一筹，决定实践一把。 apache替换为nginx 1： 停掉apache sudo service httpd stop 注意：以防万一，最好不好提前卸掉。 2：安装nginx yum install nginx 3：启动nginx sudo nginx 安装成功之后，启动成功如下图 4：简单配置nginx主要是简单修改下log【方便追查问题】 和 web_root 对应文件【快速启用网站】 5：重启nginx [root@iZ25xlozdf2Z nginx]# nginx -s quit [root@iZ25xlozdf2Z nginx]# nginx 如下图，配置web目录成功！ 6：添加php 支持安装php-fpm yum install php-fpm nginx.conf设置 location ~ .php$ { root /var/www/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /var/www/html$fastcgi_script_name; include fastcgi_params; } 7：重新启动服务，网站回复。 8：耗存简单对比 如下图：基本上节省了200M，虽然这个可能是运行初期数据；但是，还是确实轻了不少，每个服务占存基本上1/4，线程也少了不少。内存占用方面表现，感觉尚可，接下就看性能了 后续初次接触nginx，整体感觉还不错。后续，进行基本的防攻击，多端口设置，和性能配置。 个人小站原文链接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx实践二：nginx端口配置，域名重定向设置]]></title>
      <url>%2F2015%2F11%2F18%2FNginx%E5%AE%9E%E8%B7%B5%E4%BA%8C%EF%BC%9Anginx%E7%AB%AF%E5%8F%A3%E9%85%8D%E7%BD%AE%EF%BC%8C%E5%9F%9F%E5%90%8D%E9%87%8D%E5%AE%9A%E5%90%91%E8%AE%BE%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[nginx替换apache之后，需要进行两个基本设置，一是：域名绑定和重定向，防止盗链，死链，参考文章 apache 防盗链 ；二是：设置多个端口，一个端口显然无法满足需求。 域名防盗链设置域名防盗链主要通过，设定服务器域名，非域名重定向到现有域名（相对于之前的黑名单，我太单纯了，流量可以重定向利用一下）。 配置nginx.conf 12345678# default 默认只能server_name 访问listen 80 default ;server_name cuihuan.net;# 重定向if ($host != "cuihuan.net") &#123; rewrite ^/(.*)$ http://cuihuan.net/$1 permanent;&#125; 解释：首先80端口默认只能域名访问 ，默认的域名cuihuan.net。 对于所有非cuihuan.net 的过来的数据直接引流的cuihuan.net。如下图【这个战斗力为五的渣渣还挂在我的页面】 进行了转码后还可以避免搜索引擎抓的域名出现死链。 配置多端口： 这个就简单了，直接把上面配置好的server copy一个挂上其他web服务或者phpadmin等等1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 8002 default ; server_name cuihuan.net; if ($host != "cuihuan.net") &#123; rewrite ^/(.*)$ http://cuihuan.net/$1 permanent; &#125; location / &#123; root /var/www/weixin; index index.php; &#125; location ~ \.php$ &#123; root /var/www/weixin; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /var/www/weixin$fastcgi_script_name; include fastcgi_params; &#125; # set nginx stutus location /NginxStatus&#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file conf/htpasswd; &#125; #set deny all file error_page 404 /404.html; location = /var/www/wordpress/40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /home/www/wordpress/50x.html &#123; &#125; &#125; 对于nginx搭建小网站来说，这个是基本的配置。个人感觉相对于之前 apache 防盗链配置 来说难易差不多。 相关文章：Nginx实践一：centos apache更换为nginx 个人小站原文链接]]></content>
    </entry>

    
  
  
</search>
