<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[颠覆发展-读《极简欧洲史》]]></title>
    <url>%2F2020%2F02%2F02%2F%E9%A2%A0%E8%A6%86%E5%8F%91%E5%B1%95-%E8%AF%BB%E3%80%8A%E6%9E%81%E7%AE%80%E6%AC%A7%E6%B4%B2%E5%8F%B2%E3%80%8B%2F</url>
    <content type="text"><![CDATA[我们的目的是找出欧洲文明的基本元素，看这些元素如何通过时间重新组合，从古旧中重塑新的样貌。看旧的东西如何屹立不倒，风云再现，肺炎亦然！ 一、先说肺炎1.1、针对肺炎知识推荐一篇介绍文章，很用心。回形针：关于肺炎的一切。(推荐再忙也看看） 1.2、针对思考方式也推荐一篇文章，多数观点认可。量子学派：越是在关键时刻，越是要独立思考 1.3、针对武汉红会无言以对，说多了文章都发布出去，“颠覆发展”相信一定会有更高效的组织方式，就像新教发展基督教一样！担心不透明，区块链可以考虑下！ 中世纪多数人加入圣职体制的初衷：只是因为他是当时最庞大也是最有钱的组织。 1.4、针对武汉政府 拿后来的认知水平去质疑过去的应对策略，是很不负责任的。期待最后深度复盘，期待最终不要变成赞歌！ 1.5、针对疫情面对疫情，衷心的感谢各位医疗工作者、一线人员的付出和努力！多难兴邦，相信大家众志成城，定能度过难关！也希望各位小伙伴，带上口罩，勤洗手！ 1.5、针对小页面 个人尤为触动的是，本着力所能及开发了几个页面，却得到了远超预期的反馈和协助，也让自己看到，真的有一大批人在默默的做着一些事情！ mark一下，第一次访问流量过万，第一次发起github项目，再接再厉！github：https://github.com/cuihuan/2019_nCov网站：http://cuihuan.net/wuhan/news.html 二、概述言归正传，春节结束前读完了这本书，短小精悍。不同于一般按照时间逻辑，本书采用平行结构，以希腊&amp;罗马文化，基督教文化和日耳曼战士文化三要素的角度阐述了欧洲的简史。 极简欧洲史虽缺少了历史辩证全面的思考，但多了几分演义的色彩，值得一读。 全书分为两大部分，先总述，后展开。 第一部分，概述了希腊罗马文化，基督教文化和日耳曼战士文化，如何产生、迭代、融合，形成中世纪政教合一的社会。 第二部分，分场景阐述了文艺复兴、宗教改革、启蒙运动、科学革命、浪漫主义思潮、世界大战等，如何造就了当今的欧洲文化。 总的来看，欧洲文明是个不断颠覆发展的过程，欧洲文明最大发明就是科学本身！ 三、文章摘录 欧洲文明的三个基本元素：希腊&amp;罗马文化，基督教，日耳曼战士文化 欧洲文明分为三个时代：古典时代，中世纪和近代 希腊文化：唯有答案简单，才能近乎正确。 十诫首戒：除我以外，你不可有别的神犹太人一直相信，宇宙只有一个神，这是极不寻常的观点，希腊人和罗马人憧憬多神，这比较普遍。 三大元素的第一次结合是君士坦丁大帝赋予了基督教合法地位。日耳曼：能靠流血换到的东西却去汗流浃背，是没骨气，等而下的事情。日耳曼战士支持基督教是最后一个连接 耶稣回答：凯撒的归凯撒，上帝的归上帝。你应当全心、全灵、全意爱耶和华你的天竺，要爱你的邻居如同爱你自己。耶稣把犹太人的道德教训转化成了宇宙大爱。他关于爱的教诲，凌驾于一切法律之上。 几何学是个简单，有呀，有逻辑的系统，非常赏心；几何学是引导人类认知宇宙本质的一个途径。 欧洲贵族：’土地你拿去，其他留给我’，&#39;并非所有的东西都贵国王所有&#39;，是欧洲政府思维的基石。 对政府有所设限对经济的发展有举足轻重的影响，欧洲经济之所以能够一飞冲天，成长速度非其他地区所能比拟，”商人有保障“是个关键 文艺复兴：行动像天使，悟性像神明。 圣职体制不单有自己的法律、刑罚和监狱，还有自订的税收制度，多数人加入教会，只是因为他是当时最庞大也是最有钱的组织。 新教教义：”因信称义“是新教的基本观点，你根本不必做任何事就能得救，尤其不必对神父的指示言听计从。只要你相信上帝，保持信仰就行了。基督教并不是罗马人的宗教。 法国启蒙运动，社会的两股非理性的强大势力，一个是教会，一个是法国国王。教会和国王的地位之所以屹立不摇，靠的就是人民的无知。 启蒙运动信息是：宗教就是迷信，因此，尽管宗教曾经是欧洲文明的核心，现在他不得不靠边站，由理性取而代之。 浪漫主义运动：崇尚感受，情绪以及所有强烈的情感。艺术是穷尽灵魂，讨薪剖腹地将热情，痛苦，绝望赤裸裸的摊在第一线=&gt;文明是人为的，它束缚了我们，局限了我们。 文艺复兴，宗教改革，科学革命，启蒙运动，浪漫主义运动，以不同的方式削减了教会的权威。 苏格拉底：质疑一切，任何事物不能只看表面，他认为一般人的意见不具备理性的基础，提倡争辩才能出结果。苏格拉底问答法。没有反思的生活不值得；活着不是目的，好好活着才是。 柏拉图：理想主义哲学家，我们在世间的所见所感，只是存在与另一个崇高灵魂界中的完美形体的影子。 亚里士多德：三段论【概述，明确叙述，推出结论】123每一猫都有四只脚喵喵是只猫所以喵喵有四只脚。 从医第一课，希波克拉底誓言：谨慎，有医德，时时以病人的福祉为念12345678910111213141516希波克拉底誓言仰赖医神阿波罗·埃斯克雷波斯及天地诺神为证，鄙人敬谨直誓，愿以自身能力及判断力所及，遵守此约。凡授我艺者，敬之如父母，作为终身同业伴侣，彼有急需，我接济之。视彼儿女，犹我兄弟，如欲受业，当免费并无条件传授之。凡我所知，无论口授书传，俱传之吾与吾师之子及发誓遵守此约之生徒，此外不传与他人。 我愿尽余之能力与判断力所及，遵守为病家谋利益之信条，并检柬一切堕落和害人行为，我不得将危害药品给与他人，并不作该项之指导，虽有人请求亦必不与之。尤不为妇人施堕胎手术。我愿以此纯洁与神圣之精神，终身执行我职务。凡患结石者，我不施手术，此则有待于专家为之。 无论至于何处，遇男或女，贵人及奴婢，我之唯一目的，为病家谋幸福，并检点吾身，不作各种害人及恶劣行为，尤不作诱奸之事。凡我所见所闻，无论有无业务关系，我认为应守秘密者，我愿保守秘密。尚使我严守上述誓言时，请求神祗让我生命与医术能得无上光荣，我苟违誓，天地鬼神实共亟之。 20200202 于西山林语]]></content>
      <tags>
        <tag>2020读书</tag>
        <tag>读书笔记</tag>
        <tag>《极简欧洲史》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[公信力-《图解区块链》读书笔记]]></title>
    <url>%2F2020%2F01%2F26%2F%E5%85%AC%E4%BF%A1%E5%8A%9B-%E3%80%8A%E5%9B%BE%E8%A7%A3%E5%8C%BA%E5%9D%97%E9%93%BE%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[智人之所以能够以劣势的生理特性横扫五大洲，成为唯一存活下来的人类，并且主导了地球进化的方向，其原因在于其通过独有的语言和文字创造了虚构的概念。人类通过对这些&quot;虚构的概念共识&quot;实现了大规模合作的可能，从而创造了人类辉煌。 ——《人类简史》利用可信程序获取公信力，区块链可能成为这种虚构的力量。 引言庚子春节注定与众不同，新冠肆虐，小拽积极响应国家号召，不恐慌，不传谣，躺在家里给社会做贡献^_^。 最近几年，区块链和比特币一直是追捧的热点，闲来无事，翻了翻15年解读区块链的一本书，算是回望历史，结果充分佐证了一句话：拿后来的认知水平去质疑过去的应对策略，是很不负责任的，肺炎亦然。 本书整体打分2星，除了复盘看看，不值得一读。笔记主要记录了区块链的一些思考、应用和golang的一个简单实现。 一、是什么？区块链到底是什么，不同领域认识偏差很大，常被用到的词有”自由”、”信任”、”价值转移”、”安全”等等。 百科定义：区块链是一个信息技术领域的术语。从本质上讲，它是一个共享数据库，存储于其中的数据或信息，具有“不可伪造”“全程留痕”“可以追溯”“公开透明”“集体维护”等特征。基于这些特征，区块链技术奠定了坚实的“信任“基础，创造了可靠的“合作”机制，具有广阔的运用前景。 从程序员角度看什么是区块链 小拽定义：区块链是一种开发完成后，任何人无法干预运行的可靠程序。 之所以这样定义，小拽认为，区块链有两个关键技术目标：不可干预和可靠运行。进而达到程序具有公信力的最终目标。 不可干预：要求具有公信力的算法和架构设计，设计者本人也无法直接修改，只能按照既定规则运转，不可篡改。例如比特币使用的算法，即使创始人中本聪也无法修改。 可靠运行需要提供分布式存储，异常容灾，可扩展等架构能力，来保证稳定的运行，不会被攻击，出异常。例如比特币目前来看分布式存储，选举机制，容量也是可以从1M扩展到8M(国际扩展到20M)。 而最终达到的目标是大家认可，也就是具有了所谓的“公信力”。信任本就贵，公信价更高。而公信力的获取和维持成本极高，例如银行要维持自己的公信力，花大量资金拿牌照（找背书），在核心区建网点（提面子），还要有准备金，审计等等；而国家甚至要考军队来维持公信力。 简而言之区块链就是一个不能被篡改的，大家都觉的​灰常靠谱的数据记录方式！ 二、如何用？区块链的关键意义在于利用可信程序获取公信力，那么如何应用？仁者见仁智者见智，小拽列举一些小的思考。 可信记录：比如电子病例、电子学历、电子合同、电子护照等。一旦通过区块链记录下来，就不能被以任何手段篡改，可以降低机构的公信成本。那么问题来了，写错了怎么办？答案是只能写一个新的，就像财务系统一样，钱记录错了，是不能擦掉的，只能后面新入一笔账。 保险行业：保险行业接近三分之一的成本用于管理费用，那么如果区块链可以解决公信力，那么互助险是否可以利用区块链记录分摊过程来降低管理成本？ 股权交易：这个本身就是完全靠公信力来支撑的运营方式， 电子商务：有了区块链的公信力，是否还需要“支付宝”，是否可以有更可靠的预付款和信用链？ 物联网：每个物联网设备的“数字化身份”、“验证”、“记录”，链式不可篡改的结构是否解决这块问题？ 反洗钱：所以记录至少是公开透明，不可篡改的，是否可以更利于追查？ 三、Golang实现一个简单的区块链具体看代码，入门golang写的一个小栗子，核心是信息加密和链实际应用中有一个经典的链式结构参考：《热点账户设计》 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180package mainimport ( "crypto/sha256" "encoding/hex" "encoding/json" "io" "log" "net/http" "os" "time" "github.com/davecgh/go-spew/spew" "github.com/gorilla/mux" "github.com/joho/godotenv")type Block struct &#123; Index int // 是这个块在整个链中的位置 Timestamp string // 生成块的时间戳 BPM int // 心跳 Hash string // SHA256 生成的散列值 PrevHash string // 前一块的hash散列值&#125;// 整个区块链var Blockchain []Blocktype Message struct &#123; BPM int&#125;// 计算给定的数据的 SHA256 散列值// 这个 calculateHash 函数接受一个块，通过块中的 Index，Timestamp，BPM，以及 PrevHash 值来计算出 SHA256 散列值func calculateHash(block Block) string &#123; record := string(block.Index) + block.Timestamp + string(block.BPM) + block.PrevHash h := sha256.New() h.Write([]byte(record)) hashed := h.Sum(nil) return hex.EncodeToString(hashed)&#125;// 生成新的区块链，通过迁移块的hash + 时间戳 + 特定参数func generateBlock(oldBlock Block, BPM int) (Block, error) &#123; var newBlock Block t := time.Now() newBlock.Index = oldBlock.Index + 1 newBlock.Timestamp = t.String() newBlock.BPM = BPM newBlock.PrevHash = oldBlock.Hash newBlock.Hash = calculateHash(newBlock) return newBlock, nil&#125;// 校验块，主要检查区块的传递是否正确，// 通过Prehash 与前一块的hash是否一致，通过cal算出当前hash是否一致// 校验的原则：始终选择最长的链func isBlockValid(preBlock, afterBlock Block) bool &#123; if preBlock.Index+1 != afterBlock.Index &#123; return false &#125; if preBlock.Hash != afterBlock.PrevHash &#123; return false &#125; if calculateHash(preBlock) != afterBlock.Hash &#123; return false &#125; return true&#125;// 最长的链标识数据是最新的，所以需要一个函数来将本地过期的链切换成最新的// 检查长度，直接替换func replaceChain(newBlocks []Block) &#123; if len(newBlocks) &gt; len(Blockchain) &#123; Blockchain = newBlocks &#125;&#125;//&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;// 上面是xiaozhuaichain 的主要函数，下面采用web方式来展现// 初始化web服务func run() error &#123; handler := makeMuxRouter() httpAddr := os.Getenv("ADDR") log.Println("Listening on ", os.Getenv("ADDR")) s := &amp;http.Server&#123; Addr: ":" + httpAddr, Handler: handler, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; if err := s.ListenAndServe(); err != nil &#123; return err &#125; return nil&#125;// get 请求来查看链，post请求来写链func makeMuxRouter() http.Handler &#123; muxRouter := mux.NewRouter() muxRouter.HandleFunc("/", handleGetXiaozhuaiChain).Methods("GET") muxRouter.HandleFunc("/", handleWriteBlock).Methods("POST") return muxRouter&#125;// 读取func handleGetXiaozhuaiChain(w http.ResponseWriter, r *http.Request) &#123; bytes, err := json.MarshalIndent(Blockchain, "", " ") if err != nil &#123; http.Error(w, err.Error(), http.StatusInternalServerError) return &#125; io.WriteString(w, string(bytes))&#125;// 写入func handleWriteBlock(w http.ResponseWriter, r *http.Request) &#123; var m Message decoder := json.NewDecoder(r.Body) if err := decoder.Decode(&amp;m); err != nil &#123; respondWithJSON(w, r, http.StatusBadRequest, r.Body) return &#125; defer r.Body.Close() newBlock, err := generateBlock(Blockchain[len(Blockchain)-1], m.BPM) if err != nil &#123; respondWithJSON(w, r, http.StatusInternalServerError, m) return &#125; if isBlockValid(newBlock, Blockchain[len(Blockchain)-1]) &#123; newBlockchain := append(Blockchain, newBlock) replaceChain(newBlockchain) spew.Dump(Blockchain) &#125; respondWithJSON(w, r, http.StatusCreated, newBlock)&#125;// responsefunc respondWithJSON(w http.ResponseWriter, r *http.Request, code int, payload interface&#123;&#125;) &#123; response, err := json.MarshalIndent(payload, "", " ") if err != nil &#123; w.WriteHeader(http.StatusInternalServerError) w.Write([]byte("HTTP 500: Internal Server Error")) return &#125; w.WriteHeader(code) w.Write(response)&#125;func main() &#123; err := godotenv.Load() if err != nil &#123; log.Fatal(err) &#125; go func() &#123; t := time.Now() // 小拽，第一个创世块 genesisBlock := Block&#123;0, t.String(), 0, "", ""&#125; spew.Dump(genesisBlock) Blockchain = append(Blockchain, genesisBlock) &#125;() log.Fatal(run())&#125; 四、一点摘录P12：区块链的五大特性：去中心化(Decentralized)、集体维护(Colletively maitain)、高度透明（Transparent）、去信任(Trustless)。 P18：央行发型数字货币的原则（周小川） 提供便利和安全性 保护隐私与维护社会秩序、打击违法犯罪的平衡（显然比特币打破了平衡） 有利于货币政策的有效运行和传导 保留货币主权的控制力（显然，比特币或者目前已知的电子货币还都不具备） P89：区块链的关键意义：无需中介和公信力。两大意义主要通过共享账本和共识机制两种技术实现。 P10：区块链的每个区块的三要素：本区块的ID，加密一段时间内全部的信息体，上一区块ID。 P16：现钞的发行和汇拢基于“中央银行-商业银行机构”的二元体系来完成。数字货币的发行和运行同样要基于该体系，但是“运送”和“保管”会发生变化，运送方式有物理运送变为电子运送，保存方式变为云计算空间——周小川 P19：R3的核心职能是指定银行业区块链技术开发的行业标准。目的是要做一个全球的去中心化的实时银行间清结算系统。 P43：中国对比特币是绝对禁止，但是对区块链“是一项可选的技术”（15年对于区块链已经是认可的，但比特别明令禁止，和目前差异不大） P111：2016年2月，央行明确表示发行数字货币的战略目标，争取早日退出央行的数字货币。 20200126 于西山林语]]></content>
      <tags>
        <tag>2020读书</tag>
        <tag>《图解区块链》</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020小拽书单]]></title>
    <url>%2F2020%2F01%2F26%2F2020%E5%B0%8F%E6%8B%BD%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[高效的读书，一定要从选书开始。小拽2020所读的一些书、读书笔记和推荐级别。 书名 读书笔记 推荐等级 关键词 分类 《谁动了我的奶酪》 享受变化 ※※※ 享受变化 个人成长 《图解区块链》 ※※ 区块链 互联网]]></content>
      <tags>
        <tag>2020书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[享受变化-读《谁动了我的奶酪》]]></title>
    <url>%2F2020%2F01%2F04%2Fbook-%E8%B0%81%E5%8A%A8%E4%BA%86%E6%88%91%E7%9A%84%E5%A5%B6%E9%85%AA%2F</url>
    <content type="text"><![CDATA[引言：支持者也好，批评者也罢，他们都有自己的道理。其实，重要的并不是“奶酪”这个故事本身，而是你如何解读它，并且把它应用到生活中 乌镇呆了两天，一直细雨濛濛，或许是淡季的原因，显的过分宁静。 闲来无事，重读了《谁动了我的奶酪》，挺不错的一篇释压文，读完后心情也宁静一些。 一、看书中事书中的小故事很简单直白：两个小老鼠和两个小矮人在迷宫中寻找奶酪，在突然寻得一大堆向往已久的奶酪后，讲述了四个小家伙是如何处理的。同时，奶酪终究会失去的，在奶酪被动了后，又描写了四个小家伙又是如何应对的。 而“奶酪”是一个比喻，指的是我们生活中任何想要的东西，可以是一份工作、一种人际关系、金钱、豪宅、自由、健康等等！“奶酪”会带给我们“幸福”和“快乐”，但变化总会发生，他们总会不断地拿走你的“奶酪”。而作者就是想告诉我们要转换一种眼光去看待变化，去处理变化。 二、想当下景相较于其他鸡汤文，作者逻辑清晰。论据是：变化是始终存在的，所以“奶酪”也一定会变化，因此是&quot;不论你愿不愿意，总有人会来动你的奶酪&quot;。 映射到当下比较火的话题，例如“中年危机”年轻人的不断加入，会让你肤浅的积累淡然失色。倘若一直迷失在互联网浮夸的高薪红利下，不思进取，那么你终究会丢掉这块丰厚的“奶酪”。最终，面对裁员，你的指责、愤怒、恐惧，甚至所谓的xx权利都无法帮你守住这份“奶酪”，或许同情心和法规还能帮你捞到部分补偿“奶渣”。 与其恐惧必然发生的问题，是否可以换个思路：直面必然会不停变化的“奶酪”，调整心态，接收变化，拥抱变化，享受变化。 因此，不论愿不愿意，都有人会来动你的奶酪，尤其是当你的奶酪“过分鲜美”。类似的例子还有很多，例如“国企/公务员改革”，“互联网金融变革”，“网约车变革”等等。 三、思如何为生活是个充满变化的迷宫，怎样才能找到属于自己的“奶酪”？ 作者给了几条建议 转变心态：认识到变化总会发生，你的奶酪不断的被拿走是客观事实，不必要过分焦虑和恐惧，时刻做好失去奶酪的准备。 关注变化：经常关注奶酪是否正在发生变化，自身或者行业是否将要、正在或是已经发生了变化。 适应变化：越快放弃旧的奶酪，你就会越早的找到新的奶酪 享受变化：尽情的享受探险的过程和新奶酪的美味（加一句：也没必要拿新旧奶酪做对比，失去的对于你来说已经没有意义） 总的老说，与其像老白兔，费尽心机守着注定会丢失的“老奶酪”，为什么不转变心态、拥抱变化，去勇敢，快乐的追寻“新奶酪”。不但能够享受探险的过程，还能获取“新奶酪”的奖励。 所以在这样一个不断变化的世界，学会适应，从而欣赏和追逐更好的事情，这对我们终归是有好处的。 20200104 于乌镇]]></content>
      <tags>
        <tag>《谁动了我的奶酪》</tag>
        <tag>2020读书</tag>
        <tag>读后感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019总结]]></title>
    <url>%2F2020%2F01%2F01%2F2019%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[闲云谭影日悠悠，物换星移几度秋。不管是以梦为马、不负韶华，还是无所事事、蹉跎岁月，2019都已成为过去。回首向来萧瑟处，也无风雨也无晴。历史长河奔流不息，没人可以阻挡她的前进，但总想给她些许留痕。 一、FLAG回顾2018年总结 2018年的总结，整体基调过于低沉，只有多喜乐、长安宁的自在，缺少西北旺、射天狼的霸气。哈哈，难怪2019有些逍遥自在（一事无成）。 今年开篇先定基调：鸟未尽，弓未藏；广积粮，缓称王。 1234567==== 2019 flag 回顾 ====工作方面：2019立了一个flag，重新捡起博客，目标20篇文章。呵呵，结果公众号只写了10篇 ￣□￣｜｜（考虑到公司wiki还有10+篇总结，勉强及格）投资方面：2019立了一个flag，每周阅读《中国经济周刊》完成，投资年化收益超10，完成。兴趣爱好：立了个flag，学做饭，目前看，勉勉强强，总计搞定了28个菜谱（包括但不限于：煮粥，煮面^_^） 19年股票投资趋势 秀秀19年的菜谱 二、目标拆解 工作方面：2019年离开了做了一年半的财务系统，投身国际化了横向技术，一个全新的领域，挑战很大。主要针对企业出海，做了的两间事：1、如何满足当地法规：出海合规。2、如何符合当地习惯：软件本地化（i18n）。19年整体算是入门吧，20年的目标是深耕，响应习大大2020年新春祝福的号召：把短板补的再扎实一些，把基础打的再牢靠一些。 2020年工作上两个flag吧，1、完成企业出海这个命题作文，形成一套体系化的解决方案。2、公众号技术文章数量：保十争十五。 投资方面：19年相对18年资产配置稳了一些，得益于全球环境不错，整体稳步上升。19年的投资总结就一句话：寻找价值偏差，耐心等待。道理挺简单，就是客观要理性分析，看准了，要坚持，有耐心。举个栗子：刘强东事件是否影响了京东的根基？京东股价跌一半是否合理。同理：区块链对英伟达的影响，薅羊毛对拼多多影响，甚至贸易战对经济根基的影响。 19年针对线下也做了大量调研，整体结论是就个人而言，ROI不高。2020年转移目标线上，结合自身优势做些尝试。 19年投资方面flag不变，继续保持每周读经济周刊！加个flag，保险入门了解，产出一篇入门文章。 生活方面：生活嘛，闹是多喜乐，静是长安宁，贵在心态。生活毕竟是自己的事情，之后的规划中，也逐步把这块放入私密了，正所谓团圆便是家肥事，何必盈仓与满箱！！！ 兴趣爱好：2019除了学习做饭外，新get两个小兴趣，一个是德州扑克，挺有意思，前半年玩的挺多，后半年时间有点失控，逐步控制了，偶尔看看直播，高山仰止；另一个是下象棋，哈哈，小下怡情，欢迎切磋^_^！关于爱好，整体来看，运动类的少了太多，配置不合理，无论是爬山、游泳、篮球、羽毛球都没啥进展。 2020立个flag，学会自由泳+踩水！ 三、忆往昔，看今朝同2018，最后致谢，感谢老婆和家人的支持，有了你们坚实后盾，怎么走都是路！感谢工作中小伙伴，有了你们的信任和配合，稳如狗！ 2019，以梦为马，2020 只争朝夕。 2020年1月1号 于杭州西湖]]></content>
      <tags>
        <tag>2019总结</tag>
        <tag>2020展望</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国际化货币那些事儿]]></title>
    <url>%2F2019%2F09%2F08%2F%E5%9B%BD%E9%99%85%E5%8C%96%E8%B4%A7%E5%B8%81%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[内网项目总结发的一篇小文，今年12篇文章告急，滥竽充数了o(╥﹏╥)o 第一部分涨姿势，聊聊什么是货币和国际化的场景下货币遇到的问题；第二部分分享货币改造，聊聊货币改造是怎么玩的。期望大家通过本文了解到货币的一些小知识，货币处理的最佳实践，以及分享下个人在项目推进中的一些总结。 一、聊聊货币在具体谈货币之前，先抛几个小问题1231、$1.000 是多少钱？是1美刀吗？还是1000哥伦比亚比索？2、哥伦比亚行程计价结果是：$666，用户能现金支付吗？3、发奖励兜底限额，来个888万写死，够不够？ 显然都不行，原因可以跳转下面货币小知识。 那么问题来了，货币到底是什么？货币在经济学的解释是：货币 ，百科的描述是：货币 作为世界经济体系的核心，到底是个啥，身为一名底层码农，咱也不懂，咱也不敢问，咱也不敢讲。 但作为工程师角度，货币无非就是我们系统中录入，存储，传递，展现的一组变量。如何规范，准确，本地化的处理这组变量就是IBT货币改造的主要内容。 货币小知识问题一：$1.000 具体是多少钱，要看具体的语言和国家，比如在语言美国(US)和英语（en-US）的情况下，$1.000标示1美元；但是在哥伦比亚(COL)西语(es-CO)的情况下，$1.000就表示1000哥伦比亚比索，西语的千分位都是&#39;.&#39;，小数点是&#39;,&#39;，吃不吃惊，腻不腻害！ 问题二：$666在哥伦比亚无法用现金支付，因为哥伦比亚现存的最小现金是50，所以在哥伦比亚的现金支付需要抹零，而且要符合法律规定的抹零。同时，还有很多国家是没有分的，例如日本的最小货币单位就是日元，没有日分（-_-） 问题三：888万看似很大，其实不然，例如哥伦比亚的汇率和人民币差不多1:500，也就是说不到888万，也就1w多。同时，由于int32最多存储2147483647，21亿如果是哥伦比亚按照分存储也就4.2万[21亿/100(分)/500(汇率)]，所以存储和传递一定都要用长整形。 分割线：科普到此结束，下面会重点分享下，货币改造的实践和项目总结； 二、广告插入^_^前方高能预警 货币涨见识，时间度量衡更涨见识，多国环境下的架构抽象那才叫酸爽，各位架构师要不要来感受下？请戳国际化出行平台工程师/架构师 投递链接 内推链接 活水链接 3亿+请求一天够不够玩？不够，那如果是牵涉资金和交易的流量呢？敢不敢来？PHP/Go研发工程师（国际化支付）投递链接 内推链接 活水链接Java研发工程师/专家（国际支付）投递链接 内推链接 活水链接 三、货币怎么玩下面部分为阉割版，牵涉过多内部示例已经处理，仅保留项目推进和问题解决的一些总结 货币的重要性毋庸置疑，毕竟牵涉到钱。在我滴国际化土匪猛进的时候，货币问题在开发和线上频繁发生，给用户和业务造成了极坏的影响。举几个栗子 除了货币展现不一致的情况，通过上面的讲解你可能已经知道了，西语情况下2.5是有可能被理解为2500 自古有云：再一再二不能在再三，虽然走向了国际，但祖训不能忘。 为了从根本上解决货币相关的问题，IBT在六月中启动了货币改造专项行动。 1项目简介：加密，内容就是解决货币本地化处理和展示的问题， 权知轻重，度知长短，货币改造前先来分析下存在的主要挑战。 本身牵涉细节多，工程量大，100+页面，几十个模块，多部门协调 紧排期情况下，40多个关联模块升级的稳定性风险很高，兼容性升级是重中之重，不能因为改造而引入新的问题。 整体排期，大联调和级联上线，核心一大块：API+收银+账单+fleet+各端+H5的整体排期，联调环境统一部署，占仿真，占pre回归需要提前预估到。 质量把控，改造不是目的，解决问题才是，那么落地质量就是需要最严把的关口。 说了这么多，货币改造具体是怎么玩的？有哪些经验可以在后续项目中沉淀？ 作者本人也是第一次驾驭横向项目，总结了下货币改造一期的在实践中六个步骤和细节，下文慢慢道来，先挂个整体时间图 总的来说就是项目推进的留个阶段：【六步走】细梳理=》定方案=》出排期=》助落地=》控质量=》查遗漏下面分阶段阐述各个步骤的主要工作，要点和内容参考 3.1 问题现状梳理核心工作：梳理现状，分析问题，定位重点和难点。 货币改造的梳理阶段，梳理了IBT全量货币的存储、展现、传递现状；调研了限额、溢出、失精度，取整等技术和业务问题。梳理后重难点落在两块 重点：用户感知最明显的，终端展现不标准，服务端格式化不统一，以及高风险溢出字段改造； 难点：模块间错综复杂调用关系，字段梳理和兼容性改造落地。 贴一些该阶段的梳理和调研：参考内网小文 123总结：问题现状梳理的核心贵在一个"细"字。处于六部曲的第一环，一定要梳理尽可能细致、细致、细致的梳理，否则后面问题会被层层放大。回头来看，这次货币改造还是有些梳理遗漏，给后面实践过程造成了很大的影响，例如：负号问题，券的页面归属，某些情况下司机端周流水页面等等。 3.2 标准制定发布核心工作：针对调研现状和目标进行问题拆解，制定权威标准和落地可行最佳实践 货币改造的标准制定阶段，按照货币的存在的全生命周期（录入，传递，处理，存储，展现）进行了过程拆解，问题拆解，草拟各个阶段处理货币的可落地标准，结合业务实际情况产出落地最佳实践。 对于标准和最佳实践，着重要考虑了两个方面： 一是权威：保证标准的可信度。在货币的格式问题上，专门成立个货币标准小组，和前线运营，产品确认当地的习惯。 二是可行：保证方案的可行。在货币的展现阶段标准上，针对目前系统的图表展示等，对货币原值保留了标准保留。 目前IBT的货币标准和军规 参考内网小文 格式标准举个栗子 处理标准举个栗子 1总结：制订标准和最佳实践本质上是一个可落地的方案，在权威的基础上一定要注意可行性。 3.3 方案排期拉齐核心工作：同步方案（涵盖标准/最佳实践/军规），评估各方实现成本，产出整体排期。 货币改造在这个阶段做的最重要的事情就是和15+团队单独沟通，同步方案，结合模块现状和细节，产出团队在业务快速迭代的情况下的方案和排期。 沟通和消息同步是这个阶段的重要事项，最终目的是为了 同步标准。已读不代表理解，还是需要和各个业务方，亲自小范围的沟通方案，解答疑惑，标准的原因，方案如何落地，一定要注意哪些方面 产出排期。家家有本难念的经，各模块的状况不一样，所以需要小范围沟通，结合模块的现状产出，处理重难点，不影响整体进展排期。 方案拉齐阶段的一些资料供参考：参考内网小文 1总结：小范围沟通是保证方案的同步效果，结合模块实际情况产出排期是结果。 3.4 整体改造落地核心工作：协助业务改造，工具支持，推进问题，同步风险。 货币改造在这个阶段基本进入了业务的开发过程中，也是问题集中爆发的阶段。在这个阶段横向技术协助业务方接入SDK，协调测试环境，处理理解偏差问题， 针对开发中的问题，横向技术主要通过下面几个方式来推进 开发工具提效：针对痛点问题，从整体和工具层面来协助，比如覆盖率等，应急性的解决问题。 横向问题推进：针对这个阶段的跨团队技术问题的解决、推进，甚至对于风险瓶颈，要亲自上手（作者在这个过程中对于很多确实工作量大和排期紧的项目也是被迫自己上）。 风险同步：针对排期风险和业务隐藏风险，要保证消息的同步通道和效果，本次改造过程中，两次全范围排期风险同步，一次SDK风险同步。 1总结：核心是保证信息同步通道。只有风险，问题，细节，改造环境等等都完备同步了，才能把控好进度和质量 3.5 交付质量把控核心工作：交付质量是重中之重，着重从质量通道的角度去把控。 该阶段货币改造过程中，这个阶段是黎明前的黑暗。初期的任何信息同步和设计遗漏，在此时都会彰显，比如没有做兼容，遗漏页面，遗漏接口，负数情况等等。 货币改在在这个阶段的主要抓手有两个：质量团队+RD检查项。 自检项：具体到每一点，是否执行到位。 质量团队：QA作为最终质量的控者，从每一个细节去确认，同时从用户角度来把控。横向技术在这个阶段，参与了几乎所有case评审，共性case指定，异常情况探讨等等。 这个阶段特别要感谢QA同学：制定了完备的保障方案和连续两个周末加班支持 列下本次整体货币质量保障方面的文档，后续的项目也可以参考借鉴：参考内网小文 3.6 问题遗漏汇总核心工作：基本完成，一方面查漏补缺，一方面需要总结。 阶段性的总结是为了更好，更低成本的去实现下一次跳跃。本次货币改造在这个阶段重点做了两件事情 查漏：梳理所有的遗留，遗留问题；针对问题复盘，针对这次货币改造内部复盘总结：总结相关经验和成果 相关文档参考：参考内网小文 四、小结国际化改造道重而任远，货币这次小小尝试，只是个开始。关于时间，度量衡，数字，电话等问题域，也将逐渐展开，技术实现细节后面继续探讨^_^]]></content>
      <tags>
        <tag>国际化</tag>
        <tag>货币</tag>
        <tag>项目推进</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符编码那些事儿]]></title>
    <url>%2F2019%2F05%2F12%2F%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[身为一名要冲出国门的国际化码农🙃，字符编码是必备课题。小拽本文依次介绍下字节，ASCII，GB2312，GBK，GB18030，UNICODE，UTF8，UTF16，ICU 等到底是什么鬼？最后理论结合实际，研究下网站中经常出现的“锟斤拷，��，烫烫烫烫烫，屯屯屯屯屯屯”是什么神兵利器O(∩_∩)O？ 一、二进制和字节大概一百多年前，贝尔实验室制造了世界上的第一个晶体管，晶体管具有开合(0和1)的状态，这种01状态的变化被称为二进制位（bit）。 过了几年，英特尔把八个可以开合的晶体管组合，做为一个基本的记录单元，这个单元被称作字节（byte），所以一个byte由8个bit构成，可以表达256种状态。 又过几年，祖师爷冯诺依曼设计了一台可以存储和处理（冯诺依曼体系）字节变动的机器ENIAC，后来这个机器被称作计算机。 二、标准ASCII计算机运行是二进制，如何用二进制位来标识人类语言，就需要和计算机有一套约定关系。例如约定，0100 1111代表O，0100 1011代表K，那么存储为01001111 01001011的两个字节就代表OK，这套约定关系被称作字符编码。 冯祖师爷是的德国人，二战去了美国设计了第一台计算机。起初，只有美国人能用计算机，山姆大叔就根据英语习惯设计了一套映射约定 0-31 标识控制字符，例如换行[LF]，删除[DEL]，确认[ACK]等 32-47 标识符号例如!@#$等 48-57 标识0-9是个阿拉伯数字 65-122 标识大小写字母 大家都按着这个约定来，交流表达起来没啥问题，呵呵，都挺好。于是这个方案就一致通过了，山姆大叔也给这个约定起了个名字ASCII编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文字符。 计算机一个标准字节8bit本身可以标识256个符号，但标准的ASCII的最高位去掉用做奇偶校验，用剩余7位标识128个符号，如下图 三、ASCII 扩展字符集随着计算机的发展，欧洲人开始逐步接触计算机了。 英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。 IBM牵头扩充了ASCII编码128-256位的标识字符，主要是一些欧洲的常用符号，这部分扩展映射被称为ASCII扩展字符集 四、GB2312雄关漫道真如铁，而今迈步从头越，美帝国主义万万没有想到，二战后，大量第三世界的人民站起来了，逐步开始使用计算机。但问题是256个字符已经没啥可利用的字节状态来表示汉字了，更何况中华文明有6000多个常用汉字需要保存呢。 但是这难不倒智慧的中国人民，面对帝国主义的压迫，我们毫不客气的做了两件事情，并在1980年发表了这个声明 互相尊重：尊重标准ASCII 规范中0-127位表示的标准字符。 平等互利：ASCII的128-256位，我们用来标识中文，由于中文太多，我们要使用两个字节来表示一个中文^_^ 中国人民觉的这个声明还不错，毕竟当时计算机的使用范围也不大，基本满足需求，于是就把这种汉字方案叫做 GB2312编码。GB2312 是对 ASCII 的中文扩展。 1234567891011非专业人士可以忽略： GB2312如何组合，能表示多少个？GB2312中用两个字节来标识一个汉字，前面的一个字节（他称之为高字节）从0xA1用到0xF7，后面一个字节（低字节）从0xA1到0xFE，简单计算0xA1：10*16 + 1 = 161 0xF7：15*16 + 7 = 247 =&gt; 247-161 = 860xFE：15*16 + 14= 254 =&gt; 254-161 = 93因此GB2312可以标识约86*93=7998 个汉字实时上 GB2312 标准共收录 6763 个汉字，其中一级汉字 3755 个，二级汉字 3008 个。同时收录了包括拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字母在内的 682 个字符。几乎覆盖了大陆常用的99.75%汉字 这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的全角字符，而原来在127号以下的那些就叫半角字符了。 五、GBK满足了基础和常用的汉字需求后，但依然会有很多人的生僻字名字打不出来，屌丝还好，但是一旦牵涉伟人名字打不出来那就坑爹了！改改改，抓紧改！ GB2312的编码，使用两个字符，每个都只用了后128位，不合理呀，干脆我们把低字节127号之后的内码我们也用了，不浪费。 说干就干，于是扩展之后的编码方案被称为GBK标准（不知道K是不是扩展的缩写K^_^），GBK包括了GB2312的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。 12345678910非专业人士可以忽略： GBK如何组合，能表示多少个？第一个字节的值从 0x81 到 0xFE保持不变，第二个字节的值扩展从 0x40 到 0xFE0xFE-0x81：254 - 8*16+1 =1250xFE-0x40：254 - 4*16 =190 因此，GBK约标识了 125*190 = 23750 GBK 共收入 21886 个汉字和图形符号，包括：GB2312 中的全部汉字、非汉字符号；BIG5中的全部汉字；ISO10646 相应的国家标准GB13000 中的其它 CJK 汉字以上合计 20902 个汉字； 其它汉字、部首、符号，共计 984 个。 六、GB18030中华民族大团结，后来少数民族也要用电脑了，于是我们需要再次扩展，又加了几千个新的少数民族的字，GBK扩成了GB18030。从此之后，中华民族的文化就可以完美的在计算机时代中传承了。 1234非专业人士忽略：这一系列汉字编码的标准通为 `DBCS`（Double Byte Charecter Set 双字节字符集）。在DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了 从ASCII到GB2312，再到GBK，而后GB18030，中华民族终于完成了全量中文字符的编码，简单总结下 第一阶段：中国人民通过对 ASCII 编码的中文扩充改造，产生了GB2312 编码，可以表示6000多个常用汉字。 第二阶段：汉字实在是太多了，包括繁体和各种字符，于是产生了 GBK 编码，它包括了 GB2312 中的编码，同时扩充了很多。 第三阶段：中国是个多民族国家，各个民族几乎都有自己独立的语言系统，为了表示那些字符，继续把 GBK 编码扩充为 GB18030 编码，完成全量中文字符编码。 六、UNICODE之后的世界，百花齐放，百家争鸣，各国纷纷制造自己的编码规范，同时互相不去理解对方规范，即使同一种语言也区别巨大，例如台湾地区中文采用big5的繁体编码，名字也牛逼大了，叫大五码。 各自为政引来了大量的问题，各个语言互不兼容，此时，一堆大佬看不下去了，勇敢的站了出来，着手解决这个问题，他们成立了一个类似于TC的组织，叫做ISO(International Organization for Standardization 国际标准化组织)。 他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号的编码！他们打算叫它”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “UNICODE“。这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码！ UNICODE统一了各国，成为了实事上的大一统的编码规范。这种编码非常大，大到可以容纳世界上任何一个文字和标志。所以只要电脑上有 UNICODE 这种编码系统，无论是全球哪种文字，只需要保存文件的时候，保存成 UNICODE 编码就可以被其他电脑正常解释。 12345678非专业人士忽略：unicode 编码unicode开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是ISO就直接规定:1：必须用两个字节，也就是16位来统一表示所有的字符2：对于ASCII里的那些“半角”字符，unicode包持其原编码不变，只是将其长度由原来的8位扩展为16位，3：其他文化和语言的字符则全部重新统一编码。由于”半角”英文符号只需要用到低8位，所以其高8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。 七、UTF，UTF8，UTF16UNICODE很好的解决了不同语言统一编码的问题，但同样也不完美，有两个主要问题， 字符识别：如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？ 存储浪费：我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储空间来说是极大的浪费，文本文件的大小会因此大出二三倍。 此时UTF(unicode transfer format)标准出现了，顾名思义，是UNICODE在传输和存储过程中的格式化标准，其中使用最广的是utf8和utf16 UTF-16相对好理解，就是任何字符对应的数字都用两个字节来保存！我们通常对Unicode的理解就是把Unicode与UTF-16等同了。但是很显然如果都是英文字母这做有点浪费，明明用一个字节能表示一个字符为啥整两个啊。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度，当字符在ASCII码的范围时，就用一个字节表示，保留了ASCII字符一个字节的编码做为它的一部分，注意的是unicode一个中文字符占2个字节，而UTF-8一个中文字符占3个字节）。从unicode到utf-8并不是直接的对应，而是要过一些算法和规则来转换。 1234567891011121314151617181920212223非专业人士直接忽略：unicode 如何转换成utf-8以小拽的"拽"字为例Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）—————————————————————–0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx中文一般三个字节，前置标识位举个栗子，中文：拽 unicode是2534125341 十进制 unicode0x62fd 十六进制 0110 0010 1111 1101 二进制 ### 套上模板0110 001011 111101 二进制 253411110xxxx 10xxxxxx 10xxxxxx 模板第三行11100110 10001011 10111101 utf8 二进制e 6 8 b b d utf8 十六进制【一切为了节省】最终utf8拽对应的就是0xe68bdb UTF-8就是在互联网上使用最广的一种unicode的实现方式，这是为传输而设计的编码，并使编码无国界，这样就可以显示全世界上所有文化的字符了。 简单对比下GB系列，UTF8，UTF16 UTF16：不推荐使用utf16，因为utf16最初能表示的字符数有6万多，看起来很多，但是实际上目前 Unicode5.0 收录的字符已经达到99024个字符，其实不够，有可能出现乱码。 UTF8：国际化编码首推UTF8，兼容全量，唯一的问题是空间略有浪费! GB系列：GB系列都是双字节字符集，相对节省空间，如果只是国内使用GB18030完全可以兼容所有。 八、“锟斤拷��” 是什么通过上面介绍，可以看出来，各个编码规则是不一样的，目前互联网浏览器默认传输和解析方式是UTF8，但是部分老的网页采用GB系列，就会出现传输过程UTF8解析不了，展示GB错乱问题。 UNIDCODE规定：当unicode遇到解释失败的字时，会尝试用 「U+FFFD」 来代替，「U+FFFD」乃是 unicode 的一个占位符， 显示为 � 而utf8识别为异常的传输字符后，传到页面转为双字节展示的GB会怎么样呢？1234567➜ xiaozhuai ✗ pythonPython 2.7.10 (default, Aug 17 2018, 19:45:58)[GCC 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.0.42)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; s = (u'\uFFFD'.encode('utf8')*2)&gt;&gt;&gt; print(s.decode('gbk'))锟斤拷 也就产生了，传说中的”锟斤拷”神器！ 另外还有几个神器：”烫烫烫烫烫，屯屯屯屯屯屯”“烫” 主要出没于 windows 平台下，ms 的 vc++ 编译器中， 当你在栈内开辟新内存时， vc 会使用 0xcc 来初始化填充， 很多个 0xcc 连起来就成了 烫烫烫烫烫 同理在堆内开辟新内存时， 会用 0xcd 填充，这便是 屯屯屯屯屯屯不管是 “锟斤拷” 还是 “烫” 都要求最后是用GB码输出。 九、ICU在unicode的统治下，世界各国的基本编码不会出现乱码等异常。但当中华民族逐步强大，准备冲出中国统一世界的时候，发现各国的货币，时间，数字等表示灰常不统一，例如数字1234.5，英文表示1,234.5，葡语表示确是1.234,5，很是苦恼。 此时IBM站了出来，叫上google,apple等小伙伴，遵循”IBM公共许可证”，开源了一套基于unicode的国际化组件ICU(International Component for Unicode)。根据各地的风俗和语言习惯，实现对数字、货币、时间、日期、和消息的格式化、解析，对字符串进行大小写转换、整理、搜索和排序等功能，ICU4C提供了强大的BIDI算法，对阿拉伯语等BIDI语言提供了完善的支持。 ICU成为了目前国际化组件的实事标准，底层依赖UNICODE和CLDR，官方提供了C/C++和JAVA的SDK，ICU4C和ICU4J，同时，各个语言在此基础上开发了各个语言的版本，例如php的intl组件。 十、实事标准字符编码的从产生，发展，到国际化一步一步走来，逐步形成了下列实事标准 字符集：UNICODE 字节编码：UTF8 国际化：ICU 需要注意的是，mysql的utf8并不完全兼容标准的utf8编码，后续推出了utf8mb4完全兼容，所以推荐采用utf8mb4 参考网站： BIDI：https://www.ibm.com/developerworks/cn/web/1404_xiayin_bidihtml/index.html CLDR：http://cldr.unicode.org/ ICU：http://site.icu-project.org/design/size/cldr UNICODE：http://www.unicode.org/standard/versions/enumeratedversions.html]]></content>
      <tags>
        <tag>国际化</tag>
        <tag>字符编码</tag>
        <tag>ICU</tag>
        <tag>UTF</tag>
        <tag>UNICODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【周记】996思考和团队文化]]></title>
    <url>%2F2019%2F05%2F06%2F%E3%80%90%E5%91%A8%E8%AE%B0%E3%80%91996%E6%80%9D%E8%80%83%E5%92%8C%E5%9B%A2%E9%98%9F%E6%96%87%E5%8C%96%2F</url>
    <content type="text"><![CDATA[题记：从外卖财务团队转做出行国际化团队^_^，入了新团队。恰好新团队要求，每周要写点感悟分享，字数内容不限，转到blog 20190504 《思考996》 本周五一旅途，来回20小时的驾驶，听完了案件一郎的《被讨厌的勇气》，在阿德勒的思想中游历了一番，颇为惬意！ 《被讨厌的勇气》通过青年和禅师对话，分层次的剖析了束缚人的三个因素：卑缅过去，期幻未来，沉溺人际关系，之后从哲学和心理学角度来逐个击破，帮助青年挣脱束缚，解放自我！ 正如书中所述：人生很简单，认真并且无需深刻！12345678## 解读：当下，过多的人在追求一些极为深刻和复杂的事情，而做不到一些极为简单的习惯，譬如总结，锻炼等等。回收蓦然，一事无成。倘若能够认真的对待每一件际遇，不浮不躁，不急于奔向所谓的未来，认真对待当下，人生一定会回馈给你一个更美好的未来！ 想到当下热议的996工作方式，作为一名计算机工程师，真的很庆幸自己能够生活在第三次工业革命的信息化时代，能够通过自己的技能来解决问题。回想自己这几年的工作，成长和产出的最快的时光偏偏都和996无关，却和一些认真的小习惯息息相关 规划总结：分时间片的规划自己的行程，珍惜规划后行程中的每一个时间片，而后对自己走过的时间片进行总结思考。每个人的能力不一样，长期的总结纠偏，教会自己把控自身的能力范围和人生轨迹，学会更多的和自我交流。而安静和轻松的环境，恰恰可以让你更深度的思考，996反之！ 持续学习：保持初心，持续学习。无论从个人还是公司角度看，持续的学习都是一个+EV的操作；所以相对于996的丧心病狂去写一堆不可维护的烂代码，做一个无法扩展的缺陷设计，真的很庆幸自己一直能够抽出一丢丢时间来持续学习。 解决问题：在飞速发展的互联网行业，提升解决问题的能力一直是我的第一准则。尤其是和大牛们在一起解决问题，你会学习到很多解决问题的方法：需求分析，方案折中，迭代优化等等；但996绝对不是解决问题的方式，因为，真正需要解决的问题，如果平时解决不了，996依然解决不了。哈哈，偷偷告诉你，职业生涯困惑迷茫的时候，请大牛吃顿饭往往会有意想不到的收获！！！ 分享交流：实践证明，在分享出自己的观点和总结的同时，总能够收获到很多超出预期的建议。不信，你可以试试，而且，分享只需要：认真且无需深刻！ 对于被迫996的工作方式，小拽是完全反对，996方式的时间榨取，在长远来看一定不是全局最优的，除了榨取时间，也丧失了生活，主观能动性和创造力！ 最后摘录阿德勒的一段话共勉，珍惜当下： 其实人生总是处于完结状态的，即使生命终结于此时此刻，那也无需称之为不幸。无论是20岁终结还是90岁终结，都是完结的、幸福的人生。认真的过好此时此刻，每一个刹那都是一种完结。人生最大的谎言就是纠结过去，关注未来，却一直忽略此时此刻，这就是对自己的人生和无可替代的刹那撒下的最大的谎言。对于当下来说，过去和未来根本就不存在，所以我们只谈现在。 决定人生的既不是昨天也不是明天，而是此时此刻。 20190427 《思考团队文化》 本周对于团队文化和制度的思考。一个团队必须有自己的文化和做事方式，否则，太多的磨合和不默契会浪费很多时间。初来乍到，非常认可目前的团队文化，也希望能通过团队文化，提升大家对团队的认可，增加合作的默契！ follow through ：做事情，有始有终，跟进到底，凡事必须要有后续的action和落地评估，show me what you do not what you say ！ 主动性：相较于被动的执行，主动的思考，抽象，沟通，推进更有利于业务和个人的成长。人非圣贤，皆有惰性，被动的制度来提升主动习惯，是养成主动性的有效方式！ 沉淀：rush和沉淀相辅相成，如同折中的思考架构和业务，每周抽出10%的时间来沉淀和思考重要不紧急的事情，无论对自身，对业务长远来看都非常重要！另外，其实结合自身情况，提出两点，也希望自己能够坚持 效率至上：不提倡无效加班，做事情讲究效率至上。为了提升效率，无论沟通，还是执行，从长远角度看，都要做到事前准备，事中高效，事后反思！ 健康团队：团队的健康不仅仅是停留在业务产出，团队健康包含但不限于小伙伴的身体健康，工作积极性，成长空间，技术氛围，竞争格局！]]></content>
      <tags>
        <tag>周记</tag>
        <tag>2019</tag>
        <tag>996思考</tag>
        <tag>团队文化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据归档那些事儿]]></title>
    <url>%2F2019%2F04%2F03%2F%E6%95%B0%E6%8D%AE%E5%BD%92%E6%A1%A3%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[在热点账户问题和常用解决方案【中】这篇文章中提到，解决热点读性能的一个非常通用方式是数据归档。本篇小拽总结下在操作数据归档过程中遇到的一些问题和经验！ 一、数据归档所谓数据归档就是把部分低频访问的历史数据从线上库迁移到归档库的过程。在设计数据归档方案的时候通常需要思考三个问题 归档前：如何进行存储选型 归档中：如何保证迁移准确 归档后：如何处理数据完整性破坏所引起的问题 下面也着重从这三部分来聊聊 二、存储选型存储选型是归档前要做的最重要的一件事情，目前市面上的存储方式多如牛毛，如何选择能够支撑当前业务环境的存储选型，就非常重要！ 2.1 归档的数据特点既然是要选型数据归档的存储，首先来需要梳理下归档数据的特点 读性能：归档数据对读性能没啥要求，能够读出来就可以 写性能：尽可能好的批量写入性能，能够批量1w+达标 压缩比：尽可能的节省空间，采用高压缩比的存储引擎 分布式：最好能够分布式，考虑到目前单片都40T了，非分也可 数据量级：上限尽可能高，考虑到实际情况，10TB+目前达标 一致性保证：归档是兜底，尽可能高的保证数据不会出现异常丢失 2.2 通用选型因素除了考虑归档数据的特点，还要考虑一些通用因素，例如 公司是否运维支持：大厂这个因素很重要，如果运维支持背书，最好不过！ 开源活跃程度：活跃度太低不能选 普遍使用场景：跳出存储给的通用场景的不能选 2.3 备选存储的特性也初步总结和梳理了下可能用到的集中存储的特性 结合归档数据的特点和不同存储的优势，最终选用了 rocksDB：作为存储归档数据引擎，性能和数据压缩比都不错，最主要是公司DBA愿意支持 ES：作为在线查询，公司运维支持 HIVE：作为财务数仓核心数据和全量数据中心，哈哈，为下一篇财务数据中台做铺垫^_^ fusion：作为幂等健破坏后的幂等健KV池 三、一致性保证归档过程存在会删除线上数据，是个非常高危的操作，所以操作过程中和操作之后都需要特别注意数据一致性的保证。 对于操作过程的一致性保证相对简单，过程通常两步step1 插入确认：查询线上库-&gt;插入归档库-&gt;查询归档库-&gt;确认插入step2 删除确认：删除线上库-&gt;查询线上库-&gt;确认删除注意：过程中尽可能的保证读取和写入的时间，删除会锁库，大批量读会抢网络和IO，防止对线上业务造成压力，尽可能调优批量数据，推荐条目在200-1000条一次，数据量在5M-100M一次 四、归档后问题数据归档后，必然破坏了数据的完整性，会造成下面几个问题,，需要提前考虑 4.1 读数据穿透问题低频历史数据归档后，造成线上数据缺失，查询数据穿透和范围关系查询损失都会存在。因此，数据归档后，对于读操作有两种处理方式 归档数据不读：最简单，但是对于某些场景可能确实不太合适。 读proxy兼容：通过读proxy，穿透性的选择各种存储截止。 针对读数据，还有一种比较特殊的情况，就是跨区间范围关系聚合，这样就需要有一份完整数据来满足极端需求，目前财务系统对于这类需求统一走离线财务数仓来解决！ 4.2 写幂等破坏问题对于写数据最大的问题就是幂等健被破坏，归档了数据后，rds写入唯一健破坏，在极端情况下，可能会造成duplicate。考虑到问题的出现概率和实现成本，初期可以忽略，采用人工干预的方式，归档最终要写入全量，写不进去就是duplicate了；后面可以采用前置幂等健组来挡，做到最终一致！ 4.3 数据一致性问题无论是数仓数据还是归档数据，作为财务数据，一旦提供资金服务，那么就必须保证强一致性，财务目前采用离线分天统计数据的金额和数量，来保证宏观上的一致性。这里面也有需要小坑，例如数据飘移，时间gap等，关于财务数仓中遇到的坑和解决方案，后续专项讨论 五、最终归档方案分析了归档前选型，归档中数据转移，归档后数据完整性问题，初步的归档方案如下图 简单梳理下核心流程 写数据流：写数据写入online rds[备注：目前没有前置幂等拦截，后面择机完善]，写入后通过binlog准实时写入es，提供线上读服务；通过binlog小时级入hive，作为分析数据和全量数据存储；通过天级归档脚本，将历史数据导入rocksdb归档。同时，如果有日切，也会天级进行数据日切和新表创建。 读数据流：读数据过proxy，非归档期间数据直接读取es，归档数据和es没有的数据都会穿透到rocksdb。 监控流：天级监控hive，es，rocksdb，三个不同来源的数据条目和总金额，保证一致性。 六、总结和不足本篇主要总结了小拽在数据归档过程中，如何选型，如何归档以及在归档数据后引起的问题如何处理。 通过数据归档，更清楚的划定了不同存储介质的功能边界，是进行数据中台搭建，赋能业务的前置准备！]]></content>
      <tags>
        <tag>数据归档</tag>
        <tag>存储选型</tag>
        <tag>数据通道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[热点账户问题和常用解决方案【中】]]></title>
    <url>%2F2019%2F04%2F01%2F%E7%83%AD%E7%82%B9%E8%B4%A6%E6%88%B7%E9%97%AE%E9%A2%98%E5%92%8C%E5%B8%B8%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%90%E4%B8%AD%E3%80%91%2F</url>
    <content type="text"><![CDATA[话接上回，上篇阐述了什么是热点账户，基本财务账户如何设计，幂等健和链式设计！本篇将针对热点账户在实践中引发的问题，梳理和拆解业务流，分析问题点，提出七种常用解决方案。 一、性能问题初现上线初期数据量较小，运行正常！一次大促后，账户流水的总数目接近亿级别，初现性能问题：系统整体的qps也就10+，但热点账户写入失败率偏高，并且随数据量增加失败率逐步升高；整个账户系统全靠上游有redo标识位不断重试，才能保证最终写入成功! 哈哈，作为一名拥有三年工作经验的老码农，面对问题，要做的第一件事，就是静，抽根烟静静，准备开搞！ 二、数据流拆解拿到问题，抽根烟静一下之后，分析问题需要三步：梳理数据流，拆解过程，定位问题点。先对财务账户更新的数据流进行拆解 链式锁后的基本账户操作过程，分为如下五阶段 请求阶段：账户操作请求。 查询阶段：查询当前账户信息。主要获取当前链，资金数据等！ 计算阶段：对链和操作的资金进行计算，判定资金操作合规，同时保证幂等和并发！ 写入阶段：事务同步写入流水和余额 响应阶段：告知上游回调 三、链路分析梳理数据流后，接下来分析每个阶段可能引发的问题。按照优先级，先分析业务问题区域（读取阶段，计算阶段，写入阶段），通常问题会出现在业务阶段；之后，再分析框架问题区域（请求阶段和回调阶段），该区域出现问题的情况偏小，但是一旦出现问题，就是比较有意思^_^！ 3.1 业务问题区域分析读取阶段，计算阶段，写入阶段三个阶段是具体的业务操作，从并发和耗时两个角度来分析下可能的问题点 3.1.1 耗时分析耗时分为三块 查询耗时：RDS拥有亿级别数据量，查询未中primary，但命中索引，业务数据体并未完全在索引中，因此访问数据走index match；数据主键聚簇，唯一健索引查询获取数据，page极难命中cache，也不会命中磁盘电梯算法优化！结合实际情况，查询耗时在10-100ms级别 写入耗时：insert 包含了自增，理论上在数据落盘是追加写，即使uniq_key去创建索引的情况下，耗时在ms级 过程耗时：长连接情况下，init conn时间基本可以忽略，但是读写两次往返数据库的链路时间还是需要考虑，整体预估在1-2ms之间 从整体上看，预估该阶段的耗时在10-100+ms，从实际失败率来看也基本一致！ 3.1.2 并发分析 天级QPS：当时分析天级几十万单，天级QPS不到10，不高！ 瞬间QPS：每个订单拆解到资金流后，会同时操作多次热点账户，瞬间qps相对很高，理论qps就可能达到语言上限，由于上游链路限流1024，按照10级别操作拆分，理论上满池QPS在万级别。考虑实际单量，瞬间QPS=单量(10)*拆解量(10)，实际的满额预估QPS可能到100+ ！ 按照上面分析，在瞬时QPS达到10+的情况下，热点账户整体延时在10-100+ms，由于DB在写入uniq_key保证链点唯一，所以出现并发写入失败也在情理之中；并且随着数据量的提升，读取延时增加，写入失败率会继续增加。 3.2 框架问题区域请求阶段做为入口，一般也分为三个小阶段 webserver接收请求 框架加载和路由 基础校验 请求阶段核心耗时一般存在于框架加载和路由，高并发场景webserver和upstream之间的调用也是一个可能出问题点！当时财务系统，采用欢总封装的go-thrift，并且其他模块并未出现请求阶段问题，所以并未对这个阶段的latency和并发做一个衡量，重点分析了业务模块！ 四、解决方案4.1 读取和写入阶段优化通过上面分析，目前问题的痛点是并发读取热点账户数据高延时引发写入失败，提升读性能成为了关键 读性能提升有两个基本思路：读的时效快和读的次数少 针对上面两个基本思路，结合财务账户情况提出了五种提升读性能的解决方案 【读快】持久化last record：不从全量数据里面读，抽离子账户的最新信息，持久化到单独的表中或者内存中，降低整体数据量，提升了读性能。缺点是要保证持久化信息的准确性，引入事务写。 【读快】纵向切分-时间分库分表：按照时间进行纵向切分，降低查询范围内的数据量，提升读性能。缺点是跨时间读不友好，开发量也不小 【读快】纵向切分-归档：历史数据归档是实现相对简单，跨时间读也比较友好，随着数据量的提升，也是必须要做，之后会详细介绍归档方案和选型。 【读快】横向切分-业务分库分表：按照账户类型或者城市分库分表，可以优化读写数据量，同时，跨表读负担也会较小。但对于热点账户或者热点城市，依然聚簇，效果不是很明显。同时，再次对热点账户进行横向分库分表也是极度不推荐，引入的极高的读写成本均。 【读少】阶段快照：一定量或者一定时间内的数据，持久化一次。优势是极大的降低读写次数；缺点是需要复杂的逻辑来保证undo操作和数据一致性！ 五种解决方案各有千秋，作为一个初期的财务系统推荐采用持久化last record和数据归档来保证写入读性能和整体读的数据量。如果系统发展到了中期，推荐按照时间分库分表。如果发展到了双11或者春晚某些极端场景，牺牲掉部分准确性，采用阶段快照也是可以的。 4.2 计算阶段优化存在计算阶段造成的最大影响也就是引起了两次数据传输，通常是不可避免的，但是如果真的是要进行提升有一种方案通用方案 DB计算：通过存储计算，转嫁计算成本给DB，减少一次链路请求。但不太推荐，复杂的sql往往有坑，insert computer from select 还会造成大面积的数据隔离，很容易引起死锁。 4.3 请求和回调阶段优化请求阶段一般有三种形式：同步调用，异步调用和伪同步调用！前两种调用非常常见：同步爆池的情况，一般采用限流来降压，采用漏桶，令牌桶等等策略；异步调用通常采用消息队列来削峰填谷；这里重点阐述对于支付和财务系统在请求阶段经常采用的伪同步的方式 伪同步流量较早出现在innodb，leveldb等存储引擎为了利用追加写提升写入性能，采用类WAL日志来持久化数据。通常伪同步方案采用三件套：WAL日志+校验位+广播消息来完成一次完整的请求！流程图一般如下 请求阶段：同步请求调用，核心要素追加写入wal日志，变更校验位，完成同步调用！此处追加写保证了快速写入，校验位来保证数据的最终写入成功。图中1，2 异步阶段：通过读取wal日志的核心数据，进行复杂事务处理，如果成功进入下一阶段；如果失败，没问题，通过外部trigger来触发redo操作！如果多次redo依然失败，那么通过undo来回滚数据。 回调阶段：如果成功，更改校验位，同时发布成功广播消息，关注结果和时效性的模块，可以获取最终成功的标识！如果undo回滚数据，则发布失败广播消息，告知结果失败！ 在伪同步的模式下指标衡量： QPS：伪同步模式，采用WAL核心要素追加写，所以写性能可以极大提升，进而满额QPS相对直接同步调用也大量提升 时效性：伪同步并非完全同步，所以结果需要监听回调。对于结果强一致的请求，必须监听回调，确保一致，时效性降低；对于弱一致可以认为同步回调即成功，时效性提升。 失败率：操作知识核心要素追加写入，真正的操作通过异步保证，整体成功率提升！ 对于资金处理过程，大量采用伪同步的请求方式来保证快速写入和最终一致性。 4.4 解决方案总结总的来说，归结了七种优化方式（哈哈，上篇写的八种优化，当时总结的，现在愣是想不到还有啥了^_^）。其中请求和回调的伪同步方式，是在架构层面优化，这个在多数的财务系统和财务系统的内部数据流中都会用到；而读写和计算阶段的优化，可以跟进实际业务情况进行选型处理。 五、事故复盘面对各种优化方案，需要结合实际情况做出取舍，有的是长期方案，有的是快速方案，但一定需要想清楚了再开搞，过程中有一个对小拽之后影响很大的事故，引以为戒。 翻车过程：当时觉的读-&gt;计算-&gt;写这个过程，两次读DB操作，下沉计算过程到DB后，通过DB计算，可以减少一次数据库请求。于是合并了一个大SQL，也就是所谓的insert ( field computer from select)，觉的写了个狂赚酷炫吊炸天的SQL，一上线，库锁死了！幸好有前置的redo flag，全量redo数据恢复，要不然估计直接祭天了！ 对于这个复杂大SQL事故，小拽总结了三个方面123莫炫技：没啥好说的，解决问题的成就感要远大于炫技！简单设计：简单的设计通常意味着可依赖；复杂的设计要尽可能的拆解，想清楚，队友都理解不了的设计，那就别上线了，可能真的需要再思考拆解下尊重线上：核心服务基本上线流程一定要遵守，测试，监控和回滚方案缺一不可 六、小结本篇主要针对热点账户问题提出了七种常用的解决方案，下篇将继续引申探索下，各种解决方案在不规则高并发场景，例如双十一，微博热点事件中如何套用 预知后事如何，下回再聊！]]></content>
      <tags>
        <tag>财务系统</tag>
        <tag>热点账户</tag>
        <tag>伪同步设计</tag>
        <tag>读写优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[热点账户问题和常用解决方案【上】]]></title>
    <url>%2F2019%2F02%2F13%2F%E7%83%AD%E7%82%B9%E8%B4%A6%E6%88%B7%E9%97%AE%E9%A2%98%E5%92%8C%E5%B8%B8%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%90%E4%B8%8A%E3%80%91%2F</url>
    <content type="text"><![CDATA[热点账户问题由来已久，一直是账户系统设计中的一个难点和瓶颈！小拽将通过上中下三篇文章，分别介绍下热点账户的产生，解决方案和延伸应用！本篇主要介绍下什么是热点账户？通用财务账户系统如何设计？以及其中的幂等健和链式设计等 一、热点账户问题1.1 什么是热点账户热点账户：顾名思义，热点账户就是会被高频操作的账户！相较于普通的账户，热点账户数量不多，但操作频率极高！ 热点账户从产生来源可分两大类： 富二代型：从产生之初就是热点账户，非常稳定。例如财务中公司的账户，每一笔资金操作都要经过公司出金账户，自然而然操作就会灰常频繁，此类账户还包括：大V账户，大KA账户等等，此类账户所引起的问题是本文重点要解决的 暴发户型：本身是普通账户，由于热点问题变为热点帐户。例如微博出轨女猪脚账户，诺贝尔奖获得者等等，由于热点事件造成的短时间内访问暴增！此类热点账户防不胜防，超出本文的攻击范围，暂不讨论。 1.2 热点账户问题热点账户一旦产生便伴随着高并发，流量分布不均匀，高一致性等等问题。在实际场景中是热点账户必然存在，常常成为用户系统的瓶颈！同时，热点账户问题也是高并发问题的延展，由于热点的不规则性，如何在高并发情况下，削峰填谷，弹性抗压也是很有挑战性的一个方向！ 1.3 热点账户通用解决方案的价值热点账户除了是账户体系的一个通用问题，在高并发，流量分布不均匀，异常峰值等其他问题上，也有一定的通用性。例如微博热点问题，支付宝双11弹性变更，高频抢购问题等等。期望通过学习热点账户的八种解决方案，能够举一反三，应用于不同场景！ 二、如何设计一个财务账户在解决热点账户问题之前，先来看下如何设计一个简单的财务账户，来保障资金记账的安全！ 2.1 业务场景分析从业务上看，财务账户需要准确记录用户的资金变动过程和结果！因此设计一个简单财务账户至少要能包括两个部分：账户余额和账户流水 便于理解，来张传统的账本，看下什么是流水，什么是余额 账户流水：账户流水也就是通俗意义上的帐或者账单！针对某个账户，每一笔资金的变更都需要记录下来，并且保障准确，不可更改！同时如图所示，流水中需要包含单据产生的原因，来源，变更额等等 账户余额：账户余额记录用户某个场景账户的当前资金额度！在复杂的业务场景中往往需要拆分出不同的子账户和账户模型。例如，未结算子账户，可提现子账户，冻结子账户，授信账户等等。 从业务场景上一个账户系统核心需要准确记录余额和流水，同时，必须保障记录的准确，完备，不可变更! 2.2 技术层面拆解2.2.1 基本表方案通过业务场景初步分析，基本的账户系统，需要三张基本表123456789账户基本信息：账户信息表子账户余额信息：账户余额表账户流水信息：账户流水表三张表基本关系账户信息表 1:N 账户余额表账户余额表 1:N 账户流水表## 具体账户和用户的关联可以参考三户模型 2.2.2 表字段设计从技术层面看，设计具体表细节关键要解决以下几个问题 防重：幂等健设计 防改：链式设计 防错：销账设计 先上结果，简单的，能够满足上述需求的设计可以参考innodb mvcc，核心表字段如下 2.2.3 表字段解读2.2.3.1 幂等健设计通过三个属性资金凭证号+版本号+rollback三个字段作为uniq key来保证幂等！ 资金凭证号：来自业务方，业务方发起资金操作的唯一财务凭证，必须可追溯上游凭证和对账！版本号：每次获取DB最新流水n后，版本号n+1插入，保障在并发情况下，每个子账户只有唯一一个版本号：n+1条记录能够插入成功！rollback：回滚标识，保证每条记录能且只能销账一次！ 对于幂等建设计此处有三条小技巧 上游产生：每一个幂等健如果可能的话，尽可能的上游产生，这样可以最大限度的避免自产生幂等健的重复问题。如果确实不能上游产生，例如订单ID，提现单ID，那么也尽可能的分阶段产生，例如提现时，先生成提现单ID，真正提现操作的时候，一定是带着提现单ID和信息来的，防止重复造成资损！ 业务关联：幂等健的产生可以用ice生成，但是，最好能够和业务关联，因为通过业务强关联的幂等健可以无限回溯来容灾！比如，a用户的b订单进行c操作，uniq_key = a_b_c的话，也就是在任何情况下，无论多少次回溯，重试也只会有一个唯一的a_b_c，而ice生成则可能造成自回溯的时候插入多条！ 写库保证：这条原则是高一致高并发的基本原则！因为读取a，校验a，然后插入，必然会存在读写之间a变了，或者主从延时a已经变了，读了历史a。因此，幂等一定要通过写库保证或者最底层保证 2.2.3.2 链式设计链式设计是保证操作精准不可篡改的非常有效手段！通过资金的before info，after info，版本号三个要素来保证一条资金记录一旦插入成功，前后置信息固化！ 链式设计的情况下单条修改是不可能的，多条修改需要在保证条目不变的情况下重组资金，但是，整体资金不可变 解决多条修改的一般方案：分布式存储，选举来判定最终正确的链，来确认是否某条链发生了过程修改，这种设计有一个很时髦的名字：区块链！而每条流水的核心信息加密后也有了一个更加时髦的名字：比特币！ 2.2.3.3 销账设计销账设计在账户系统中是一直存在的，现实财务系统可以红销蓝抵，线上财务系统加了链式之后，基本上就只能采用蓝抵通过增加rollback字段，并且严格限制0|1，保证一条账务流水只能被抵销一次！ 具体三张表详细字段，需要脱敏，就不贴了，参考上面，其中索引，字段大小，联合索引等设计根据自身业务场景兼容即可！ 本篇小结：欲知后事如何，且听下回分解本篇介绍了什么是热点账户和账户的基本设计，涵盖幂等健设计，链式设计等方面，期望大家能够热点账户问题有个初步的认识！ 下一篇重点小拽分析下热点账户由于链式设计造成的问题和八种基本解决方案]]></content>
      <tags>
        <tag>财务系统</tag>
        <tag>热点账户</tag>
        <tag>安全性</tag>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[财务系统设计【序】]]></title>
    <url>%2F2019%2F01%2F06%2F%E8%B4%A2%E5%8A%A1%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%90%E5%BA%8F%E3%80%91%2F</url>
    <content type="text"><![CDATA[新年伊始，组织团队小伙伴进行了一次头脑风暴，畅想了下财务系统2019的愿景，自己也思考颇多，决定针对【财务系统设计】做个专栏，落笔为记！ 一、一次头脑风暴头脑风暴前，除了准备泡面，花生，矿泉水，还列了几个比较现实的问题 公司：你做的事情，值多少钱？公司凭什么给你升职，涨薪？财务系统到底还能给公司带来多少收益？ 自己：为什么要留下来？干一年财务系统，到底能给每个人带来多大成长？ 目标：下次跳槽时，你希望自己成长成什么样子？ 落地：规划每个人的模块方向，如何把自身成长需求和业务成长绑票？ 与我个人而言，期望通过这次头脑风暴，让团队小伙伴们能够对自己的模块有个规划，能够在业务成长的过程中实现个人技能成长，能够通过促进模块收益来提升自己薪资职级！ 无他，也希望各位看官能够思考一下 二、财务系统设计专栏头脑风暴后，小拽也一直在思考，2018年干了一年财务系统了，2019年如何搞？ 具体的需求拆解，模块设计，架构图，暂时先不祭出来了，毕竟还需要深入的拆解和剖析！ 但结合年初的flag，小拽决定2019年完善【财务系统设计】专栏^_^，期望能够通过专栏，自己能够体系化的梳理下财务系统，抽象出更通用的解决方案！ 废话不提先列下2018年亏欠的文章和目录，今年一定补上^_^！ 热点账户问题思考和常用解决方案 数据最终一致性保证 幂等健设计原则 全局ID生成思考和解决方案 财务系统异步和同步的思考 国际化账务系统思考 财务数仓有哪些坑？ 通用账单分级模型设计 账户模型设计和思考 账户流水设计和思考 三、专栏目录长远的看，小拽的财务模块设计最终会把所有文章落到各个模块中，暂时先梳理了下目录！ 123456789101112131415161718192021222324252627282930财务系统专栏├── 在线系统设计和实现│ ├── 分账模块│ ├── 提现模块│ ├── 收银模块│ ├── 结算模块│ ├── 记账模块│ └── 账户模块├── 支撑系统设计和实现│ ├── MIS系统│ ├── openAPI│ ├── 任务系统│ ├── 财务网关│ ├── 数据质量中心│ └── 监控预警系统├── 数据中心设计和实现│ ├── ARCHIVE│ ├── GraphDB│ ├── HBASE│ ├── HIVE│ ├── KV│ ├── RDS│ └── TSDB└── 离线系统设计和实现 ├── 对账引擎 ├── 经营分析 ├── 结算引擎 ├── 财务报表 ├── 资金安全 └── 预算引擎]]></content>
      <tags>
        <tag>财务系统</tag>
        <tag>系统设计</tag>
        <tag>业务系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018回顾]]></title>
    <url>%2F2019%2F01%2F02%2F2018%2F</url>
    <content type="text"><![CDATA[岁月不居，时光荏苒，本想写个2018的总结，结果2019都过2天了，三十功名已经泡汤，顺道写些2019展望吧！ 工作方面 工作方面，18年离开混了四年的狼厂母校，加入滴滴，没有了小伙伴和团队的呵护，只能独立面对，干了几件还算可以的事儿！花了四个月，从0到1的设计，开发了外卖财务在线系统；又花了四个月，搭建了财务离线系统和支撑系统；最后四个月，财务系统国际化改造！整体来说，成长很快，日子很燃，业务波动大！对于自己，无论从技术架构、业务成长、团队建设，既是机遇也是挑战。2019支撑业务发展的同时，需要加深技术的深度和体系化，增强技能外的视野^_^！ 19年个人成长立个flag吧，一年多没更新的博客重新捡起来，做到每月至少一篇！总计达标20篇吧，其中至少有两篇是技能外的 投资方面 18年可谓过山车，年中股票整体收益高达150%，年底落到了20%多，总算没亏。教训就是，止损一定要果断！果断！果断！经济低迷的环境下，基金逐步加仓，等待周期！投资个小桶装水厂，也是亏了，经验一句话：做生意，人非常重要，一定想清楚了再干！18年看好半导体，19年目前比较看好健康体检，旅游领域。19年的核心调整自己的资产配置，按着二八原则递归！实体行业暂时先观望 19年投资方面flag不变，继续保持每周读经济周刊！ 生活方面 18年有些波澜不惊，在媳妇的组织下，爸妈哥嫂全家旅游了一趟，毕业后一直没有好好陪过父母，多少弥补了些遗憾。年底和媳妇儿去了趟台湾，互联网方面太落后了，吃老本而已，以后也不会再去了！年末赶上天朝洪恩，买了共有产权房，位置很喜欢，上下班方便！大事儿就这些，哈哈，整体感觉自己变懒了，很多事情都是媳妇儿在张罗维持，需要反思！2019期望，自己能够腾出更多的时间和媳妇在国内好好逛逛，毕竟三人世界很快就要替代二人世界了！ 19年在生活方面立个flag，哈哈，就不在这里说了，感恩家庭 兴趣方面 2018新get两个技能，一个是无人机，很喜欢，换一个角度看看世界，很不一样，后面也逐步学习下原理和拍摄技巧；另一个勉强算是羽毛球了，哈哈，不过现在还是苍蝇拍，也没啥提升的兴趣了，挺好的健身途径，目标保持体重！2019，期望新增一门技能：做饭，最好能考个证(初步查了下新东方厨师周末班都要6000，真贵)，毕竟程序员的未来都是开饭店，提前做好准备！ 2019 年兴趣爱好方面立个flag，能做一桌菜！ 想说的很多，但是没喝点酒，吹不起来，18年先这样子吧O(∩_∩)O 最后致谢，感谢老婆和家人的支持，有了你们坚实后盾，怎么走都是路！感谢工作中小伙伴，有了你们的信任和配合，稳如狗！ 2018，不管愿不愿意，已经成为过去，让我们在2019继续努力，以梦为马，不负韶华！]]></content>
      <tags>
        <tag>年终回顾</tag>
        <tag>2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解php单例模式]]></title>
    <url>%2F2017%2F06%2F28%2F%E7%90%86%E8%A7%A3php%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例作为一个最经典的设计模式之一，到底什么是单例？为什么要用单例？怎么设计单例？php中单例如何具体实现？ 一、什么是单例wiki百科：单例模式，也叫单子模式，是一种常用的软件设计模式。 在应用这个模式时，单例对象的类必须保证只有一个实例存在。 许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。 通俗的说，也就是对于某一个功能只能实例化一个对象。 二、为什么用单例实际项目中像数据库查询，日志输出，全局回调，统一校验等模块。这些模块功能单一，但需要多次访问，如果能够全局唯一，多次复用会大大提升性能。这也就是单例存在的必要性。 单例模式的好处： 1：减少频繁创建，节省了cpu。 2：静态对象公用，节省了内存。 3：功能解耦，代码已维护。 三、如何设计单例通过上面的描述，单例的核心是，实例一次生成，全局唯一，多次调用。因此在单例模式必须包含三要素： 1：私有化构造函数，私有化clone。也就是不能new，不能clone。【唯一】 2：拥有一个静态变量，用于保存当前的类。【唯一如何保存】 3：提供一个公共的访问入口。【可以访问】 四、php实现php 实现的单例模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?phpclass XiaozhuaiSingleton&#123; // 私有化构造方法 private function __construct() &#123; &#125; // 私有化clone方法 private function __clone() &#123; &#125; // 保存实例的静态对象 public static $singleInstance; /** * 声明静态调用方法 * 目的：保证该方法的调用全局唯一 * * @return XiaozhuaiSingleton */ public static function getInstance() &#123; if (!self::$singleInstance) &#123; self::$singleInstance = new self(); &#125; return self::$singleInstance; &#125; // 调用单例的方法 public function singletonFunc() &#123; echo "call single ton method"; &#125;&#125;$singleInstance = XiaozhuaiSingleton::getInstance();$singleInstance-&gt;singletonFunc();$singleInstance2 = XiaozhuaiSingleton::getInstance();$singleInstance2-&gt;singletonFunc();// 校验是否是一个实例var_dump($singleInstance === $singleInstance2); // true ，一个对象]]></content>
      <tags>
        <tag>php</tag>
        <tag>单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php进程通信]]></title>
    <url>%2F2017%2F06%2F21%2Fphp%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[PHP间进程如何通信，PHP相关的服务的IPC是实现方式，IPC的思想如何用到项目中。 一、linux进程间通信理解php间进程通信机制，先了解下linux进程间有哪些通讯机制 1.1 历史发展linux ipc 按照历史来源主要有两大块 AT&amp;T的system v IPc:管道，FIFO，信号 BSD的socket Ipc :消息队列，共享内存，信号灯。 1.2 主要方式总结起来主要有以下六种方式 1：管道【pipe】：主要是有关系的进程之间的通讯，例如ls xx |grep xx。 2：信号【signal】：通过中间进程来管理进程之间的通讯，属于比较复杂的进程间通讯方式。 3：消息队列【message】：消息的链接表，进程生产和消费消费消息队列。 优势：克服了信号量承载的消息少，管道只能用规定的字节流，同时受到缓冲区大小的约束的问题 （而且读写是有队列的，有一个写，就只有一个能读到，比较简单，不需要同步和互斥） 缺点：太过简单，处理复杂情况可能会造成饥饿现象 4：共享内存。多个进程访问同一个内存区。最快的IPC方式，但是需要处理进程间的同步和互斥。 同时也是当下使用最广泛的IPC，例如nginx，框架通讯，配置中心都是该原理。 5：信号量【semaphore】：主要作为进程间，以及进程内部线程之间的通讯手段。nginx早起的channel机制就类似于信号量 6：套接字【socket】：不同机器之间的通讯手段。处于tcp-》socket-》http之间的一个协议。 二、php进程通讯有哪些方式最好的语言php有哪些IPC的方式 pcntl扩展：主要的进程扩展，完成进程的创建，子进程的创建，也是当前使用比较广的多进程。 posix扩展：完成posix兼容机通用api,如获取进程id,杀死进程等。主要依赖 IEEE 1003.1 (POSIX.1) ，兼容posix sysvmsg扩展：实现system v方式的进程间通信之消息队列。 sysvsem扩展：实现system v方式的信号量。 sysvshm扩展：实现system v方式的共享内存。 sockets扩展：实现socket通信，跨机器，跨平台。 php也有一些封装好的异步进程处理框架：例如swoole,workman等 三、与php相关的IPC3.1 nginx的IPCnginx的ipc主要有两种： 早期：channel 机制：类似于信号，标示不同进程以及进程与子进程之间的套接字，同时具有继承关系。缺点：过于复杂，也产生了过多的套接字，造成存储浪费。 当前主流：共享内存方式：快，写入数据少，方便。 具体可以参见这篇文章：写的非常好 https://rocfang.gitbooks.io/dev-notes/content/nginxzhong_de_jin_cheng_jian_tong_xin.html 3.2 apache的IPCapache：https://arrow.apache.org/docs/ipc.html 四、实际应用中的IPC在平时的项目中，类似于php和linux的IPC的思想大量存在，深入理解。 socket方式：不同项目间通讯，跨机微服务等等，也是使用最广泛的IPC。 共享内存方式：配置中心，公共数据库，甚至git都可以看做共享内存的衍生；`共享内存就必须要注意同步和互斥。 cache ：是共享内存和管道结合的思想 项目流式架构：管道的方式，可以大量的节省空间和时间的通讯方式。 【转载请注明：php进程通信 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>ipc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CodeIgniter 性能优化]]></title>
    <url>%2F2017%2F06%2F05%2FCodeIgniter%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[背景：部署一套PHP微服务接口，需要兼顾性能，开发效率，扩展性。权衡后选择了CodeIgniter；同时优化框架的默认启动项，在qps1000+的压力下整个启动时间优化到5ms左右。 一、选型 背景：使用php作为微服务的接口，具有一定的性能要求和并发要求。 方案： 1：选一个轻量的php框架。具有简单高效的路由，模块化即可。 2：在框架的基础上，自定义的优化 从以下几个角度做了简单的比较 1.1 不同框架的性能https://www.ruilog.com/blog/view/b6f0e42cf705.html 列举了很多数据，除了直接写php之外，ci和lumen的并发和性能不错，在考虑范围内。 1.2 从流行度上看。github排名前四的是laravel,symfony,ci,yii2。最火的是laravel毋庸置疑。但前四均在考虑范围内 1.3 从文档来看。laraval,ci,yii的中文社区都还不错。 综合考虑之后，在满足功能的情况下，选择性能最好，也易入手的codeIgniter作为基础框架。（整个包才2.5M，删除了web文件夹后更小） 二、30ms+到10ms[粗读代码]框架的基本部署，直接参考官网：https://codeigniter.org.cn/ 2.1 问题描述配置了数据库之后，添加了一个默认的controller，一个model，默认加载时间竟然30ms+—_-。瞬间懵逼了，nginx+fpm也就1-2ms，框架竟然30ms，肯定那里配置错了，决定沿着路由追一下。 2.2 问题追查沿着ci的路由顺序追查，从index入，一步一步卡时间。[括号内为运行到的总计数] -》index.php [1ms]-》core/CodeIgniter.php-》加载常量[1ms]-》加载common(包括log，show，error,is_https等)[1ms]load hooks [2ms]-》加载autoload 方法-》加载benchmark-》实例化hooks-》实例化pre_controller-》实例化post_controller_constructor-》实例化post_controller-》实例化post_system-》加载config [3ms]-》加载扩展mbstring,iconv,hash,stardard-》load 组件utf8，uri-》load router [4ms]-》load output，input，lang[5ms]-》autoload package,cinfig,helper,language,driver,lib,model,db,cache-》404 &amp;empty$…handle [31ms]-》controller remap（测试性能写了个remap）[35ms]-》controller 业务逻辑 [35ms] 这个ci的加载过程之后，基本一幕了然，在autoload里面耗时25ms。然后对autoload里面8个组件一个一个分析。 2.3 问题原因分析完之后，处理特别简单，下面这行代码1$autoload['libraries'] = array('database'); ci 出于单例和复用角度考虑，选择默认加载database，也就是mysql在框架初始化的过程中默认初始化了。mysql链接在并发情况下，init基本上要耗费10-30ms。直接干掉。干掉之后，压测基本上在10ms左右。 三、从10ms到5ms [细看代码]3.1 优化目标优化了配置等之后，ci在高并发下依然有10ms左右的加载时间，需要结合自身逻辑优化下，删减掉部分不需要的功能和组件。 3.2 代码分析之前在追查问题的过程中，粗读了一遍代码的流程。而需要进一步优化，就需要细看每个模块函数的功能，干掉不需要的，逐步优化。 -》index.php 作用：加载了部分全局变量，文件路径等入口 优化：干掉了整个web文件，调整了部分路径 -》core/CodeIgniter.php 作用：ci的核心文件，基本上加载了整个模块 优化：进入内部优化 -》加载common.php 作用：框架特别基本的一些函数log，show，error，is_xxx等，800行左右代码 优化：暂时未处理 -》composer autoload func-》加载benchmark 作用：benchmark性能追查工具，设置了全局的开始和结束时间 优化：直接干掉，全局处理。但是性能需要卡，就在index中初始化了一个入库的timer12345// 定义全局开始追查list($msec, $sec) = explode(' ', microtime());define('START_TIME', (float)sprintf('%.0f', (floatval($msec) + floatval($sec)) * 1000));// 定义全局uuiddefine('UUID', uniqid('xxx', true)); -》实例化hooks和预变量 作用：设计特别棒，对于一些hook或者针对不同模块的预加载函数。 优化：直接干掉，7,8个hook后期用到再针对性添加 -》加载config 作用：对应的是ci的get_config等函数，加载了base_url,uri,cache path等 。 优化：直接干掉，全局变量占用需要自己加就行，这种不可控的干掉 -》加载扩展mbstring,iconv,hash,stardard 作用：一些额外的扩展。 优化：直接干掉，试了下干掉对功能不影响，ci写的太全面了，后期可以通过加载自己的lib弥补。 -》load 组件utf8，uri 作用：uri路由方式处理，utf8的处理。 优化：直接干掉。 -》load router [4ms] 作用：路由。 优化：干不掉。 额外：laravel 据说是使用COC最好的框架，看了下ci的router也不错，基本上都是遵循COC -》load output，input 作用：output和浏览器交互输出的处理组件，input包括获取数据array_merge等等。 优化：干掉,需要自己写 -》autoload package,cinfig,helper,language,driver,lib,model,db,cache 作用：各种各样的组建了。 优化：全不加载 -》404 &amp;empty$…handle 作用：异常处理。 优化：加载 -》controller remap（测试性能写了个remap） 作用：指向其他controller。 优化：无 -》controller 业务逻辑 到此将整个框架过程优化完成，初始一下4-5ms感觉还不错。 四、压测数据4.1 高并发压测2000qps+ ，均值约6ms 4.2 长时间高负载压测1500qps 10min，均值约6ms 问题：分析了部分数据的超时分布，约千分之二超过30ms，如下图【这块需要之后优化】 4.3 无限发压nginx + php 均值：17ms框架部分的均值：9ms 也基本上满足需求 五、汇总ci 是一个比较优秀的轻量级MVC框架，可以用来，业能否支撑1000-2000pqs的业务接口。 最后来一张ci的路由图 `]]></content>
      <tags>
        <tag>php</tag>
        <tag>性能优化</tag>
        <tag>codeIgniter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【nginx学习一】基本原理学习]]></title>
    <url>%2F2017%2F03%2F14%2Fnginx_study_1%2F</url>
    <content type="text"><![CDATA[由于性能问题，需要将 apache + php5.2 升级到 nginx + php7，对于nginx的性能和热加载早有耳闻，why nginx so diao。小拽进行了初探，有任何疑问或不准确的地方，欢迎直接开炮！！！ 一、nginx现状nginx 是当前的使用最广泛的webserver ,支持http正向/反向代理，支持TCP/UDP层代理，来看下netcraft的数据 nginx在全部网站中占比达到18%，在top millon busest 达到28%，而且一直在增加。当下最时尚的webserver非nginx莫属 更全数据可以参考：【netcraft】 二、nginx的特点深入了解nginx之前，先泛泛的了解下nginx的几个特点 性能好 非阻塞IO/高并发,支持文件IO 多worker，thread pool 基于rbtree的定时器 系统特性的持续支持 功能强大 webserver/cache/keepalive/pipeline等等 各种upstream的支持【fastcgi/http/…】 输出灵活【chunk/zip/…】 在不断的发展 http2,tcp,udp,proxy… 运维的友好【这个对于开发和部署很重要】 配置非常规范【个人认为：约定及规范是最好的实践】 热加载和热更新【后文会详细介绍，能在二进制的层面热更新】 日志强大【真的很强的，很多变量支撑】 扩展强大 下图是nginx、apache和lighttpd的一个对比。系统压力，内存占用，upstream支持等多个方面都非常不错 三、nginx的核心机制3.1 运行方式一句话简述nginx的运行方式：master-worker多进程模式运行，单线程/非阻塞执行 如下官方图：nginx 启动后生成master，master会启动conf数量的worker进程，当用户的请求过来之后，由不同的worker调起执行线程，非阻塞的执行请求。这种运行方式相对于apache的进程执行相对轻量很多，支撑的并发性也会高很多。 3.2 进程管理nginx是master-worker进程工作模式，那么nginx是如何管理master启程，怎么做到热加载的？ 3.2.1 配置热加载官方图很赞，在更换配置之后，master生成新的worker，直到原有的worker全部任务结束kill掉之后。从现象上作证，也就是在relaod配置之后，短时间可能出现超过conf数量的进程，更新完成后，进程会完全改变。 不更新、直接替换，这种设计思路在代码部署中也很常见，包括mysql迁移，代码更新，服务尝试，很值的学习。 3.2.2 版本更新热加载了解了worker的热加载之后，理解master就非常简单了，通过信号控制，同时存在两个master，逐步替代。 关于replace过程中如何细节控制一致性，稳定性，信号控制，log控制等等，敬请期待小拽的进一步探索！ 3.3 处理流程和模块启动进程后，请求在nginx内部是如何流转的，nginx内部包括哪些模块？ 3.3.1 worker处理过程 【post header】请求到达后首先读取header，log中request time初始时间便从此开始。 【rewrite】请求相关的配置和参数 【pre-access】预处理阶段，频率控制，高频绝句 【acess】权限控制，白名单，403，access deny ，静态文件开放等均有这个模块产生 【content】这个模块会调用upstream产生内容，这个阶段最重要此处调起了工作线程，调用fastcgi，http，以及各种操作产生内容均在此处。性能优化可能需要确认程序执行时间，对应access log中的upstream time 由此产生，记录了nginx中程序运行的全量时间，而request - upstream 就是网络传输和预处理时间。 【filter】内容过滤，包括gzip压缩，返回等在此处 【log】日志的产生 【重定向】没有这个模块，所有的进行智能单向走，有了这个，在任何阶段都可以产生返回，例如client主动阶段产生499的log，过程可能就是1-》2-》8-》7 over 摘自某ppt的一个图，如侵权，请尽快联系小拽 各个阶段的主要状态机可以参考:【跳转】 3.4 请求管理了解了worker的工作模式和worker的内部主要模块，那么worker是如何管理请求的？ 3.4.1 任务调度 官方阐述：It’s well known that NGINX uses an asynchronous, event‑driven approach to handling connections. This means that instead of creating another dedicated process or thread for each request (like servers with a traditional architecture), it handles multiple connections and requests in one worker process. To achieve this, NGINX works with sockets in a non‑blocking mode and uses efficient methods such as epoll and kqueue.核心词：异步，事件驱动，链接控制 解释的很清楚，nginx并不是通过每个请求都创建线程，而是通过内部管理的调度分配。如下图：此处不翻译了，大家直接看原版epoll详解：【跳转】 3.4.2 线程池官方说明 Let’s return to our poor sales assistant who delivers goods from a faraway warehouse. But he has become smarter (or maybe he became smarter after being beaten by the crowd of angry clients?) and hired a delivery service. Now when somebody asks for something from the faraway warehouse, instead of going to the warehouse himself, he just drops an order to a delivery service and they will handle the order while our sales assistant will continue serving other customers. Thus only those clients whose goods aren’t in the store are waiting for delivery, while others can be served immediately. 小拽认为简而言之：结合实际情况，除了空闲被动给，更多的通过事件驱动主动要，通过这种方式在执行资源紧缺的情况下，达到一个执行资源的优化部署，如下图。线程池官网详解：【跳转】 3.4.3 事件调度请求的具体调度基于事件，例如网络IO,磁盘IO,定时器等均可以对事件进行阻塞，当阻塞的事件空闲时，发出调度请求，完成处理。需要额外提一下，nginx的定时器基于rbtree，红黑树的快速插入和查询保证了nginx事件调度的高效性事件框架的处理模型 四、简单总结 性能：nginx 工作模式是master-worker进程方式，执行请求是有更轻量线程完成。 热加载：nginx 替换非更新的方式是nginx热加载的本质 功能强大：nginx upstream是在线程层面调度，兼容多种，所以可以扩展很多功能强大 处理流程：主要的流程过程和模块分离清晰。 请求处理：通过自身的管理，线程池，异步事件驱动等当来完成任务调度 再次强调：初探nginx，有疑问或不准确的地方，请直接开炮！！！ 五、参考文章 netcraft：https://news.netcraft.com/archives/2017/01/12/january-2017-web-server-survey.html nginx的线程调度设计：https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/ epoll详述：http://man7.org/linux/man-pages/man7/epoll.7.html http://yaocoder.blog.51cto.com/2668309/888374 线程池：https://www.nginx.com/blog/thread-pools-boost-performance-9x/ 【转载请注明：【【nginx学习一】基本原理学习 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>nginx</tag>
        <tag>基本原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【redis学习三】简单高可用redis架构实践]]></title>
    <url>%2F2017%2F02%2F05%2Fredis3%2F</url>
    <content type="text"><![CDATA[背景：支撑线上千万级别的天级查询请求，要求高可用。 一、方案调研1.1 redis版本选择redis当前主流版本是redis 2.x 和 redis 3.x，3.0对集群支持比较不错，官方解释如下： Redis是一个开源、基于C语言、基于内存亦可持久化的高性能NoSQL数据库，同时，它还提供了多种语言的API。近日，Redis 3.0在经过6个RC版本后，其正式版终于发布了。Redis 3.0的最重要特征是对Redis集群的支持，此外，该版本相对于2.8版本在性能、稳定性等方面都有了重大提高。 综合考虑之后扩展性和稳定性之后，选择版本 redis 3.2.3-1版本进行部署 1.2 是否选择搭建集群是否搭建集群关键要看单机是否能够满足业务需求，做了个简单的数据评估。 数据量评估 测试：单机写入2000w业务数据，占用内存1.5g，本机126g内存 评估：单机的稳定数据承载量：2000w （126/1.56） 0.6 = 96923w 结论：9T 的数据承载量，远超当前千万级别的数据量 性能评估 测试：简单压测了下 写操作 1000w，80% 在20ms一下 ，98%在30ms，最大218ms，qps 5w/s，总耗时197s 读操作 1000w，97% 在10ms一下 ，99.99%在24ms，qps 6w/s，总耗时160s 评估：当前的调用量在千万每天，qps的话在百/s。 结论：当前单机的redis完全满足需求 因此：在单机远能够满足当下业务需求的情况下，决定不采用的集群的方式来部署redis，减少技术债务风险。 1.3 初定方案和架构图选定了版本和基本部署方案之后，主要考虑服务的容灾和稳定性，经过思考之后采用采用极简的主从从结构，001实时同步数据002和003；001读写，002，003只读，机构图如下 二、实现过程2.1 redis安装此处略去，参考官方文档 https://redis.io/ 2.2 配置读写master 修改端口：port 【目的：简单的修改默认端口是最好的防攻击】 添加密码：pwd 关闭压缩：rdbcompression no 【硬盘最够，降低cpu的能耗更利于提升性能】 开启守护进程：daemonize yes 【master开启守护，增加稳定性】 关闭protect-mode :允许他机器访问 添加白名单：bind xxx 修改log地址，pid地址和数据存储地址：logfile pidfile 【便于维护和安全】 添加慢查询：slowlog-log-slower-than 500 【根据业务需求，便于优化】 最大内存限制：maxmemory 【考虑稳定性和性能，一般不超过最大内存的60%】 2.3 配置只读slave 同master 设置主库:slaveof ip:port 主库密码：masterauth masterpwd 只读：slave-read-only yes 2.4 启动测试启动主库写入数据 进入从库查看最初没有数据，主库写入之后，从库去到数据 查看log确认过程 三、架构能力评估3.1 容灾能力 主动容灾 备份：master 全量备份，slave全量备份。 备份安全：本机保存，hadoop同步保存一份。 监控和探活：监控机分钟级探活和预警 被动容灾： slave 宕机：重启之后直接从master恢复 master 宕机且硬盘数据为损坏：重启后数据自动恢复且和从库一致。 master 宕机且数据损坏：删除损坏数据，使用slave1的数据恢复，保证数据一致。 master 和slave 1 同时宕机：slave2 保证读正常，业务不影响，利用slave2 数据备份恢复master，启动slave 即可 三台全宕机：服务挂掉，从hadoop获取数据恢复服务。 3.2 性能评估压测数据，参见方案选择，完全hold住。 四、问题思考4.1 内存清理策略暂时采用：noeviction -&gt; 谁也不删，直接在写操作时返回错误。之后采用：volatile-lru -&gt; 根据LRU算法删除带有过期时间的key。 最少使用算法删除。如果达到内存限制，手工清理，通过监控脚本监控内存情况 4.2 伸缩性和单节点问题扩展slave可以直接扩展，扩展master需要master之间数据同步，暂时是个瓶颈。对于主读业务的需求，暂时问题不大；写需求的话，暂时的想法是代码转写的方式。 4.3 采用redis sentinal 监听默认不错的监听，尝试了下效果不错，还在调研中，配置conf即可，完成后可以查看监听的情况12345678127.0.0.1:port&gt; INFO Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redis115,status=ok,address=ip:port,slaves=2,sentinels=1 五：常用代码12345678910# 强制杀死redis，模仿宕机ps aux |grep redis |awk '&#123;print $2&#125;'|xargs kill -9# 优化模拟宕机 【根据Dual-X-raY提示-_-】redis&gt; DEBUG SEGFAULT# 重启，指定conf/home/work/xxx/bin/redis-server /home/work/xxx/etc/redis.conf# 压测，具体参数可以参考benchmark[cuihuan@cuihuan bin]$ ./redis-benchmark -h 127.0.0.1 -p 端口 -a 密码 -c 1000 -n 10000000 -d 1024 -r 100000 -t set,get,incr,del 【转载请注明：【redis学习三】简单高可用redis架构实践 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>redis</tag>
        <tag>高可用架构</tag>
        <tag>容灾方案</tag>
        <tag>redis主从</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php爬虫：知乎用户数据爬取和分析]]></title>
    <url>%2F2017%2F01%2F20%2Fcharactor%2F</url>
    <content type="text"><![CDATA[背景说明：小拽利用php的curl写的爬虫，实验性的爬取了知乎5w用户的基本信息；同时，针对爬取的数据，进行了简单的分析呈现。demo 地址 php的spider代码和用户dashboard的展现代码，整理后上传github，在个人博客和公众号更新代码库，程序仅供娱乐和学习交流；如果有侵犯知乎相关权益，请尽快联系本人删除。 无图无真相移动端分析数据截图 pc端分析数据截图 整个爬取，分析，展现过程大概分如下几步，小拽将分别介绍 curl爬取知乎网页数据 正则分析知乎网页数据 数据数据入库和程序部署 数据分析和呈现 curl爬取网页数据PHP的curl扩展是PHP支持的，允许你与各种服务器使用各种类型的协议进行连接和通信的库。是一个非常便捷的抓取网页的工具，同时，支持多线程扩展。 本程序抓取的是知乎对外提供用户访问的个人信息页面https://www.zhihu.com/people/xxx,抓取过程需要携带用户cookie才能获取页面。直接上码 获取页面cookie 123// 登录知乎，打开个人中心，打开控制台，获取cookiedocument.cookie"_za=67254197-3wwb8d-43f6-94f0-fb0e2d521c31; _ga=GA1.2.2142818188.1433767929; q_c1=78ee1604225d47d08cddd8142a08288b23|1452172601000|1452172601000; _xsrf=15f0639cbe6fb607560c075269064393; cap_id="N2QwMTExNGQ0YTY2NGVddlMGIyNmQ4NjdjOTU0YTM5MmQ=|1453444256|49fdc6b43dc51f702b7d6575451e228f56cdaf5d"; __utmt=1; unlock_ticket="QUJDTWpmM0lsZdd2dYQUFBQVlRSlZUVTNVb1ZaNDVoQXJlblVmWGJ0WGwyaHlDdVdscXdZU1VRPT0=|1453444421|c47a2afde1ff334d416bafb1cc267b41014c9d5f"; __utma=51854390.21428dd18188.1433767929.1453187421.1453444257.3; __utmb=51854390.14.8.1453444425011; __utmc=51854390; __utmz=51854390.1452846679.1.dd1.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); __utmv=51854390.100-1|2=registration_date=20150823=1^dd3=entry_date=20150823=1" 抓取个人中心页面通过curl，携带cookie，先抓取本人中心页面 123456789101112131415161718192021/** * 通过用户名抓取个人中心页面并存储 * * @param $username str :用户名 flag * @return boolean :成功与否标志 */public function spiderUser($username)&#123; $cookie = "xxxx" ; $url_info = 'http://www.zhihu.com/people/' . $username; //此处cui-xiao-zhuai代表用户ID,可以直接看url获取本人id $ch = curl_init($url_info); //初始化会话 curl_setopt($ch, CURLOPT_HEADER, 0); curl_setopt($ch, CURLOPT_COOKIE, $cookie); //设置请求COOKIE curl_setopt($ch, CURLOPT_USERAGENT, $_SERVER['HTTP_USER_AGENT']); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); //将curl_exec()获取的信息以文件流的形式返回，而不是直接输出。 curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 1); $result = curl_exec($ch); file_put_contents('/home/work/zxdata_ch/php/zhihu_spider/file/'.$username.'.html',$result); return true; &#125; 正则分析网页数据分析新链接，进一步爬取对于抓取过来的网页进行存储，要想进行进一步的爬取，页面必须包含有可用于进一步爬取用户的链接。通过对知乎页面分析发现：在个人中心页面中有关注人和部分点赞人和被关注人。如下所示12// 抓取的html页面中发现了新的用户，可用于爬虫&lt;a class="zm-item-link-avatar avatar-link" href="/people/new-user" data-tip="p$t$new-user"&gt; ok，这样子就可以通过自己-》关注人-》关注人的关注人-》。。。进行不断爬取。接下来就是通过正则匹配提取该信息 12345// 匹配到抓取页面的所有用户preg_match_all('/\/people\/([\w-]+)\"/i', $str, $match_arr);// 去重合并入新的用户数组,用户进一步抓取self::$newUserArr = array_unique(array_merge($match_arr[1], self::$newUserArr)); 到此，整个爬虫过程就可以顺利进行了。如果需要大量的抓取数据，可以研究下curl_multi和pcntl进行多线程的快速抓取，此处不做赘述。 分析用户数据，提供分析通过正则可以进一步匹配出更多的该用户数据，直接上码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 获取用户头像preg_match('/&lt;img.+src=\"?([^\s]+\.(jpg|gif|bmp|bnp|png))\"?.+&gt;/i', $str, $match_img);$img_url = $match_img[1];// 匹配用户名：// &lt;span class="name"&gt;崔小拽&lt;/span&gt;preg_match('/&lt;span.+class=\"?name\"?&gt;([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+span&gt;/u', $str, $match_name);$user_name = $match_name[1];// 匹配用户简介// class bio span 中文preg_match('/&lt;span.+class=\"?bio\"?.+\&gt;([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+span&gt;/u', $str, $match_title);$user_title = $match_title[1];// 匹配性别//&lt;input type="radio" name="gender" value="1" checked="checked" class="male"/&gt; 男&amp;nbsp;&amp;nbsp;// gender value1 ;结束 中文preg_match('/&lt;input.+name=\"?gender\"?.+value=\"?1\"?.+([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+\;/u', $str, $match_sex);$user_sex = $match_sex[1];// 匹配地区//&lt;span class="location item" title="北京"&gt;preg_match('/&lt;span.+class=\"?location.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)\"&gt;/u', $str, $match_city);$user_city = $match_city[1];// 匹配工作//&lt;span class="employment item" title="人见人骂的公司"&gt;人见人骂的公司&lt;/span&gt;preg_match('/&lt;span.+class=\"?employment.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)\"&gt;/u', $str, $match_employment);$user_employ = $match_employment[1];// 匹配职位// &lt;span class="position item" title="程序猿"&gt;&lt;a href="/topic/19590046" title="程序猿" class="topic-link" data-token="19590046" data-topicid="13253"&gt;程序猿&lt;/a&gt;&lt;/span&gt;preg_match('/&lt;span.+class=\"?position.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+).+\"&gt;/u', $str, $match_position);$user_position = $match_position[1];// 匹配学历// &lt;span class="education item" title="研究僧"&gt;研究僧&lt;/span&gt;preg_match('/&lt;span.+class=\"?education.+\"?.+\"([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)\"&gt;/u', $str, $match_education);$user_education = $match_education[1];// 工作情况// &lt;span class="education-extra item" title='挨踢'&gt;挨踢&lt;/span&gt;preg_match('/&lt;span.+class=\"?education-extra.+\"?.+&gt;([\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+)&lt;/u', $str, $match_education_extra);$user_education_extra = $match_education_extra[1];// 匹配关注话题数量// class="zg-link-litblue"&gt;&lt;strong&gt;41 个话题&lt;/strong&gt;&lt;/a&gt;preg_match('/class=\"?zg-link-litblue\"?&gt;&lt;strong&gt;(\d+)\s.+strong&gt;/i', $str, $match_topic);$user_topic = $match_topic[1];// 关注人数// &lt;span class="zg-gray-normal"&gt;关注了preg_match_all('/&lt;strong&gt;(\d+)&lt;.+&lt;label&gt;/i', $str, $match_care);$user_care = $match_care[1][0];$user_be_careed = $match_care[1][1];// 历史浏览量// &lt;span class="zg-gray-normal"&gt;个人主页被 &lt;strong&gt;17&lt;/strong&gt; 人浏览&lt;/span&gt;preg_match('/class=\"?zg-gray-normal\"?.+&gt;(\d+)&lt;.+span&gt;/i', $str, $match_browse);$user_browse = $match_browse[1]; 数据入库和程序优化在抓取的过程中，有条件的话，一定要通过redis入库，确实能提升抓取和入库效率。没有条件的话只能通过sql优化。这里来几发心德。 数据库表设计索引一定要慎重。在spider爬取的过程中，建议出了用户名，左右字段都不要索引，包括主键都不要，尽可能的提高入库效率，试想5000w的数据，每次添加一个，建立索引需要多少消耗。等抓取完毕，需要分析数据时，批量建立索引。 数据入库和更新操作，一定要批量。 mysql 官方给出的增删改的建议和速度：http://dev.mysql.com/doc/refman/5.7/en/insert-speed.html 12# 官方的最优批量插入INSERT INTO yourtable VALUES (1,2), (5,5), ...; 部署操作。程序在抓取过程中，有可能会出现异常挂掉，为了保证高效稳定，尽可能的写一个定时脚本。每隔一段时间干掉，重新跑，这样即使异常挂掉也不会浪费太多宝贵时间，毕竟，time is money。 12345678#!/bin/bash# 干掉ps aux |grep spider |awk '&#123;print $2&#125;'|xargs kill -9sleep 5s# 重新跑nohup /home/cuixiaohuan/lamp/php5/bin/php /home/cuixiaohuan/php/zhihu_spider/spider_new.php &amp; 数据分析呈现数据的呈现主要使用echarts 3.0，感觉对于移动端兼容还不错。兼容移动端的页面响应式布局主要通过几个简单的css控制，代码如下 12345678910111213141516171819202122232425262728293031323334/*兼容性和响应式div设计*/@media screen and (max-width: 480px) &#123; body&#123; padding: 0 ; &#125; .adapt-div &#123; width: 100% ; float: none ; margin: 20px 0; &#125; .half-div &#123; height: 350px ; margin-bottom: 10px; &#125; .whole-div &#123; height: 350px; &#125;&#125;&lt;!-- 整块完整布局，半块在web端采用float的方式，移动端去掉--&gt;.half-div &#123; width: 48%; height: 430px; margin: 1%; float: left&#125;.whole-div &#123; width: 98%; height: 430px; margin: 1%; float: left&#125; 不足和待学习整个过程中涉及php,shell,js,css,html,正则等语言和部署等基础知识，但还有诸多需要改进完善，小拽特此记录，后续补充例： php 采用multicul进行多线程。 正则匹配进一步优化 部署和抓取过程采用redis提升存储 移动端布局的兼容性提升 js的模块化和sass书写css。 【转载请注明：php爬虫：知乎用户数据爬取和分析 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>javascript</tag>
        <tag>网页爬虫</tag>
        <tag>shell</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【高并发简单解决方案】redis队列缓存 + 批量入库 + php离线整合]]></title>
    <url>%2F2017%2F01%2F20%2F%E3%80%90%E9%AB%98%E5%B9%B6%E5%8F%91%E7%AE%80%E5%8D%95%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%91redis%E9%98%9F%E5%88%97%E7%BC%93%E5%AD%98%20%2B%20mysql%20%E6%89%B9%E9%87%8F%E5%85%A5%E5%BA%93%20%2B%20php%E7%A6%BB%E7%BA%BF%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[需求背景：有个调用统计日志存储和统计需求，要求存储到mysql中；存储数据高峰能达到日均千万，瓶颈在于直接入库并发太高，可能会把mysql干垮。 问题分析思考：应用网站架构的衍化过程中，应用最新的框架和工具技术固然是最优选择；但是，如果能在现有的框架的基础上提出简单可依赖的解决方案，未尝不是一种提升自我的尝试。 解决： 问题一：要求日志最好入库；但是，直接入库mysql确实扛不住，批量入库没有问题，done。【批量入库和直接入库性能差异参考文章】 问题二：批量入库就需要有高并发的消息队列，决定采用redis list 仿真实现，而且方便回滚。 问题三：日志量毕竟大，保存最近30条足矣，决定用php写个离线统计和清理脚本。 done，下面是小拽的简单实现过程 一：设计数据库表和存储 考虑到log系统对数据库的性能更多一些，稳定性和安全性没有那么高，存储引擎自然是只支持select insert 没有索引的archive。如果确实有update需求，也可以采用myISAM。 考虑到log是实时记录的所有数据，数量可能巨大，主键采用bigint，自增即可。 考虑到log系统以写为主，统计采用离线计算，字段均不要出现索引，因为一方面可能会影响插入数据效率，另外读时候会造成死锁，影响写数据。 二：redis存储数据形成消息队列由于高并发，尽可能简单，直接，上代码。123456789101112131415161718192021222324252627282930313233&lt;?php/***************************************************************************** 获取到的调用日志，存入redis的队列中.* $Id$***************************************************************************//*** @file saveLog.php* @date 2015/11/06 20:47:13* @author:cuihuan* @version $Revision$* @brief***/// 获取info$interface_info = $_GET['info'];// 存入redis队列$redis = new Redis();$redis-&gt;connect('xx', 6379);$redis-&gt;auth("password");// 加上时间戳存入队列$now_time = date("Y-m-d H:i:s");$redis-&gt;rPush("call_log", $interface_info . "%" . $now_time);$redis-&gt;close();/* vim: set ts=4 sw=4 sts=4 tw=100 */?&gt; 三：数据定时批量入库。定时读取redis消息队列里面的数据，批量入库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;?php/** * 获取redis消息队列中的脚本，拼接sql，批量入库。 * @update 2015-11-07 添加失败消息队列回滚机制 * * @Author:cuihuan * 2015-11-06 * */// init redis$redis_xx = new Redis();$redis_xx-&gt;connect('ip', port);$redis_xx-&gt;auth("password");// 获取现有消息队列的长度$count = 0;$max = $redis_xx-&gt;lLen("call_log");// 获取消息队列的内容，拼接sql$insert_sql = "insert into fb_call_log (`interface_name`, `createtime`) values ";// 回滚数组$roll_back_arr = array();while ($count &lt; $max) &#123; $log_info = $redis_cq01-&gt;lPop("call_log"); $roll_back_arr = $log_info; if ($log_info == 'nil' || !isset($log_info)) &#123; $insert_sql .= ";"; break; &#125; // 切割出时间和info $log_info_arr = explode("%",$log_info); $insert_sql .= " ('".$log_info_arr[0]."','".$log_info_arr[1]."'),"; $count++;&#125;// 判定存在数据，批量入库if ($count != 0) &#123; $link_2004 = mysql_connect('ip:port', 'user', 'password'); if (!$link_2004) &#123; die("Could not connect:" . mysql_error()); &#125; $crowd_db = mysql_select_db('fb_log', $link_2004); $insert_sql = rtrim($insert_sql,",").";"; $res = mysql_query($insert_sql); // 输出入库log和入库结果; echo date("Y-m-d H:i:s")."insert ".$count." log info result:"; echo json_encode($res); echo "&lt;/br&gt;\n"; // 数据库插入失败回滚 if(!$res)&#123; foreach($roll_back_arr as $k)&#123; $redis_xx-&gt;rPush("call_log", $k); &#125; &#125; // 释放连接 mysql_free_result($res); mysql_close($link_2004);&#125;// 释放redis$redis_cq01-&gt;close();?&gt; 四：离线天级统计和清理数据脚本123456789101112131415161718192021222324252627282930313233343536?php/*** static log ：每天离线统计代码日志和删除五天前的日志** @Author:cuihuan* 2015-11-06* */// 离线统计$link_2004 = mysql_connect('ip:port', 'user', 'pwd');if (!$link_2004) &#123; die("Could not connect:" . mysql_error());&#125;$crowd_db = mysql_select_db('fb_log', $link_2004);// 统计昨天的数据$day_time = date("Y-m-d", time() - 60 * 60 * 24 * 1);$static_sql = "get sql";$res = mysql_query($static_sql, $link_2004);// 获取结果入库略// 清理15天之前的数据$before_15_day = date("Y-m-d", time() - 60 * 60 * 24 * 15);$delete_sql = "delete from xxx where createtime &lt; '" . $before_15_day . "'";try &#123; $res = mysql_query($delete_sql);&#125;catch(Exception $e)&#123; echo json_encode($e)."\n"; echo "delete result:".json_encode($res)."\n";&#125;mysql_close($link_2004);?&gt; 五：代码部署主要是部署，批量入库脚本的调用和天级统计脚本，crontab例行运行。12345# 批量入库脚本*/2 * * * * /home/cuihuan/xxx/lamp/php5/bin/php /home/cuihuan/xxx/batchLog.php &gt;&gt;/home/cuihuan/xxx/batchlog.log# 天级统计脚本0 5 * * * /home/cuihuan/xxx/php5/bin/php /home/cuihuan/xxx/staticLog.php &gt;&gt;/home/cuihuan/xxx/staticLog.log 总结：相对于其他复杂的方式处理高并发，这个解决方案简单有效：通过redis缓存抗压，mysql批量入库解决数据库瓶颈，离线计算解决统计数据，通过定期清理保证库的大小。 【转载请注明：高并发简单解决方案 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>mysql</tag>
        <tag>redis</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fsck修复linux文件损坏]]></title>
    <url>%2F2016%2F08%2F20%2Ffsck%E4%BF%AE%E5%A4%8Dlinux%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%2F</url>
    <content type="text"><![CDATA[数据一定要备份，最好多机备份，代码一定要ci。 背景和损失背景：机房事故，突然关机，硬盘年老失修，造成很多文件不可用。如图 面临损失：作为一名靠谱程序员，数据库单机多机备份，程序版本控制这些都是有的【如果没有，一定要加上】；但这次有一个重要影响，就是git中commit之后，没有push的文件全损坏了，损坏了，坏了，了。。。。 分析原因op给出的说法是网络波动，造成机房故障，机器重启。但从结果看，文件系统乱掉了，而且乱掉的文件主要分两类： 1：当时正在写入和操作的文件。例如运行的脚本，正在写的文件，samba建立网络映射的文件，git实时文件。 2：内存里的数据，例如memcache里的数据等等 处理：fsck修复。###1：查看硬盘挂载：df查看下磁盘的挂载位置。 2：操作挂起：不挂起可能会出现数据恢复中断。报错：直接挂起会出现 dev is busy，如下图用：umout -l /dev/sda31234#umount -l &lt;挂载点|设备&gt;此命令将会断开设备并关闭打开该设备的全部句柄。通常，您可以使用 eject &lt;挂载点|设备&gt;命令弹出碟片 3：fsck 扫盘1fsck -f /dev/sda3 注意ext2 还会进行e2fsck 再扫一遍，此为正常操作 4：扫盘结束后，挂载驱动盘5：寻找和恢复文件把.git 内的文件全部整理，导出，一个一个寻找自己需要的文件，找到了久违的文件。 后续一句话：代码一定要ci，数据一定要容灾 【转载请注明：fsck修复linux文件损坏 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>linux</tag>
        <tag>git修复</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【page-monitor 前端自动化 下篇】 实践应用]]></title>
    <url>%2F2016%2F08%2F20%2F%E3%80%90page-monitor%20%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96%20%E4%B8%8B%E7%AF%87%E3%80%91%20%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[通过page-diff的初步调研和源码分析，确定page-diff在前端自动化测试和监控方面做一些事情。本篇主要介绍下，page-diff在具体的实践中的一些应用 核心dom校验前端的快速发展，造成前端dom无论结构还是命名经常变化，每次都尽可能关注每个dom的变化，不可能也没有必要。但是核心dom是相对变化较小，但是比较重要，因此可以利用page-monitor 修改关注结构中的核心代码，核心架构的变化。 上图是未修改的代码，下图是忽略footer内部变化实践中可以针对自身的核心dom进行进一步优化 局部dom校验项目中，往往在某一时期特别关心某些板块，或者某些板块相对容易出错；因此，可以利用page-monitor 进行局部dom的细节diff。中篇中对只针对header进行对比diff做了详细介绍，此处不赘述，上图。 算法优化由于获取了完整了dom的json，因此可以通过相关阈值的设定或者算法的优化；来对比结果，进行更加优化的分级预警和分析；作者一般对非核心预警超过15%变化会做出预警，超过更高阈值会进一步的预警等等。贴一个dom 细节图 其他分析小拽通过上面的举例，旨在抛砖引玉，希望page-monitor或者dom结构在前端的自动化测试有一定应用，提升产品质量。 最终再上一张流程图，便于分析 相关文章：【page-monitor 前端自动化 上篇】 初步调研【page-monitor 前端自动化 中篇】 源码分析]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>前端</tag>
        <tag>自动化测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[phpredis单例模式封装]]></title>
    <url>%2F2016%2F08%2F08%2Fphpredis%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%B0%81%E8%A3%85%2F</url>
    <content type="text"><![CDATA[通过单例模式实现对phpredis连接的封装。 直接上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?php/** * Class RedisConnManager * * 单例模式对redis实例的操作的进一步封装 * 主要目的：防止过多的连接，一个页面只能存在一个声明连接 * * @author ：cuihuan */class RedisManager&#123; private static $redisInstance; /** * 私有化构造函数 * 原因：防止外界调用构造新的对象 */ private function __construct()&#123;&#125; /** * 获取redis连接的唯一出口 */ static public function getRedisConn()&#123; if(!self::$redisInstance instanceof self)&#123; self::$redisInstance = new self; &#125; // 获取当前单例 $temp = self::$redisInstance; // 调用私有化方法 return $temp-&gt;connRedis(); &#125; /** * 连接ocean 上的redis的私有化方法 * @return Redis */ static private function connRedis() &#123; try &#123; $redis_ocean = new Redis(); $redis_ocean-&gt;connect(G::$conf['redis-host'], G::$conf['redis-port']); $redis_ocean-&gt;auth(G::$conf['redis-pass']); &#125;catch (Exception $e)&#123; echo $e-&gt;getMessage().'&lt;br/&gt;'; &#125; return $redis_ocean; &#125;&#125; 【转载请注明：phpredis单例模式封装 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>redis</tag>
        <tag>单例模式</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【page-monitor 前端自动化 中篇】 源码分析]]></title>
    <url>%2F2016%2F08%2F07%2Fpage_monitor_second%2F</url>
    <content type="text"><![CDATA[上篇中初探了page-monitor的一些功能和在前端自动化测试方面的可行性，本篇主要分析下page-monitor的实现方式和源码。 mode-module简介page-monitor的存在形式是node-module，依赖于node安装和运行，简单必须了解下node_modules node-module是nodejs的模块，符合commonJs规范【具体规范可以参考：http://javascript.ruanyifeng.com/nodejs/module.html】 简单描述commonJs规范1：文件即模块，作用域在文件内，不允许重复，不会污染。2：加载依赖出现顺序，加载即运行，重复则利用缓存。 多说一句：这是amd 和cmd(commonJs)的本质区别，由于node多运行于服务端，加载比较快，因此比较适合cmd 规范，浏览器端的模块则更适用于cmd的规范，个人理解没有广义的好坏之分 方便看源码，贴出node_modole简单构成和主要函数modulenode内部提供一了一个modle的构造函数，所有的模块都继承和依赖于此模块。node module的引入 require命令。其他加载规则，路径设定不在此赘述。 page-monitor文件分析完整文件目录： 运行生成目录分析： 出了node_module及其组件代码，可用和值的分析的文件index.js 和phantomjs 下面的五个文件。 分析index.js代码中无非变量声明和引用，关键一句引用phantom的命令乳腺12// 多线程启动位置var proc = spawn(binPath, arr); 通过上面多线程的启动node可以达到高效和并发处理测试任务的需求，分析下arr的内容如下图：看到了 窗口大小，延时，ua，存放地址，diff变量等等 分析获取DOM源码获取dom的源码主要利用了web api evalution，evalution传入一个xpath的参数，返回一个xpath的对象，之后通过遍历和xpath规则生成规则化的json。贴一个evalution api 为了看懂page-monitor的代码举个栗子123456789101112# evalution example:var headings = document.evaluate("/html/body//h2", document, null, XPathResult.ANY_TYPE, null);/* 检索body中所有H2的所欲. * 结果存在于一个node的迭代器中 */var thisHeading = headings.iterateNext();var alertText = "Level 2 headings in this document are:\n";while (thisHeading) &#123; alertText += thisHeading.textContent + "\n"; thisHeading = headings.iterateNext();&#125;alert(alertText); // Alerts the text of all h2 elements 通过上面函数和page-monitor中walk.js函数最后一行，可以看出page-monitor 保存了四个元素：属性[name,id等等]，节点类型，位置[后期渲染]，样式的md5加密[样式仅需要对比是否变化即可]具体内容和dom结构如下： 对应的具体dom结构 diff.js 代码diff代码主要两个作用 1：获取差异 2：渲染差异其中对比的策略： 历史完全每个对比现在：获取更新和删除的内容现在完全每个对比历史：获取更新和新增的内容具体可以参考代码 其他api和源码简单修改必须了解的web api 还有一个是querySeletor 也就是检索的api，参考地址document.querySelector()了解了这个api就可以做一件事情：不对全局dom diff，只对特别关心的dom进行diff实现方式：修改querySelector的根节点为Header获取的dom结构如下：根节点为header 获取的页面截图如下： 代码流程图 总结本次在调研page-monitor的基础上，对page-monitor的源码实现进行分析；同时利用相关api修改，来只对核心页面进行获取优化。下一篇将会进一步思考page-monitor的应用。 相关文章：【page-monitor 前端自动化 上篇】 初步调研【page-monitor 前端自动化 下篇】 实践应用]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>自动化测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【page-monitor 前端自动化 上篇】初步调研]]></title>
    <url>%2F2016%2F08%2F07%2F%E3%80%90page-monitor%20%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96%20%E4%B8%8A%E7%AF%87%E3%80%91%E5%88%9D%E6%AD%A5%E8%B0%83%E7%A0%94%20%2F</url>
    <content type="text"><![CDATA[前端自动化测试主要在于：变化快，不稳定，兼容性复杂；故而，想通过较低的成本维护较为通用的自动化case比较困难。本文旨在通过page-monitor获取和分析dom结构，调研能否通过监控和分析核心dom，来进行前端自动化测试。 一：page-monitor 介绍page-monitor：通过xpath获取dom节点结构，之后可视化的渲染出页面的差异。github地址：https://github.com/fouber/page-monitor基本原理：利用xpath获取页面的dom结构，存储为结构化的json，对比两次的json之间的差异，利用phantom渲染页面和差异页面。 先上个初次试用的图 二：初次试用2.1 安装123# page-monitor 依赖于 phantomjsnpm install phantomjsnpm install page-monitor 注意：phantomJs较大，如果比较慢 可以用brew安装，并且page-monitor最多兼容phantom1.9812345# 调整phantom为1.98 版本MacBook-Pro:~ cuixiaohuan$ brew link phantomjs198Linking /usr/local/Cellar/phantomjs198/1.9.8... 2 symlinks createdMacBook-Pro:~ cuixiaohuan$ phantomjs -v1.9.8 2.2 初次运行：写一个test.js 代码如下:12345678var Monitor = require('page-monitor');var url = 'http://www.baidu.com';var monitor = new Monitor(url);monitor.capture(function(code)&#123; console.log(monitor.log); // from phantom console.log('done, exit [' + code + ']');&#125;); 运行效果12345678910111213141516171819MacBook-Pro:test cuixiaohuan$ node test.js&#123; debug: [ 'mode: 11', 'need diff', 'loading: http://www.baidu.com', 'page.viewportSize = &#123;"width":320,"height":568&#125;', 'page.settings.resourceTimeout = 20000', 'page.settings.userAgent = "Mozilla/5.0 (iPhone; CPU iPhone OS 7_0 like Mac OS X; en-us) AppleWebKit/537.51.1 (KHTML, like Gecko) Version/7.0 Mobile/11A465 Safari/9537.53"', 'loaded: http://www.baidu.com', 'delay before render: 0ms', 'walk tree', 'save capture [/Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/www.baidu.com/Lw==/1461155680901]', 'screenshot [/Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/www.baidu.com/Lw==/1461155680901/screenshot.jpg]', 'Unsafe JavaScript attempt to access frame with URL about:blank from frame with URL file:///Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/node_modules/page-monitor/phantomjs/index.js. Domains, protocols and ports must match.' ], warning: [], info: [], error: [], notice: [] &#125;done, exit [0] 2.2 生成对比页面 test.js code 1234monitor.diff(1408947323420, 1408947556898, function(code)&#123; console.log(monitor.log.info); // diff result console.log('[DONE] exit [' + code + ']');&#125;); 运行123MacBook-Pro:test cuixiaohuan$ node test.js[ '&#123;"diff":&#123;"left":"1461155680901","right":"1461163758667","screenshot":"/Users/cuixiaohuan/Desktop/workspace/test/pagemonitor/test/www.baidu.com/Lw==/diff/1461155680901-1461163758667.jpg","count":&#123;"add":2,"remove":2,"style":0,"text":9&#125;&#125;&#125;' ][DONE] exit [0] 2.3 对比页面效果如下图 2.4 目录初步分析通过目录和运行结果1：每个时间利用phantom生成一张截图【保存现场】和一个dome的tree.json【对比dom】 【生成过程看下源码】2：diff 调用tree.json 比较区中的区别【位置，内容生成和对比过程之后看下源码？】3：利用当时保存的截图渲染生成的结果 三：dom diff工具page monitor 调研初步结论： 1：dom的diff 是可行的。 2：page monitor 现有主要功能：抽取不同时间段的页面做页面domdiff使用过程中缺陷：1：依赖太多，依赖node，依赖phantom，2：接口太少，现在直接提供的就两个一个保存现场，一个diff。不方便dom定制和阈值定制。 四：应用价值思考和下一步如果能对dom树的处理更完善一些，应用价值还是挺高的，例如核心dom的diff，局部dom的diff，时效性dom(例如：时间tag必须变化，不变化则为bug)的变更检验，兼容性dom的check等等 下一步调研：看下源码中，分析dom生成tree过程，对比tree过程，展现tree过程。 相关文章：【page-monitor 前端自动化 中篇】 源码分析【page-monitor 前端自动化 下篇】 实践应用]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>自动化测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【chrome 插件一】开发一个简单chrome浏览器插件]]></title>
    <url>%2F2016%2F04%2F26%2Fchrome_1%2F</url>
    <content type="text"><![CDATA[chrome 之所以越来越好用，很大一部分原因归功于功能丰富的插件；对于chrome忠实用户来说，了解和开发一款适合自己的chrome插件，确实是一件很cool的事情。 了解chrome 插件chrome 插件个人理解：就是一个html + js +css + image的一个web应用；不同于普通的web应用，chrome插件除了兼容普通的js，json，h5等api，还可以调用一些浏览器级别的api，例如收藏夹，历史记录等。 推荐两个网站了解和入门谷歌官方API：https://developer.chrome.com/extensions/getstarted360的文档：http://open.chrome.360.cn/extension_dev/overview.html 开始写第一个插件文件结构一个简单的demo，文件目录如下和普通的web文件没有什么区别，简单介绍下 html:存放html页面 js :存放js locales ：存放了一个多语言的兼容【可无】 image ：放了两张图片【初期图标】 manifest ：核心入口文件 写一个manifestapi参考文档 :http://open.chrome.360.cn/extension_dev/manifest.html 直接上代码：12345678910111213141516171819202122232425262728293031323334353637383940&#123; "name": "hijack analyse plug", "version": "0.0.1", "manifest_version": 2, // 简单描述 "description": "chrome plug analyse and guard the http hijack", "icons": &#123; "16": "image/icon16.png", "48": "image/icon48.png" &#125;, // 选择默认语言 "default_locale": "en", // 浏览器小图表部分 "browser_action": &#123; "default_title": "反劫持", "default_icon": "image/icon16.png", "default_popup": "html/test.html" &#125;, // 引入一个脚本 "content_scripts": [ &#123; "js": ["script/test.js"], // 在什么情况下使用该脚本 "matches": [ "http://*/*", "https://*/*" ], // 什么情况下运行【文档加载开始】 "run_at": "document_start" &#125; ], // 应用协议页面 "permissions": [ "http://*/*", "https://*/*" ]&#125; test.js 文件1234567891011/** * @author: cuixiaohuan * Date: 16/4/13 * Time: 下午8:41 */(function()&#123; /** * just test for run by self */ console.log('begin');&#125;)(); test.html 文件12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;just for test&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;test&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 运行插件chrome 中输入：chrome://extensions选择加载已解压的插件-》选择文件根目录即可。效果如下： 一个基本的插件变完成了，勾选已启用，随便打开一个网页，会看到log中输出如下 点击页面上面的小图标如下图： 优化建议一个小的插件已经完成，但是还有更多的api和有趣的事情可以去做。下面是360文档中给出一些优化建议，共勉。 确认 Browser actions 只使用在大多数网站都有功能需求的场景下。确认 Browser actions 没有使用在少数网页才有功能的场景， 此场景请使用page actions。 确认你的图标尺寸尽量占满19x19的像素空间。 Browser action 的图标应该看起来比page action的图标更大更重。 尽量使用alpha通道并且柔滑你的图标边缘，因为很多用户使用themes，你的图标应该在在各种背景下都表现不错。不要不停的闪动你的图标，这很惹人反感。 【转载请注明：【chrome 插件一】开发一个简单chrome浏览器插件 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>chrome-extension</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【chrome 插件二】添加菜单和添加消息提醒]]></title>
    <url>%2F2016%2F04%2F20%2Fchrome_2%2F</url>
    <content type="text"><![CDATA[上一篇中简单的接触了chrome插件，并且草草的制作一个chrome 插件（-_-只中看，不能用）；这次主要学习，browse action api制作菜单制作和调用系统提醒。 browse actionbrowse action 包括四部分：一个图标，一个tooltip，一个badge和一个pophtml先上代码和效果12345"browser_action": &#123; "default_title": "反劫持工具", "default_icon": "image/icon_19.png", "default_popup": "html/popup.html" &#125;, 图标图标优化：最好是19px，这样基本占满，可以直接使用图标也可以用h5 canvas element，同时，图片一定要是背景透明的。 ps处理后页面效果如下： tooltip直接设置default_title 效果是鼠标经过显示标题效果 badge:这个相当于设置图片文字和背景色：提供了两个方法：设置badge文字和颜色可以分别使用setBadgeText()andsetBadgeBackgroundColor()。 pophtml：创建菜单上码：能用代码说话的，不用文字js12345678910111213141516171819202122232425262728293031/** * @author: cuixiaohuan * Date: 16/4/19 * Time: 下午9:41 *//** * 点击菜单的事件 * * @param e */function click(e) &#123; chrome.tabs.executeScript(null, &#123; // 更改背景色 code: "document.body.style.backgroundColor='" + e.target.id + "'" &#125; ); window.close();&#125;/** * 页面加载完成后，监听事件 */document.addEventListener('DOMContentLoaded', function () &#123; var divs = document.querySelectorAll('div'); for (var i = 0; i &lt; divs.length; i++) &#123; divs[i].addEventListener('click', click); &#125;&#125;); html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Set Page Color Popup&lt;/title&gt; &lt;style&gt; body &#123; overflow: hidden; margin: 0px; padding: 0px; background: white; &#125; div:first-child &#123; margin-top: 0px; &#125; div &#123; cursor: pointer; text-align: center; padding: 1px 3px; font-family: sans-serif; font-size: 0.8em; width: 100px; margin-top: 1px; background: #cccccc; &#125; div:hover &#123; background: #aaaaaa; &#125; #red &#123; border: 1px solid red; color: red; &#125; #blue &#123; border: 1px solid blue; color: blue; &#125; #green &#123; border: 1px solid green; color: green; &#125; #yellow &#123; border: 1px solid yellow; color: yellow; &#125; &lt;/style&gt; &lt;script src="../script/changeBackgroud.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="red"&gt;红色小拽&lt;/div&gt; &lt;div id="blue"&gt;绿色小拽&lt;/div&gt; &lt;div id="green"&gt;蓝色小拽&lt;/div&gt; &lt;div id="yellow"&gt;换色小拽&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 效果图 调用系统提醒notification api 官方文档:https://developer.chrome.com/extensions/notifications注意 chrome32 之前的预警接口不太一样，文档中已经说明。 使用预警一定要加上权限统一123"permissions": [ "notifications"], 调用系统提醒代码1234567891011121314151617181920212223242526272829303132// 用户授权if (Notification.permission == "granted") &#123; Notification.requestPermission();&#125;/** * 调用系统提醒 * * 第一次进入页面需要授权，之后弹出提醒 */function notifyMe() &#123; if (!Notification) &#123; alert('Desktop notifications not available in your browser. Try Chromium.'); return; &#125; if (Notification.permission !== "granted")&#123; Notification.requestPermission(); &#125; else &#123; var notification = new Notification('小拽提醒', &#123; icon: 'http://cuihuan.net/wp-content/themes/quench-master/images/cuihuan_title.jpg', body: "别点击，点击跳转'靠谱崔小拽'" &#125;); notification.onclick = function () &#123; window.open("http://cuihuan.net"); &#125;; &#125;&#125; 初次进去提醒，授权 提醒效果如右上角所示 通过菜单和提醒，我们基本就可以完成一个简单的闹钟提醒，每隔30分钟提醒，码农扭扭脑袋，伸伸懒腰，小心肩周炎-_-! 【转载请注明：【chrome 插件二】弹出菜单和系统提醒学习 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>chrome-extension</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中型存储架构实践探索]]></title>
    <url>%2F2016%2F04%2F20%2F%E4%B8%AD%E5%9E%8B%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E5%AE%9E%E8%B7%B5%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[最近一直在做平台优化：对于中小型的站点，如何在资源有限的情况下，实现一个稳定，高效，靠谱的存储方案。下图是小拽个人在时间过程使用的一个存储架构。拿出来分享交流一下，也希望得到指点改进！ 先上图 首先说思想思想就一个：权衡资源和业务需求 简单解释一下：对于架构的理解，个人非常认同百度架构师tandai的一句话：架构设计本质上是折衷的艺术，如果你有足够量的高速存储和高性能的机器，那么完全可以用足量的cache，足量的离线计算存储，来提升时效性；同样，如果你的机器不足，资源不足，那么就可以通过可接受的时间消耗来节省存储空间。 架构基本组件： 至少两台机器。【保证物理容灾】 三个mysql实例。【一主两从，一主不解释；一从主要用于实时备份，暂叫容灾从；一从用于离线计算，cache更新，非时效性的数据抓取，暂叫api从；】 ameoba 负责负载均衡和读写分离【暂时用着还可以】。 redis 负责缓存，预取，存储cache。【可以换成其他】 一个抗高并发的中间件。【暂时只加了antispam组件，高并发并未处理，可能系统负载比较平均，qpd几千万 ，但是并未出现qps峰值】 that’s all，这些组件对于一个操作尚可的程序员来说，部署一整套肯定不会特别麻烦，相对于其他大型的架构来说，略显简单；但是，麻雀虽小，五脏俱全，下面从架构必备的几个角度分析一下。 安全性（Failover）任何一个架构首要考虑的是数据安全和容灾。小拽的架构中做了哪些 数据库全量备份这个就是一个简单脚本，对api从库在闲暇时间【晚上3-4点】进行全量导出备份，同时scp到另一台机器一份。（之所以对api库，是因为api库主要负责非失效性的查询和计算） 123456# crontab 每天3点进行数据库备份 (cuihuan)# 0 3 * * * sh /home/disk6/mysql/bin/backup.sh# 每天备份，保存最近30天的DATE=$(date +%Y%m%d)/home/xxx/bin/mysqldump -uroot -pxxx db &gt; /home/xxx/bak_sql/db_$DATE.sql;find /home/xxx/bak_sql/ -mtime +30 -name '*.sql' -exec rm -rf &#123;&#125; \; 数据库增量备份增量备份主要从两个角度 binlog中定期备份sql； 是采用主从库之后，从库会定时的备份主库信息，同时，对api库采用数据完全一致，对容灾库则设置只同步update 和insert；这样完备的保证了数据的安全。 可用性（Availabilty）数据的安全排第一，毋庸置疑；次之排平台的可用性，也毫无争议。可用性最简单的一个指标则为：不卡。 cachecache是提升查询时效性最有效的一个手段，小拽在框架中主要应用了两种cache，满足不同的业务需求。（所有关于cache的使用，一定要注意时效性和一致性，时效性和一致性，时效性和一致性） 普通的cache。即用户搜索或者查询之后的结果存在redis里面，下次查询使用。 预取的cache。即预测用户要查询的内容，放到cache里面。举几个栗子，用户首页内容一定要存cache里面；用户在看page1的时候，可以后台预测用户会看page2，提前取过来等等，这些策略和自己的实际业务紧密结合。 关于时效性和一致性再多说一句：一定要注意及时更新，例如用户写操作，点击操作，都需要在后台触发cache的主动更新，否则可能造成数据一致性错误。 分库分表中小型的架构中，存储的瓶颈往往在于读。 随着数据的增加，读库的成本越来越大，一个sql很可能会造成锁死整个库，一条sql 10+s也是常有的事情；因此，解决读库的瓶颈，可以大大提升系统的可用性；小拽的实践中主要应用了分库，分表。 分库之所以要分库，是因为二八原则的存在，80%的用户操作集中于20%的数据。 举个栗子：实践过程中小拽有个月库，只存本月的数据，基本上80%+的用户操作数据，都会命中这个库。 分库的原则有很多，例如时间原则，业务原则，数据逻辑原则等等；总之在您的框架中，当db扛不住的时候就分库，分层级。 分表分表的思想和分库类似，只是粒度更小，不在赘述。 扩展性（Scabability）小拽的架构中，扩展性主要从三个方面考虑 1：数据库的扩展性。如果资源允许N主N从都是可以的，基本上不会影响业务操作。 2：缓存的扩展。缓存基本上也是单独部署的，redis，memcache等均可以，变更成本不大。 3：高并发和负载均衡。这块属于大型网站需要考虑的，暂时只采用了ameaba进行负载均衡的扩展，高并发预留接口。 权衡（Balance）所有的架构和技术，最终都要落实到和业务需求权衡。 上面的架构最大的优势其实就是：简单，搭建起来非常容易，这就够了。 作为一名码农，只有在实践的过程中，不断发现系统的瓶颈，权衡现有资源和需求，解决和处理问题，才能成为一名靠谱的码农。 以上只是小拽在实践过程中的一点小小心的，欢迎大家到小站交流（http://cuihuan.net）。 【转载请注明：中型存储架构实践探索 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>redis</tag>
        <tag>读写分离</tag>
        <tag>主从备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据导库常用操作]]></title>
    <url>%2F2016%2F03%2F08%2Fmysql%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%BA%93%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[工作中经常遇到：一个数据库导入新的数据库实例中，或者一个数据库中的某些表导入新的数据库中，常用操作，总结一下。 部分数据表导入新库 单表导入新库的sql为 12# CREATE TABLE 新表 SELECT * FROM 旧表create table `dashboard`.`xx` (select * from dashboard_stb.xxx); 多表导入新库（将所有的stability_* 导入新库）多表的时候，只需选出需要的表即可。 1234567891011# 拼接处所有的导出sqlmysql&gt; select concat ('create table `dashboard`.',table_name,'(select * from `dashboard_stb`.',table_name,');') from information_schema.tables where table_name like "stability_%";+--------------------------------------------------------------------------------------------------------+| concat ('create table `dashboard`.',table_name,'(select * from `dashboard_stb`.',table_name,');') |+--------------------------------------------------------------------------------------------------------+| create table `dashboard`.stability_capacity(select * from `dashboard_stb`.stability_capacity); || create table `dashboard`.stability_dailymaxflow(select * from `dashboard_stb`.stability_dailymaxflow); || create table `dashboard`.stability_indextype(select * from `dashboard_stb`.stability_indextype); || create table `dashboard`.stability_ktraceagent(select * from `dashboard_stb`.stability_ktraceagent); # 此处省略N行+--------------------------------------------------------------------------------------------------------+ 粘贴进去直接运行即可123456789101112mysql&gt; create table `dashboard`.stability_maccpu(select * from `dashboard_stb`.stability_maccpu);Query OK, 138138 rows affected (2.16 sec)Records: 138138 Duplicates: 0 Warnings: 0mysql&gt; create table `dashboard`.stability_macmem(select * from `dashboard_stb`.stability_macmem);Query OK, 138137 rows affected (2.07 sec)Records: 138137 Duplicates: 0 Warnings: 0mysql&gt; create table `dashboard`.stability_macssd(select * from `dashboard_stb`.stability_macssd);Query OK, 138139 rows affected (2.17 sec)Records: 138139 Duplicates: 0 Warnings: 0# 此处省略N行 全库备份导入新库数据库全量导出为sql1mysqldump -uxxx -pxxx dashboard &gt; dashboard.sql 通过sql建立新库1234# 建新库mysql&gt; create databases dashboard_new# 导入数据./mysql -uxxx -p --default-character-set=utf8 dashboard_new &lt; dashboard.sql 【转载请注明：mysql 简单全量备份和快速恢复 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postMessage处理iframe 跨域问题]]></title>
    <url>%2F2016%2F02%2F29%2FpostMessage%E5%A4%84%E7%90%86iframe%20%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景：由于同源策略存在，javascript的跨域一直都是一个棘手的问题。父页面无法直接获取iframe内部的跨域资源；同时，iframe内部的跨域资源也无法将信息直接传递给父页面。 一：传统的解决方式。传统的iframe资源解决方式：主要通过通过中间页面代理，此处不再赘述，参考中间页获取跨域iframe 二：html5 postMessage的产生随着HTML5的发展，html5工作组提供了两个重要的接口：postMessage(send) 和 onmessage。这两个接口有点类似于websocket，可以实现两个跨域站点页面之间的数据传递。 postMessage API 下面是实践过程中两个小栗子：分别父页面传递信息给iframe，iframe传递信息给父页面。 三：iframe获取父页面信息话不多说，直接上码：参考demo：父页面传给子页面demo 父页面代码123456789101112131415161718192021222324&lt;html&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔涣 iframe postmessage 父页面&lt;/title&gt; &lt;script type="text/JavaScript"&gt; function sendIt() &#123; // 通过 postMessage 向子窗口发送数据 document.getElementById("otherPage").contentWindow .postMessage( document.getElementById("message").value, "http://cuihuan.net:8003" ); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- 通过 iframe 嵌入子页面 --&gt;&lt;iframe src="http://cuihuan.net:8003/test.html" id="otherPage"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;br/&gt;&lt;input type="text" id="message"/&gt;&lt;input type="button" value="Send to child.com" onclick="sendIt()"/&gt;&lt;/body&gt;&lt;/html&gt; 子页面代码123456789101112131415161718&lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔涣测试子页面信息&lt;/title&gt; &lt;script type="text/JavaScript"&gt; //event 参数中有 data 属性，就是父窗口发送过来的数据 window.addEventListener("message", function( event ) &#123; // 把父窗口发送过来的数据显示在子窗口中 document.getElementById("content").innerHTML+=event.data+"&lt;br/&gt;"; &#125;, false ); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; this is the 8003 port for cuixiaozhuai &lt;div id="content"&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; demo 效果如下图：两个跨域页面之间，父页面给子页面传递数据。 四：iframe传递信息给父页面参考demo：跨域子页面传给父页面demo 父页面代码1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔涣测试父页面&lt;/title&gt; &lt;script type="text/JavaScript"&gt; //event 参数中有 data 属性，就是父窗口发送过来的数据 window.addEventListener("message", function( event ) &#123; // 把父窗口发送过来的数据显示在子窗口中 document.getElementById("content").innerHTML+=event.data+"&lt;br/&gt;"; &#125;, false ); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;iframe src="http://cuihuan.net:8003/iframeSon.html" id="otherPage"&gt;&lt;/iframe&gt; &lt;br/&gt; this is the 1015 port for cuixiaozhuai。 &lt;div id="content"&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 子页面代码123456789101112131415161718192021&lt;html&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;崔小涣iframe postmessage 测试页面&lt;/title&gt; &lt;script type="text/JavaScript"&gt; function sendIt() &#123; // 子页面给父页面传输信息 parent.postMessage( document.getElementById("message").value, "http://cuihuan.net:1015" ); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;br/&gt;this is the port for cuixiaozhuai&lt;input type="text" id="message"/&gt;&lt;input type="button" value="Send to child.com" onclick="sendIt()"/&gt;&lt;/body&gt;&lt;/html&gt; demo 效果如下图：两个跨域页面之间，子页面传递数据给父页面传递数据。 五：postmessage简单分析和安全问题postmessage 传送过来的信息如下图， 几乎包含了所有应该有的信息。甚至data中可以包含object，出于安全考虑可以域的校验，数据规则的校验安全校验，如下代码1234567891011121314151617181920212223242526window.addEventListener('message', function (event) &#123; //校验函数是否合法 var checkMessage = function () &#123; // 只获取需要的域，并非所有都可以跨域 if (event.origin != "need domain") &#123; return false; &#125; var message = event.data; // 传输数据类型校验 if (typeof(message) !== 'object') &#123; return false; &#125; // message 的rule中包含xxx则为xxx需要字段。 return message.rule === "xxx"; &#125;; if (checkMessage()) &#123; // 通过校验进行相关操作 addDetailFunc(event); &#125; &#125;); 【转载请注明：postMessage处理iframe 跨域问题 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>iframe跨域</tag>
        <tag>iframe自适应高度</tag>
        <tag>iframe</tag>
        <tag>html5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YII2数据库查询实践]]></title>
    <url>%2F2016%2F01%2F10%2FYII2%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[初探yii2框架，对增删改查，关联查询等数据库基本操作的简单实践。 数据库配置。/config/db.php 进行数据库配置配置可以参考 yii文档 实践过程中有个test库-》test表-》两条记录如下12345678mysql&gt; select * from test;+----+--------+| id | name |+----+--------+| 1 | zhuai || 2 | heng | +----+--------+18 rows in set (0.00 sec) sql 查询方式yii2 提供了原始的数据库查询方式findBySql；同时，通过占位符的方式，自动进行了基本的sql注入防御。上码123456789101112131415// 最基本的查询方式$sql = "select * from test where 1";$res = Test::findBySql($sql)-&gt;all();var_dump(count($res)); // res-&gt;2 // findbysql 防止sql注入方式$id = '1 or 1=1';$sql = "select * from test where id = " . $id;$res = Test::findBySql($sql)-&gt;all();var_dump(count($res)); // res-&gt; 2$sql = "select * from test where id = :id";// 定位符会自动防止sql 注入$res = Test::findBySql($sql,array(":id"=&gt;$id))-&gt;all();var_dump(count($res)); // res-&gt;1 activeRecord查询方式每个框架除了原有的sql方式，都会提供相应的封装的查询方式，yii2亦然。 创建modelyii的model基本方式如下，代码如下不赘述。123456789101112131415161718192021222324&lt;?phpnamespace app\models;use Yii;use yii\db\ActiveRecord;class Test extends ActiveRecord&#123; // 可无，对应表：默认类名和表名匹配，则无需此函数 public static function tableName() &#123; return 'test'; &#125; // 可无，验证器：主要用于校验各个字段 public function rules()&#123; return [ ['id', 'integer'], ['name', 'string', 'length' =&gt; [0, 100]], ]; &#125;&#125; 使用的时候需要引入model1use app\models\Test; 增加操作1234567891011// add 操作$test = new Test();$test-&gt;name = 'test';// 合法性校验$test-&gt;validate();if($test-&gt;hasErrors())&#123; echo "数据不合法"; die;&#125;$test-&gt;save(); 查询操作查询操作先上官方文档 activeRecord doc where doc需要强调的是：yii查询提供了特别多丰富的库，例如代码中的批量查询处理等等，细节可以看文档。 1234567891011121314151617181920212223242526// select// id = 1$res = Test::find()-&gt;where(['id' =&gt; 1])-&gt;all();var_dump(count($res)); //1// id &gt; 0$res = Test::find()-&gt;where(['&gt;','id',0])-&gt;all();var_dump(count($res)); //2// id &gt; =1 id &lt;=2$res = Test::find()-&gt;where(['between','id',1,2])-&gt;all();var_dump(count($res)); //2// name字段like$res = Test::find()-&gt;where(['like', 'name', 'cuihuan'])-&gt;all();var_dump(count($res)); //2// 查询的使用 obj-&gt;array$res = Test::find()-&gt;where(['between','id',1,2])-&gt;asArray()-&gt;all();var_dump($res[0]['id']); //2// 批量查询,对于大内存操作的批量查询foreach (Test::find()-&gt;batch(1) as $test) &#123; var_dump(count($test));&#125; 删除操作1234567// delete // 选出来删除$res = Test::find()-&gt;where(['id'=&gt;1])-&gt;all();$res[0]-&gt;delete();// 直接删除var_dump(Test::deleteAll('id&gt;:id', array(':id' =&gt; 2))); 修改操作除了代码中方式，yii2直接提供update操作。1234// 活动记录修改$res = Test::find()-&gt;where(['id'=&gt;4])-&gt;one();$res-&gt;name = "update";$res-&gt;save(); 关联查询操作关联查询示例中两个表:一个学生表(student):id ，name;一个分数表(score)：id,stu_id,score123456789// 相应学生的所有score$stu = Student::find()-&gt;where(['name'=&gt;'xiaozhuai'])-&gt;one();var_dump($stu-&gt;id);// 基本获取$scores_1 = $stu-&gt;hasMany('app\model\Score',['stu_id'=&gt;$stu-&gt;id])-&gt;asArray()-&gt;all();$scores_2 = $stu-&gt;hasMany(Score::className(),['stu_id'=&gt;'id'])-&gt;asArray()-&gt;all();var_dump($scores_1);var_dump($scores_2); 两种关联查询方式；但是，在controller进行相关操作，代码显的过于混乱，在model中封装调用 首先在student model中封装相关关联调用函数123456789101112131415161718192021222324&lt;?phpnamespace app\models;use Yii;use yii\db\ActiveRecord;class Student extends ActiveRecord&#123; public static function tableName() &#123; return 'student'; &#125; // 获取分数信息 public function getScores() &#123; $scores = $this-&gt;hasMany(Score::className(), ['stu_id' =&gt; 'id'])-&gt;asArray()-&gt;all(); return $scores; &#125;&#125; 之后直接调用，两种调用方式1234567// 函数封装之后调用$scores = $stu-&gt;getScores();var_dump($scores);// 利用__get 的自动调用的方式$scores = $stu-&gt;scores;var_dump($scores); 最后上面在yii2的部署和使用过程中的一些基本的增删改查，关联查询等操作。但是如果想要将yii2的db操作使用好，还要看文档大法： activeRecord doc 【转载请注明：YII2数据库查询实践 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>db</tag>
        <tag>active record</tag>
        <tag>yii2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器多次恶意提交攻击简单防范]]></title>
    <url>%2F2016%2F01%2F07%2F%E6%9C%BA%E5%99%A8%E5%A4%9A%E6%AC%A1%E6%81%B6%E6%84%8F%E6%8F%90%E4%BA%A4%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[先说背景：机器不断的发送请求或者恶意提交，会给服务器造成很大压力；针对这种攻击最优的策略是判断提交次数，产生动态验证码，即判断ip规定时间内重复发送达到N次弹出验证码。下面是小拽在实践过程中一个简单的识别ip，利用session记录和防御的过程。 识别和校验ip过程如下； 识别ip ip属于白名单直接通过[白名单策略：内网ip+指定ip表] 利用session存储ip的请求时间戳 校验规定时间内ip的请求次数 采取相应的措施 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 获取和校验ip；同时防止短时间内多次提交 * * @notice ：弹出验证码，需要替换掉echo $echo_str 即可。 * @return string ：返回校验成功的ip */protected function getAndCheckIP()&#123; // 获取环境ip if (getenv("HTTP_CLIENT_IP") &amp;&amp; strcasecmp(getenv("HTTP_CLIENT_IP"), "unknown")) $ip = getenv("HTTP_CLIENT_IP"); else if (getenv("HTTP_X_FORWARDED_FOR") &amp;&amp; strcasecmp(getenv("HTTP_X_FORWARDED_FOR"), "unknown")) $ip = getenv("HTTP_X_FORWARDED_FOR"); else if (getenv("REMOTE_ADDR") &amp;&amp; strcasecmp(getenv("REMOTE_ADDR"), "unknown")) $ip = getenv("REMOTE_ADDR"); else if (isset($_SERVER['REMOTE_ADDR']) &amp;&amp; $_SERVER['REMOTE_ADDR'] &amp;&amp; strcasecmp($_SERVER['REMOTE_ADDR'], "unknown")) $ip = $_SERVER['REMOTE_ADDR']; else $ip = "unknown"; // check 环境ip if (!$this-&gt;isWhiteList($ip)) &#123; $echo_str = "提交过于频繁,请稍后再试！"; // 构建ip的时间栈数据 if (!is_array($_SESSION[$ip])) &#123; $_SESSION[$ip] = array(); &#125; if (isset($_SESSION[$ip][0])) &#123; $_SESSION[$ip][] = time(); // session 保存时间为6小时。清理session $post_interval_first = time() - $_SESSION[$ip][0]; if ($post_interval_first &gt; 21600) &#123; $_SESSION[$ip] = array(); &#125; // 两次提交小于1s，禁止提交 $post_interval_pre = time() - $_SESSION[$ip][count($_SESSION[$ip]) - 3]; if ($post_interval_pre &lt; 1) &#123; echo $echo_str; exit; &#125;; // 您在10s内已经提交了3请求，禁止提交 $post_interval_third = time() - $_SESSION[$ip][count($_SESSION[$ip]) - 3]; if (isset($_SESSION[$ip][3]) &amp;&amp; ($post_interval_third &lt; 10)) &#123; echo $echo_str; exit; &#125; // 您在1分钟期间已经提交了5请求，禁止提交 $post_interval_fifth = time() - $_SESSION[$ip][count($_SESSION[$ip]) - 3]; if (isset($_SESSION[$ip][5]) &amp;&amp; ($post_interval_fifth &lt; 60)) &#123; echo $echo_str; exit; &#125; // 6小时内提交10次，禁止提交 if (isset($_SESSION[$ip][10])) &#123; echo $echo_str; exit; &#125; &#125; else &#123; $_SESSION[$ip][] = time(); &#125; &#125; return ($ip);&#125; 白名单策略白名单策略采用：内网ip放行和特定ip放行1234567891011121314151617/** * 检验是否存在于白名单中 * * @param $ip ：校验的ip * @return bool ：校验结果 */function isWhiteList($ip)&#123; /** * 内网ip默认全部存在于白名单中 */ if(!filter_var($ip, FILTER_VALIDATE_IP, FILTER_FLAG_NO_PRIV_RANGE | FILTER_FLAG_NO_RES_RANGE))&#123; return true; &#125; // 是否在写死的whitelist 里面 return in_array($ip,$this-&gt;_WHTTE_LIST);&#125; 防攻击策略小拽采用的比较简单的策略，如上面代码，实际过程中可以结合业务需求。 1s内禁止重复提交 5s内提交上限3次 60s内提交上限5次 6小时内提交上限10次 【转载请注明：机器多次恶意提交攻击简单防范 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>ip</tag>
        <tag>恶意攻击</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[检验mysql主从备份，读写分离]]></title>
    <url>%2F2016%2F01%2F03%2F%E6%A3%80%E9%AA%8Cmysql%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD%EF%BC%8C%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[先说背景：mysql的主从部署，读写分离，负载均衡之后；需要简单测试和校验一下，在实践中写了个简单的php脚本和校验过程，mark一下，方便再次部署校验。 数据库部署和实践数据库在实践中，往往需要进行多机主从备份保证安全，这个毋庸置疑；进行读写分离和负载均衡可以极大的提升mysql的读写性能。作者在实践中采用阿里的ameoba进行了读写分离和负载均衡操作。细节步骤参考小拽文章: mysql主从备份，读写分离和负载均衡实践 那么问题来了，部署完了，校验也需慎重，下面是简单的校验过程。 php简单读写库脚本上码：能用代码说的，最好不用文字说话！1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?php/** * 进行读写分离的校验 * @notice ：需要关闭主从备份的情况下进行 * 原理：打开主从，写主库，从库获取数据，校验主从备份；关闭主从写ameoba,校验读写分离和负载 * * @author: cuixiaohuan * Date: 15/12/29 * Time: 下午9:10 */class ReadAndWriteTest &#123; // ameoba 设定端口,校验读写时，放主库配置 const IP ="ip:port"; const PWD ="pwd"; const USER ="user"; const DB ="db"; public function __construct()&#123; error_reporting(E_ALL ^ E_DEPRECATED); $this-&gt;initDb(); $this-&gt;_writeTest(); $this-&gt;_selectTest(); &#125; /** * 进行10次读操作 */ public function _selectTest()&#123; for ($i = 0; $i &lt; 10; $i++) &#123; $read_sql = 'select * from test limit 10'; $g_result = mysql_query($read_sql); var_dump($g_result); mysql_free_result($g_result); &#125; &#125; /** * 进行10次写操作 */ public function _writeTest()&#123; for ($i = 0; $i &lt; 10; $i++) &#123; $id = uniqid(); $content = "pingce" . uniqid(); $write_sql = 'INSERT INTO `test`(`test`, `test1`) VALUES ("' . $id . '","' . $content . '")'; $g_result = mysql_query($write_sql); var_dump($g_result); &#125; &#125; /** * 初始化数据库连接信息 info */ private function initDb() &#123; $crowd_conn = mysql_pconnect(self::IP, self::USER, self::PWD); if (!$crowd_conn) &#123; die("Could not connect:" . mysql_error()); &#125; $crowd_db = mysql_select_db(self::DB, $crowd_conn); &#125;&#125;$rw = new ReadAndWriteTest(); 主从备份校验 开启slave 调整数据库信息为mysql，主库信息，运行脚本。 查看从库的log，有如下写入操作，说明实时主从备份成功。1234567891011121314151617181920212223242526272829303132151231 15:36:21 4 Query start slave14 Connect Out pingce@10.95.112.120:366615 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e5c85","pingce5684d957e5cf2")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e7937","pingce5684d957e7982")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e8e96","pingce5684d957e8ee4")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ea2c2","pingce5684d957ea2eb")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eb565","pingce5684d957eb5b3")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ec7ee","pingce5684d957ec83e")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eda2f","pingce5684d957eda78")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eeca4","pingce5684d957eecf0")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eff16","pingce5684d957eff61")15 Query COMMIT /* implicit, from Xid_log_event */15 Query BEGIN15 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957f121e","pingce5684d957f126d")15 Query COMMIT /* implicit, from Xid_log_event */ 检验读写分离 读写分离，首先需要关闭从机器上的slave。原因：存在主从的话，无法通过log查看出读写分离操作。 12mysql&gt; stop slave;Query OK, 0 rows affected (0.08 sec) 运行脚本：如下信息标示，运行成功。 123456789101112131415161718192021[cuixiaohuan TestScript]$ /home/work/lamp/php5/bin/php ReadAndWriteTest.phpINSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e5c85","pingce5684d957e5cf2")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e7937","pingce5684d957e7982")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e8e96","pingce5684d957e8ee4")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ea2c2","pingce5684d957ea2eb")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eb565","pingce5684d957eb5b3")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ec7ee","pingce5684d957ec83e")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eda2f","pingce5684d957eda78")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eeca4","pingce5684d957eecf0")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eff16","pingce5684d957eff61")bool(true)INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957f121e","pingce5684d957f126d")bool(true)resource(5) of type (mysql result)resource(6) of type (mysql result)resource(7) of type (mysql result)resource(8) of type (mysql result)resource(9) of type (mysql result)resource(10) of type (mysql result)resource(11) of type (mysql result)resource(12) of type (mysql result)resource(13) of type (mysql result)resource(14) of type (mysql result) 查询读写库的log 解释：之所以主库放一个读写库，是因为有些要求超高一致性的数据，备份可能会有延迟；所以，主库承担读写操作，和高负载。 1234567891011121314151617#读写机器log： 进行了10次写和 四次读151231 15:29:27 19 Query set names gbk^@19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e5c85","pingce5684d957e5cf2")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e7937","pingce5684d957e7982")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957e8e96","pingce5684d957e8ee4")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ea2c2","pingce5684d957ea2eb")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eb565","pingce5684d957eb5b3")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957ec7ee","pingce5684d957ec83e")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eda2f","pingce5684d957eda78")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eeca4","pingce5684d957eecf0")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957eff16","pingce5684d957eff61")19 Query INSERT INTO `test`(`test`, `test1`) VALUES ("5684d957f121e","pingce5684d957f126d")19 Query select * from test limit 10151231 15:29:28 19 Query select * from test limit 1019 Query select * from test limit 1019 Query select * from test limit 1019 Query select * from test limit 10 查看读库的log 123456789# 只进行了读操作，校正了数据库的读写分离操作。151231 15:29:20 4 Query stop slave151231 15:29:27 3 Query set names gbk^@3 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 103 Query select * from test limit 10 最后一句话：打开slave，校验主从备份；关闭slave，校验读写分离。 【转载请注明： 检验mysql主从备份，读写分离 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>读写分离</tag>
        <tag>主从备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php反射调用private方法实践]]></title>
    <url>%2F2015%2F12%2F20%2Fphp%E5%8F%8D%E5%B0%84%E8%B0%83%E7%94%A8private%E6%96%B9%E6%B3%95%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[问题背景：单测中有个普遍性的问题，被侧类中的private方法无法直接调用。小拽在处理过程中通过反射改变方法权限，进行单测，分享一下，直接上代码。 简单被测试类生成一个简单的被测试类，只有个private方法。 1234567891011121314151617181920212223242526&lt;?php/** * 崔小涣单测的基本模板。 * * @author cuihuan * @date 2015/11/12 22:15:31 * @version $Revision:1.0$ **/class MyClass &#123; /** * 私有方法 * * @param $params * @return bool */ private function privateFunc($params)&#123; if(!isset($params))&#123; return false; &#125; echo "test success"; return $params; &#125;&#125; 单测代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?php/*************************************************************************** * * $Id: MyClassTest T,v 1.0 PsCaseTest cuihuan Exp$ * **************************************************************************//** * 崔小涣单测的基本模板。 * * @author cuihuan * @date 2015/11/12 22:09:31 * @version $Revision:1.0$ **/require_once ('./MyClass.php');class MyClassTest extends PHPUnit_Framework_TestCase &#123; const CLASS_NAME = 'MyClass'; const FAIL = 'fail'; protected $objMyClass; /** * @brief setup: Sets up the fixture, for example, opens a network connection. * * 可以看做phpunit的构造函数 */ public function setup() &#123; date_default_timezone_set('PRC'); $this-&gt;objMyClass = new MyClass(); &#125; /** * 利用反射，对类中的private 和 protect 方法进行单元测试 * * @param $strMethodName string ：反射函数名 * @return ReflectionMethod obj ：回调对象 */ protected static function getPrivateMethod($strMethodName) &#123; $objReflectClass = new ReflectionClass(self::CLASS_NAME); $method = $objReflectClass-&gt;getMethod($strMethodName); $method-&gt;setAccessible(true); return $method; &#125; /** * @brief :测试private函数的调用 */ public function testPrivateFunc() &#123; $testCase = 'just a test string'; // 反射该类 $testFunc = self::getPrivateMethod('privateFunc'); $res = $testFunc-&gt;invokeArgs($this-&gt;objMyClass, array($testCase)); $this-&gt;assertEquals($testCase, $res); $this-&gt;expectOutputRegex('/success/i'); // 捕获没有参数异常测试 try &#123; $testFunc-&gt;invokeArgs($this-&gt;transfer2Pscase, array()); &#125; catch (Exception $expected) &#123; $this-&gt;assertNotNull($expected); return true; &#125; $this-&gt;fail(self::FAIL); &#125; &#125; ##运行结果1234567cuihuan:test cuixiaohuan$ phpunit MyClassTest.php PHPUnit 4.8.6 by Sebastian Bergmann and contributors.Time: 103 ms, Memory: 11.75MbOK (1 test, 3 assertions) 关键代码分析封装了一个，被测类方法的反射调用；同时，返回方法之前处理方法的接入权限为true，便可以访问private的函数方法。123456789101112/** * 利用反射，对类中的private 和 protect 方法进行单元测试 * * @param $strMethodName string ：反射函数名 * @return ReflectionMethod obj ：回调对象 */protected static function getPrivateMethod($strMethodName) &#123; $objReflectClass = new ReflectionClass(self::CLASS_NAME); $method = $objReflectClass-&gt;getMethod($strMethodName); $method-&gt;setAccessible(true); return $method;&#125; 【转载请注明：phpunit单测中调用private方法处理 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>单元测试</tag>
        <tag>phpunit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 简单全量备份和快速恢复]]></title>
    <url>%2F2015%2F12%2F11%2Fmysql%20%E7%AE%80%E5%8D%95%E5%85%A8%E9%87%8F%E5%A4%87%E4%BB%BD%E5%92%8C%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[一个简单的mysql全量备份脚本，备份最近15天的数据。 备份1234#每天备份mysql数据库(保存最近15天的数据脚本)DATE=$(date +%Y%m%d)/home/cuixiaohuan/lamp/mysql5/bin/mysqldump -uuser -ppassword need_db &gt; /home/cuixiaohuan/bak_sql/mysql_dbxx_$DATE.sql;find /home/cuixiaohuan/bak_sql/ -mtime +15 -name '*.sql' -exec rm -rf &#123;&#125; \; 恢复mysql 数据导入12drop databases need_db;create databases need_db; 导入数据：必须设定编码进行恢复1./mysql -uroot -p --default-character-set=utf8 need_db &lt; xx.sql 【转载请注明：mysql 简单全量备份和快速恢复 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>备份</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 查找清理大文件]]></title>
    <url>%2F2015%2F12%2F08%2Flinux%20%E6%9F%A5%E6%89%BE%E6%B8%85%E7%90%86%E5%A4%A7%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[linux 经常硬盘空间不足，往往是由于一些大文件造成；之前寻找大文件总是很头疼，速度特别慢。经学弟介绍使用：du -sh * |grep G 查找和清理速度不错，分享一下清理过程。 查看系统存储状态1234[cuihuan:~ cuixiaohuan]$ df -hFilesystem Size Used Avail Use% Mounted on/dev/sda2 8.2G 6.7G 1.6G 82% //dev/sda3 1.4T 1.3T 50G 97% /home 1.5T的硬盘占用了97%，确实不够用了，必须着手清理一下 查找大文件主要使用查找命令：du -sh * |grep G从根文件开始查找1234567[cuihuan:~]$ du -sh * | grep G。。。73G mongodb103G mxm2.1G online613G thirdparty [binggo!!!]。。。 bingo 613g，看来这个主要矛盾了，进一步分析该文件 1234567891011121314151617181920[cuihuan:~ mysql5]$ du -sh *116M bin904K include13M lib17M libexec458G log [-__]8.0K my.cnf76M mysql-test13M share2.9M sql-bench4.0K test4.0K tmp101G var [-_-][cuihuan:~ mysql5]$ cd log[cuihuan:~ log]$ ls -lhtotal 458G-rw-rw---- 1 work work 870K Dec 2 17:42 mysql.err-rw-rw---- 1 work work 3.9K Mar 24 2015 mysql.err-old-rw-rw---- 1 work work 446G Dec 3 15:19 mysql.log 【-__】-rw-rw---- 1 work work 11G Dec 3 15:10 slow.log 经过分析看到mysql.log的日志占了446G,着手清理下。【mysql log 好的保存方式是：天级导出，清理n天之前的log，此处不再赘述】 清理之后效果清理 mysql.log 和var 之后清理了大约500g的空间1234[cuihuan:~ var]$ df -h Filesystem Size Used Avail Use% Mounted on/dev/sda2 8.2G 6.7G 1.6G 82% //dev/sda3 1.4T 757G 584G 57% /home 【转载请注明：linux 查找清理大文件 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[echarts动态获取数据实例]]></title>
    <url>%2F2015%2F12%2F06%2Fecharts%E5%8A%A8%E6%80%81%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[echarts动态获取数据库的实时数据的简单实例。实例演示： 跳转demo 引入echarts 文件。引入echarts的文件方式有多种，比较推荐模块化的引入方式。小拽的简单demo是直接引入文件，提供一个下载地址 ： 点击下载 html 部分代码一块div 用于echart的展现。1&lt;div id="echart_show" style="height:500px"&gt;这里是一个布局展现&lt;/div&gt; js 部分代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167$(document).ready(function () &#123; // 绘制反馈量图形 var init_echarts = function () &#123; var refreshChart = function (show_data) &#123; my_demo_chart = echarts.init(document.getElementById('echart_show')); my_demo_chart.showLoading(&#123; text: '加载中...', effect: 'whirling' &#125;); var echarts_all_option = &#123; title: &#123; text: '动态数据', subtext: '纯属虚构' &#125;, tooltip: &#123; trigger: 'axis' &#125;, legend: &#123; data: ['最新成交价', '预购队列'] &#125;, toolbox: &#123; show: true, feature: &#123; mark: &#123;show: true&#125;, dataView: &#123;show: true, readOnly: false&#125;, magicType: &#123;show: true, type: ['line', 'bar']&#125;, restore: &#123;show: true&#125;, saveAsImage: &#123;show: true&#125; &#125; &#125;, dataZoom: &#123; show: false, start: 0, end: 100 &#125;, xAxis: [ &#123; type: 'category', boundaryGap: true, data: (function () &#123; var now = new Date(); var res = []; var len = 10; while (len--) &#123; res.unshift(now.toLocaleTimeString().replace(/^\D*/, '')); now = new Date(now - 2000); &#125; return res; &#125;)() &#125;, &#123; type: 'category', boundaryGap: true, data: (function () &#123; var res = []; var len = 10; while (len--) &#123; res.push(len + 1); &#125; return res; &#125;)() &#125; ], yAxis: [ &#123; type: 'value', scale: true, name: '价格', boundaryGap: [0.2, 0.2] &#125;, &#123; type: 'value', scale: true, name: '预购量', boundaryGap: [0.2, 0.2] &#125; ], series: [ &#123; name: '预购队列', type: 'bar', xAxisIndex: 1, yAxisIndex: 1, // 获取到数据库的数据 data: show_data[0] &#125;, &#123; name: '最新成交价', type: 'line', // 实时获取的数据 data:show_data[1] &#125; ] &#125;; my_demo_chart.hideLoading(); my_demo_chart.setOption(echarts_all_option); &#125;; // 获取原始数据 $.ajax(&#123; url: "http://cuihuan.net:1015/demo_file/echarts_realtime_demo/get_data.php", data: &#123;type: "2"&#125;, success: function (data) &#123; // 根据数据库取到结果拼接现在结果 refreshChart(eval(data)); &#125; &#125;); &#125;; // 开启实时获取数据更新 $("#getData").on("click",function() &#123; var timeTicket; var lastData = 11; var axisData; clearInterval(timeTicket); timeTicket = setInterval(function () &#123; // 获取实时更新数据 $.ajax(&#123; url: "http://cuihuan.net:1015/demo_file/echarts_realtime_demo/get_data.php", data: &#123;type: "new"&#125;, success: function (data) &#123; // 根据条件转换成相应的api 转化为echart 需要的数据 // todo 更新数据采用随机更新的方式 lastData += Math.random() * ((Math.round(Math.random() * 10) % 2) == 0 ? 1 : -1); lastData = lastData.toFixed(1) - 0; axisData = (new Date()).toLocaleTimeString().replace(/^\D*/, ''); // 动态数据接口 addData my_demo_chart.addData([ [ 0, // 系列索引 Math.round(Math.random() * 1000), // 新增数据 true, // 新增数据是否从队列头部插入 false // 是否增加队列长度，false则自定删除原有数据，队头插入删队尾，队尾插入删队头 ], [ 1, // 系列索引 lastData, // 新增数据 false, // 新增数据是否从队列头部插入 false, // 是否增加队列长度，false则自定删除原有数据，队头插入删队尾，队尾插入删队头 axisData // 坐标轴标签 ] ]); &#125; &#125;); &#125;, 2100); // 关闭更新操作 $("#stopData").on("click", function () &#123; clearInterval(timeTicket); &#125;); &#125;); // 默认加载 var default_load = (function () &#123; init_echarts(); &#125;)();&#125;); php 部分代码123456789101112131415161718192021222324252627282930313233343536/** * 连接数据库获取数据 * * User: cuixiaohuan * Date: 15/12/4 * Time: 下午6:47 */// 获取请求的类型$type = $_GET['type'];// 连接服务器$link = mysql_connect('ip:port', 'user', 'password');if (!$link) &#123; die("Could not connect:" . mysql_error());&#125;// 获取test库数据$crowd_db = mysql_select_db('test', $link);$day_time = date("Y-m-d");// 根据传输过来的数据获取数据$static_sql = "select v from test where id = " . $type . " limit 10";// 获取数据之后返回$res = mysql_query($static_sql, $link_2004);if ($res) &#123; // 将结果进行入库操作 $row = mysql_fetch_row($res); if($row[0])&#123; echo $row[0]; &#125; mysql_free_result($res);&#125; 简单说明小拽的demo中，根据echarts的api，绘制出了原有的图形展示；之后，对js设置了个定时任务，实时的去获取数据库中可能新入库的数据，接口通过php简单调用数据库实现。 小拽个人小站]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>前端</tag>
        <tag>动态获取数据</tag>
        <tag>pho</tag>
        <tag>echarts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【wordpress优化】压缩和使用静态缓存]]></title>
    <url>%2F2015%2F12%2F06%2F%E3%80%90wordpress%E4%BC%98%E5%8C%96%E3%80%91%E5%8E%8B%E7%BC%A9%E5%92%8C%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[先说背景：wordpress个人网站，整体性能挺不错；但是，由于采用php动态获取数据，构成页面的方式，势必会影响页面加载速度。对于一些最常用的页面[例如首页]等等，完全可以采用生成伪静态页面缓存的方式加载。 针对现有的缓存方式调研了一下：本文使用wp super cache进行了优化，提升加载速度200%以上。 无图无真想，先看效果针对相同页面在chrome下做了个加载时间，大小的对比，如下图 优化前数据：23ms感知页面；3.62s加载完成；页面大小：419k；请求个数：25个； 优化后数据：106ms感知页面；1.81s加载完成；页面大小13.9k；请求个数24个； 效果不错，后文做个详细分析。 了解 wp super cache wp super cache 是wordpress的一种缓存优化插件，本质是利用缓存机制提升页面加载速度。实现原理: php最终在前端展现时需要转换为html，然后获取响应的数据；wp super cache 则提前将php文件转换为的html伪静态文件进行存储，一旦发生请求，直接返回生成的页面；减少了数据库取数据，转换等过程，来增加加载速度。优 点: 增加了加载速度。缺 点: 增加了存储成本，而且要不断的更新，如果用户量大，个人感觉存储和离线成本增加会挺多。 安装 wp super cache官网下载地址： http://z9.io/wp-super-cache/ 【无法翻墙可参考小拽博文： 不翻墙，下载wordpress官方主题和插件小技巧 】 注意：安装wp super cache 需要设定固定连接 如下图推荐采用【自定义结果】：http://cuihuan.net/article/%postname%.html原因在于其他包含字母或者日期不太容易表意，也不利于阅读和seo等等。 如果最初采用的是http://xxx/?p=xxx的方式，需要对服务器进行相关设置，否则会一直出现404。解决和设置办法，在另一篇文章中，此处不赘述（[wp super cache 安装和问题解决](http://cuihuan.net/article/wp%20super%20cache%20%E5%AE%89%E8%A3%85%E5%92%8C%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3.html)）。 安装成功后，后台设置中会出现wp super cache 配置 wp super cache安装成功后的简单个人推荐设置。 通用-》启用cache：开启高级-》启用缓存：开启高级-》模式选择：推荐mode_rewrite 这个需要apache或者nginx进行相关设置，这个速度最快；如果不想设置，可以选择php缓存模式。高级-》压缩页面：必选。高级-》页面更新清除，评论更新清楚：推荐。作用是更新文章，评论之后触发缓存更新。高级-》移动支持：推荐。其他一些设置根据个人需求增加。 配置，更新之后，进入网站cache目录下会出现缓存的html文件和gzip的压缩文件（前提是设置了giz压缩）。 123456[root@cuixiaohuan cuihuan.net]# pwdxxx/wp-content/cache/supercache/cuihuan.net[root@cuixiaohuan cuihuan.net]# ls -lhtotal 52K-rw-r--r-- 1 apache apache 40K Dec 5 11:33 index.html-rw-r--r-- 1 apache apache 9.5K Dec 5 11:33 index.html.gz 效果分析优化前数据：23ms感知页面；3.62s加载完成；页面大小：419k；请求个数：25个；优化后数据：106ms感知页面；1.81s加载完成；页面大小13.9k；请求个数24个； 感知页面变慢：原因在于，原始php页面相对较小，传输也相对较快，传输基本框架之后，才进行页面dom绘制，js渲染，数据获取和再次渲染，所以感知时间原始的快。但是对于750ms以下的对于用户几乎都是无感知。 加载完成变快：最主要达到的效果，节省最多的时间在于数据库获取数据的时间。 页面大小变小：这块小的有点出乎意外，小是应该的，但是小这么多就有点🐂了；之后分析了下页面，可能和文章异步获取，存储的html只获取了部分页面的文章，同时，对jquery等等组件肯定是利用缓存，不计入数据大小了。 请求数目变化不大。 整体效果：加载快了，页面小了。 【转载请注明：【wordpress优化】压缩和使用静态缓存 | 靠谱崔小拽 】]]></content>
      <tags>
        <tag>php</tag>
        <tag>缓存</tag>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab 误删除恢复]]></title>
    <url>%2F2015%2F12%2F03%2Fcrontab%20%E8%AF%AF%E5%88%A0%E9%99%A4%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[操作过程中：crontab被全部干掉了，利用log恢复过程记录。 事故原因分析：回忆自己操作过程中，未进行crontab的清空，网上查了下原因，并且复现了下。可能原因如下： 如果在SSH远程终端中敲下“crontab”命令之后，远程连接被一些原因（比如 糟糕的网络，程序异常）意外终止了，那么Crontab计划任务就会被操作系统所清空。听起来很不可思议，但是经过在虚拟机上的多次测试，它确确实实的发生了。测试方式为 用SecureCRT开一个SSH窗口，然后敲下命令“crontab”，接着在“任务管理器”中直接杀掉SecureCRT进程，再通过另外一个SSH窗口执行“crontab -l”，就会发现，所有的计划任务都不存在了。在今天事故发生的时间点上，就有人在服务器上遇到了这样的情况。 恢复操作 获取完整日志和cmd日志。从日志中恢复出一份最近几天的完整crontab 运行日志和cmd日志，并存储，用于之后完善和核准例行时间。 12cat /var/log/cron | grep -i "`which cron`" &gt; ./all_tempcat ./all_temp | grep -v "&lt;command&gt;” &gt; ./cmd_temp 获取所有crontab指令。从日志中恢复一份去重的crontab log。【相当于所有的crontab命令】 1awk -F'(' '/crond/&#123;a[$3]=$0&#125;END&#123;for(i in a)print a[i]&#125;' /var/log/cron* &gt;crontab.txt 手工恢复：从crontab.txt 中找出每一条指令，然后在cmd_temp 中匹配运行次数，重新编辑crontab 添加 反思工作防止类似事件再次发生，写个简单shell脚本，每天对crontab进行备份，备份最近15天的数据。过期清楚123456#!/bin/bash# 每天对crontab 进行备份 ，同时删除最近15天的数据DATE=$(date +%Y%m%d)crontab -l &gt; /home/work/bak/crontab_$DATE.bakfind /home/work/bak/ -mtime +15 -name '*.bak' -exec rm -rf &#123;&#125; \; 本人小站原文链接]]></content>
      <tags>
        <tag>crontab</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jsonp + php 跨域实例]]></title>
    <url>%2F2015%2F12%2F02%2Fjsonp%20%2B%20php%20%E8%B7%A8%E5%9F%9F%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[由于跨域的存在，使资源交互在不同域名间变的复杂和安全。对于跨域数据传输，当数据长度较小(get的长度内)，jsonp是一种较好的解决方案。 分享一个自己在jsonp使用过程中的demo。关于跨域可以参考：跨域总结与解决办法 jsonp的js端调用主要功能：通过jsonp向服务器，调用相应接口，获应数据；根据获取数据结果做出相应回调。 123456789101112131415161718192021222324252627282930313233343536/** * jsonp demo * 通过回调函数，进行获取之后的事件加载 * * @author:cuihuan * @private */_jsonpDemo:function(callback)&#123; $.ajax(&#123; url: "http://your_site_url", type: 'GET', dataType: 'JSONP', success: function (data) &#123; if (data &amp;&amp; data.status) &#123; if (data.status == "0") &#123; // failure solve ... &#125; else if (data.status == 500) &#123; // server error log _sendInternalLog(data.info); &#125; else if (data.status == 1) &#123; //success solve ... &#125; // callback func (callback &amp;&amp; typeof(callback) === "function" ) &amp;&amp; callback(); &#125; &#125;, error: function () &#123; _sendFailLog(); &#125; &#125;)&#125; jsonp 服务器端 (php)1234567891011121314151617181920212223242526/** * 接口返回相应数据 * * status: 0 标示失败，1标示成功,500发生错误 * return: jsonp */public function actionGetJsonPInfo()&#123; try &#123; $data = getNeedData() if ($data['status'] == "success") &#123; $res = array("status" =&gt; "1", 'info' =&gt; $data['info']); &#125;else&#123; $res = array("status" =&gt; "0", 'info' =&gt; '0'); &#125; &#125;catch (Exception $e)&#123; $res = array("status" =&gt; "500", 'info'=&gt; $e); &#125; // jsonp 通过get请求的返回数据形式 if (isset ($_GET['callback'])) &#123; header("Content-Type: application/json"); echo $_GET['callback']."(".json_encode($res).")"; &#125;&#125; 总结 目前来说，数据量小的跨域传输，jsonp是一种很好的解决方案。 jsonp在data中可以自动识别，res.status，res.info等状态位，比较方便。 php端的接受代码最好不要采用 Access-Control-Allow-Origin:* 风险太大。 本人小站原文]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>cors</tag>
        <tag>跨域</tag>
        <tag>jsonp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php 操作不同数据库]]></title>
    <url>%2F2015%2F11%2F30%2Fphp%20%E6%93%8D%E4%BD%9C%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[php脚本经常，处理处理不同机器上，不同数据库之间数据；而且脚本特别容易写错，抽取了个工作中最常用到的多库同步，特此记忆！ 上代码举个php操作不同数据库，进行数据同步的栗子。123456789101112131415161718192021222324252627282930313233343536373839/** * 同步库1的数据到库2 * * @author ：cuihuan * @date ：2015-10-11 */public function synchDbDiff()&#123; // 连接库1 $crowd_conn_1 = mysql_connect('ip_1:port_1', 'name_1', 'pw_1'); if (!$crowd_conn_1) &#123; die("Could not connect:" . mysql_error()); &#125; mysql_select_db('test_data', $crowd_conn_1); // 连接库2 $crowd_conn_2 = mysql_connect('ip_2:port_2', 'name_2', 'pw_2'); if (!$crowd_conn_1) &#123; die("Could not connect:" . mysql_error()); &#125; mysql_select_db('test_data', $crowd_conn_2); //获取未同步的数据 $get_data_sql = "SELECT `id`, `text` FROM `fb_conversation` WHERE `flag` = 1"; $c_result = mysql_query($get_data_sql, $crowd_conn_1); $this-&gt;check_res($c_result); if ($c_result) &#123; while ($row = mysql_fetch_array($c_result, MYSQL_NUM)) &#123; // 更新同步 $new_data_sql = "update from fb_conversation set text =" . $row[1] . " where id = " . $row[0]; $res = mysql_query($new_data_sql, $crowd_conn_2); $this-&gt;check_res($c_result); &#125; &#125;&#125; 个人小站原文链接]]></content>
      <tags>
        <tag>php</tag>
        <tag>mysql</tag>
        <tag>数据库同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php 处理unicode解码]]></title>
    <url>%2F2015%2F11%2F28%2Fphp%20%E5%A4%84%E7%90%86unicode%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[备忘：这个算是解码比较靠谱的，亲测。参考自stackoverflow，mark 分享 12345678910// change unicode to unt-8function replace_unicode_escape_sequence($match) &#123; return mb_convert_encoding(pack('H*', $match[1]), 'UTF-8', 'UCS-2BE');&#125;function unicode_decode($str) &#123; return preg_replace_callback('/u([0-9a-f]&#123;4&#125;)/i', 'replace_unicode_escape_sequence', $str); &#125;$str = unicode_decode('&#123;"u5173u952eu8bcd":[&#123;"","key":"u767eu5ea6"&#125;]&#125;'); 问题：使用过程中，遇到一个问题：就是当多次调用改函数的时候，出现错误。原因在于函数名方式调用问题。 如果编码是 \u5173\u952e\u8bcd 正则改为/\u([0-9a-f]{4})/i 即可 个人小站原文链接]]></content>
      <tags>
        <tag>php</tag>
        <tag>unicode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[phpUnit 安装，实例和简单部署]]></title>
    <url>%2F2015%2F11%2F28%2FphpUnit%20%E5%AE%89%E8%A3%85%EF%BC%8C%E5%AE%9E%E4%BE%8B%E5%92%8C%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[背景：一个小脚本，保证稳定为主；所以试用了下phpunit，快捷方便 phpunit 的安装phpunit是一个轻量级的php单元测试框架，通过pear安装安装过程1234wget https://phar.phpunit.de/phpunit.pharchmod +x phpunit.pharsudo mv phpunit.phar /usr/local/bin/phpunitphpunit --version 成功之后显示如下:12cuihuan:~ cuixiaohuan$ phpunit --versionPHPUnit 4.8.6 by Sebastian Bergmann and contributors. 简单试用测试类集成框架 class PsCaseTest extends PHPUnit_Framework_TestCase{} 其中phpunit默认首先执行 setup默认最后执行 teardown 举个栗子：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?php/*************************************************************************** * * $Id: PsCaseTest,v 1.0 PsCaseTest cuihuan Exp$ * **************************************************************************//** * @file PsCaseTest.php * @author cuihuan * @date 2015/09/11 10:09:31 * @version $Revision:1.0$ * @brief pscase接口单元测试 * **/require_once dirname(__FILE__) . ('/PsCase.php');class PsCaseTest extends PHPUnit_Framework_TestCase&#123; /** * @var object pscase类 */ protected $pscase; /** * @brief setup: Sets up the fixture, for example, opens a network connection. * * This method is called before a test is executed. */ public function setup()&#123; $this-&gt;pscase = new PsCase(); &#125; /** * @brief teardown: Tears down the fixture, for example, closes a network connection. * * This method is called after a test is executed. */ public function teardown()&#123; &#125; /** * @brief : 测试config文件的获取 * */ public function testGetConfig() &#123; $this-&gt;assertEquals(true,$this-&gt;pscase-&gt;debugText("11")); &#125;&#125; 运行运行方式：phpunit —bootstrap [源文件] 测试文件具体如下：12345678cuihuande:newcode cuixiaohuan$ phpunit --bootstrap ./PsCase.php ./PsCaseTest.php32015-09-11 02:09:36:11&lt;br&gt;5Time: 116 ms, Memory: 11.75MbOK (1 test, 1 assertion) 【表示运行成功】 部署部署就不不赘述了，写个shell脚本，crontab天极运行，加个报警邮件，简单的单元测试ok，从此再也不用担心错误和回归测试了。 个人小站原文链接]]></content>
      <tags>
        <tag>php</tag>
        <tag>单元测试</tag>
        <tag>phpunit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【redis学习二】多php版本下phpredis扩展安装]]></title>
    <url>%2F2015%2F11%2F28%2F%E3%80%90redis%E5%AD%A6%E4%B9%A0%E4%BA%8C%E3%80%91%E5%A4%9Aphp%E7%89%88%E6%9C%AC%E4%B8%8Bphpredis%E6%89%A9%E5%B1%95%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[背景：安装完redis之后，需要安装phpredis扩展，才能让php操作redis；本机有多个php版本，安装过程中遇到的坑分享一下。 ##一 下载git上下载redis的扩展包 git clone https://github.com/nicolasff/phpredis ##二 挂载和configure 在shell中输入 phpize 【注意：多个php版本的时候需要指定】 ./configure【phpize是用来扩展php扩展模块的，通过phpize可以建立php的外挂模块】 注意：（phpize 如果包含多个php，必须指定位置） cuihuan:phpredis cuixiaohuan$ ../php/bin/phpize Configuring for: PHP Api Version: 20121113 Zend Module Api No: 20121212 Zend Extension Api No: 220121212 Cannot find autoconf. Please check your autoconf installation and the $PHP_AUTOCONF environment variable. Then, rerun this script. 报错的话需要安装：brew install autoconf [phpize 报错] 否则没有phpize [work@cuixiaozhuai phpredis]$ ../php/bin/phpize Configuring for: PHP Api Version: 20041225 Zend Module Api No: 20060613 Zend Extension Api No: 220060519 [work@cuixiaozhuai phpredis]$ ./configure –with-php-config=/home/work/thirdparty/php5/bin/php-config 当存在多个版本的php的时候，需要指定配置文件 ./configure –with-php-config=/home/work/thirdparty/php5/bin/php-config ##三 编译和安装 make 之后最好make test make install cuihuan:phpredis cuixiaohuan$ make 。。。 Build complete. Don’t forget to run ‘make test’. cuihuan:phpredis cuixiaohuan$ make test cuihuan:phpredis cuixiaohuan$ make install ##四 问题修复【已修复，但是原因可能不太准确】make编译报错 .libs/redis_cluster.o(.data.rel.local+0x0): In function ht_free_seed&#39;: /home/work/thirdparty/php5/php5/phpredis/redis_cluster.c:226: multiple definition ofarginfo_scan’ .libs/redis.o(.data.rel.local+0xe0):/home/work/thirdparty/php5/php5/p hpredis/redis.c:452: first defined here /usr/bin/ld: Warning: size of symbol arginfo_scan&#39; changed from 160 in .libs/redis.o to 200 in .libs/redis_cluster.o .libs/redis_cluster.o(.data.rel.local+0xe0): In functioncreate_cluster_context’: /home/work/thirdparty/php5/php5/phpredis/redis_cluster.c:276: multiple definition of `arginfo_kscan’ .libs/redis.o(.data.rel.local+0x0):/home/work/thirdparty/php5/php5/phpredis/redis.c:364: first defined here collect2: ld returned 1 exit status make: *** [redis.la] Error 1 最初以为是php多个版本生成install问题，采用./configure 指定php版本，指定php位置。但是效果还是有问题。最终通过修改redis_cluester.c 中，注释掉了这两个重复的 40 41 /* Argument info for HSCAN, SSCAN, HSCAN */ 42 /*ZEND_BEGIN_ARG_INFO_EX(arginfo_kscan, 0, 0, 2) 43 ZEND_ARG_INFO(0, str_key) 44 ZEND_ARG_INFO(1, i_iterator) 45 ZEND_ARG_INFO(0, str_pattern) 46 ZEND_ARG_INFO(0, i_count) 47 ZEND_END_ARG_INFO(); 48 */ 49 50 /* Argument infor for SCAN */ 51 /* 52 ZEND_BEGIN_ARG_INFO_EX(arginfo_scan, 0, 0, 2) 53 ZEND_ARG_INFO(1, i_iterator) 54 ZEND_ARG_INFO(0, str_node) 55 ZEND_ARG_INFO(0, str_pattern) 56 ZEND_ARG_INFO(0, i_count) 57 ZEND_END_ARG_INFO(); 58 */ ##五 简单测试 &lt;?php $redis = new Redis(); $conn = $redis-&gt;connect(&apos;127.0.0.1&apos;,6379); echo &quot;redis pass and status show&lt;/br&gt;&quot;; var_dump($redis-&gt;ping()); $redis-&gt;set(&apos;test_key&apos;,&apos;test_value&apos;); echo &quot;test set val=&quot;.$redis-&gt;get(&apos;test_key&apos;).&quot;&lt;/br&gt;&quot;; $redis-&gt;setnx(&apos;unique_key&apos;,&quot;unique_val&quot;); $redis-&gt;setnx(&apos;unique_key&apos;,&quot;unique_val_2&quot;); echo $redis-&gt;get(&quot;unique_key&quot;); sleep(60); echo &apos;is exist&apos;.$redis-&gt;exists(&apos;test_60s&apos;); echo &apos;not has value&apos;.$redis-&gt;get(&apos;test_60s&apos;); $redis-&gt;delete(&apos;test_key&apos;,&apos;test_60s&apos;); 个人小站原文链接]]></content>
      <tags>
        <tag>php</tag>
        <tag>redis</tag>
        <tag>phpredis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【redis学习一】基本概念和基本操作]]></title>
    <url>%2F2015%2F11%2F28%2F%E3%80%90redis%E5%AD%A6%E4%B9%A0%E4%B8%80%E3%80%91%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[redis 基础官网地址： http://redis.io/ 基本介绍：redis 是一个ansi c编写，支持网络的，基于内存的可持久化的日执行，kv数据库；10年期redis有vmare主持开发。 支持数据类型：redis支持strings,hashes list set sorted等结构。 持久化：存储于内存或虚拟内存中，有两种持久化的方式： ：截图，内存数据不断写入硬盘【性能较高】 ：log：记录每次更新的日志。【稳定性好】 支持主从同步，性能非常优秀。提供多种语言的api 基本上知道的都有。 使用场景：(个人觉的可以有的使用场景)1：权限【权限每次都要入库校验，放在前端不靠谱，放在cache最合适】2：缓存【例如批量操作数据，可以先缓存】3：预取【例如topN数据,另外可能用到的数据，提前取出来，加快页面加载】4：构建消息队列【可以根据redis的数据结构list，构造；数据批量入库，加快页面相应等方面不错】。5：计数器【类似于批量入库的原理，可以计数，redis原子性的，可以精确支持】6：其他场景还在不断探索中。 安装和基本操作安装参考： http://www.runoob.com/redis/redis-install.html 基本操作： 官方文档地址 启动：./redis-server关闭：redis-cli shutdown12345678910111213141516171819202122232425[cuihuan bin]$ ./redis-cli shutdown[cuihuan bin]$ ./redis-server [325] 24 Sep 18:49:06.632 # Warning: no config file specified, using the default config. In order to specify a config file use ./redis-server /path/to/redis.conf _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 2.6.10 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in stand alone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 325 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' [325] 24 Sep 18:49:06.633 # Server started, Redis version 2.6.10[325] 24 Sep 18:49:06.633 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.[325] 24 Sep 18:49:06.673 * DB loaded from disk: 0.039 seconds[325] 24 Sep 18:49:06.673 * The server is now ready to accept connections on port 6379 安装成功的标志 redis-cli 可以成功进入 12[cuihuan bin]$ ./redis-cliredis 127.0.0.1:6379&gt; 注意：使用过程中如果是保密性高的数据，可以设置登录密码，增加安全想；但如果是简单数据，则可以不设置，优点就是速度稍快。 redis 基本配置：daemonize: yes 标示在后台运行bind：绑定请求的地址port：端口号，默认6379timeout:默认客户端连接超时 多长时间不操作关闭(默认永久，此处改为3600) loglevel: log等级databases：默认连接数据库的个数 【此处为8】slaveof 主从库 masterauth :密码验证requirepass:是否需要密码 maxclients :最大客户机个数 设置为10000maxmemory:最大内存个数 6625156 [机器内存32G,分配大约6g] 最基本的操作set name xxxget name xxxdel name xxxexists name xxx 举个栗子12345678910111213141516171819# get valredis 127.0.0.1:6379&gt; get name"cuixiaohuan"# set val redis 127.0.0.1:6379&gt; set name cuixiaohuan_2 OKredis 127.0.0.1:6379&gt; get name"cuixiaohuan_2"# check exists; if exists return 1redis 127.0.0.1:6379&gt; exists name(integer) 1# del valredis 127.0.0.1:6379&gt; del name(integer) 1redis 127.0.0.1:6379&gt; get name(nil) 其他常用操作：123456789101112131415# ping :check connectredis 127.0.0.1:6379&gt; pingPONG# dbsize :check sizeredis 127.0.0.1:6379&gt; dbsize(integer) 1#flush :clear dbredis 127.0.0.1:6379&gt; dbsize(integer) 1redis 127.0.0.1:6379&gt; flushdbOKredis 127.0.0.1:6379&gt; dbsize(integer) 0 个人小站原文链接]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[canvas 生成和合并图片]]></title>
    <url>%2F2015%2F11%2F23%2Fcanvas_combine_pic%2F</url>
    <content type="text"><![CDATA[先说背景：工作中遇到一个问题，file组件上传图片，file是可以上传n张图片；但是，后台逻辑历史原因，只能展现一张。因此：考虑到成本，决定在前端将多张图片合并成一张给后端。 先上代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576_mergeImage2Canvas:function() &#123; // 获取file上传和展现的图片。一般file上传之后，有个小图标展现。 var imgs = $(".img_files"); if (!imgs) &#123; return false; &#125; // 创建原始图像 // 原因：file上传之后，展现往往是个缩略图，无法取到真正大小 for (var i = 0; i &lt; imgs.length; i++) &#123; var fbwImg = document.createElement("img"); var fbwImgID = "temp_img_id" + i; $("#" + fbwImgID).remove(); fbwImg.src = imgs[i].src; fbwImg.className = "temp-img-class"; // 不显示，仅供调用 fbwImg.style.display = "none"; // 临时区域扩展 $("#temp_section").append(fbwImg); &#125; // 合并原始图片，生成一个新的base64 图片 var getOriginImgBase64 = function (oriImgs) &#123; if (!oriImgs) &#123; return false; &#125; // 获取canvas的宽高 // 原因：canvas需要首先指定宽高，所以需要提前获取最终的宽高 var maxWidth = 0; var height = 0; for (var i = 0; i &lt; oriImgs.length; i++) &#123; var img = oriImgs[i]; if (img.width &gt; maxWidth) &#123; maxWidth = img.width; &#125; height += img.height; &#125; // 设定canvas var canvas = document.createElement("canvas"); canvas.width = maxWidth + 10; canvas.height = height + 10; var ctx = canvas.getContext("2d"); // 留5margin var dheight = 5; for (var j = 0; j &lt; oriImgs.length; j++) &#123; var img = oriImgs[j]; var cheight = img.height; var cwidth = img.width; // 留5 margin ctx.drawImage(img, 5, dheight, cwidth, cheight); dheight = dheight + cheight + 5; &#125; // 生成的base64 放在需要的一个全局变量中。 fbw_img_data = canvas.toDataURL('image/png'); // 清理 $(".temp_img_class").remove(); &#125;; // 之所以使用timer，考虑到dom树如果没有加载完成，会取到高度有误差 var imgTimer = null; imgTimer = setTimeout(function () &#123; getOriginImgBase64($(".temp_img_class")); if (imgTimer) &#123; clearTimeout(imgTimer); &#125; &#125;, 300);&#125; 合成效果图片一：小站logo 图片二：小图标： 合成效果： 原理简介主要是通过canvas 获取多个图片的base64编码，之后通过drawImage 函数合并和toDataUrl的方式合成。 问题思考 问题一：必须支持canvas，否则还需要后台统一跑脚本处理。 问题二：性能消耗过大。append img 和base64代码对dom的消耗都挺大，尤其是在移动端，很容易造成崩溃。解决办法：设定最大宽度，将图片等比缩放，这样子就少了向dom扩展元素这部分的损耗。 问题三：base64 在传输上性能消耗也挺大，没有file原生的好。 因此：出了必须前端搞定，最好的方式，还是在后台跑脚本运行合并。 个人小站原文链接]]></content>
      <tags>
        <tag>合成图片</tag>
        <tag>canvas</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx实践一：centos apache更换为nginx]]></title>
    <url>%2F2015%2F11%2F18%2FNginx%E5%AE%9E%E8%B7%B5%E4%B8%80%EF%BC%9Acentos%20apache%E6%9B%B4%E6%8D%A2%E4%B8%BAnginx%2F</url>
    <content type="text"><![CDATA[背景介绍： 阿里云，512M内存（最屌丝配置），搭建lamp 环境，除去 mysql分配了100M左右（这个不能再少了），http竟然占用了200多M，太庞大，决定换为较轻量级，高并发的nginx。 背景数据如下图所示：系统也就500M ,出了mysql占用的100M, httpd 占了1/2 还多（经常达到十几个进程），剩余50M，有时更少不能忍，经常造成数据库崩掉，写了个自动重启脚本，但觉的不是治本之策 # 统计apache 进程个数 ps aux|grep httpd | wc –l 解决策略 1：针对Apache进行优化。包括优化worker运行方式等等。可以参考 apache优化 2 :更换轻量级服务器。采用nginx 或者lighthttpd等更轻量的服务器。传说中Nginx大法负载均衡和高并发略胜一筹，决定实践一把。 apache替换为nginx 1： 停掉apache sudo service httpd stop 注意：以防万一，最好不好提前卸掉。 2：安装nginx yum install nginx 3：启动nginx sudo nginx 安装成功之后，启动成功如下图 4：简单配置nginx主要是简单修改下log【方便追查问题】 和 web_root 对应文件【快速启用网站】 5：重启nginx [root@iZ25xlozdf2Z nginx]# nginx -s quit [root@iZ25xlozdf2Z nginx]# nginx 如下图，配置web目录成功！ 6：添加php 支持安装php-fpm yum install php-fpm nginx.conf设置 location ~ .php$ { root /var/www/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /var/www/html$fastcgi_script_name; include fastcgi_params; } 7：重新启动服务，网站回复。 8：耗存简单对比 如下图：基本上节省了200M，虽然这个可能是运行初期数据；但是，还是确实轻了不少，每个服务占存基本上1/4，线程也少了不少。内存占用方面表现，感觉尚可，接下就看性能了 后续初次接触nginx，整体感觉还不错。后续，进行基本的防攻击，多端口设置，和性能配置。 个人小站原文链接]]></content>
      <tags>
        <tag>php</tag>
        <tag>nginx</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx实践二：nginx端口配置，域名重定向设置]]></title>
    <url>%2F2015%2F11%2F18%2FNginx%E5%AE%9E%E8%B7%B5%E4%BA%8C%EF%BC%9Anginx%E7%AB%AF%E5%8F%A3%E9%85%8D%E7%BD%AE%EF%BC%8C%E5%9F%9F%E5%90%8D%E9%87%8D%E5%AE%9A%E5%90%91%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[nginx替换apache之后，需要进行两个基本设置，一是：域名绑定和重定向，防止盗链，死链，参考文章 apache 防盗链 ；二是：设置多个端口，一个端口显然无法满足需求。 域名防盗链设置域名防盗链主要通过，设定服务器域名，非域名重定向到现有域名（相对于之前的黑名单，我太单纯了，流量可以重定向利用一下）。 配置nginx.conf 12345678# default 默认只能server_name 访问listen 80 default ;server_name cuihuan.net;# 重定向if ($host != "cuihuan.net") &#123; rewrite ^/(.*)$ http://cuihuan.net/$1 permanent;&#125; 解释：首先80端口默认只能域名访问 ，默认的域名cuihuan.net。 对于所有非cuihuan.net 的过来的数据直接引流的cuihuan.net。如下图【这个战斗力为五的渣渣还挂在我的页面】 进行了转码后还可以避免搜索引擎抓的域名出现死链。 配置多端口： 这个就简单了，直接把上面配置好的server copy一个挂上其他web服务或者phpadmin等等1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 8002 default ; server_name cuihuan.net; if ($host != "cuihuan.net") &#123; rewrite ^/(.*)$ http://cuihuan.net/$1 permanent; &#125; location / &#123; root /var/www/weixin; index index.php; &#125; location ~ \.php$ &#123; root /var/www/weixin; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /var/www/weixin$fastcgi_script_name; include fastcgi_params; &#125; # set nginx stutus location /NginxStatus&#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file conf/htpasswd; &#125; #set deny all file error_page 404 /404.html; location = /var/www/wordpress/40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /home/www/wordpress/50x.html &#123; &#125; &#125; 对于nginx搭建小网站来说，这个是基本的配置。个人感觉相对于之前 apache 防盗链配置 来说难易差不多。 相关文章：Nginx实践一：centos apache更换为nginx 个人小站原文链接]]></content>
      <tags>
        <tag>nginx</tag>
        <tag>apache</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
</search>